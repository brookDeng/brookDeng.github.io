[{"title":"go learning 1 变量与运算","url":"/2022/07/04/1变量与运算/","content":"\n## 变量\n\n当一个变量被声明之后，系统自动赋予它该类型的零值：`int` 为 `0`，`float32(64)` 为 `0.0`，bool 为 `false`，`string` 为空字符串，指针为 `nil`。记住，所有的内存在 Go 中都是经过初始化的。\n\n变量命名：驼峰式命名   若想为外部可见，则需首字母也大写\n\n### 变量作用域\n\n**全局变量**:在函数体外声明，允许声明但不使用。\n\n**局部变量**：在函数体内声明，作用域只在相应的代码块内，声明变量必须使用。\n\n### 变量赋值\n\n```\nvar identifier [type] = value\nvar str string = \"Go says hello to the world!\"\n```\n\nGo编译器可以自动判断变量类型\n\n函数体内声明变量使用简短声明语法  `:=` 。这是使用变量的首选形式，但是它只能被用在函数体内，而不可以用于全局变量的声明与赋值。使用操作符 `:=` 可以高效地创建一个新的变量，称之为初始化声明。\n\n当使用等号 `=` 将一个变量的值赋值给另一个变量时，如：`j = i`，实际上是在内存中将 `i` 的值进行了拷贝：\n\n你可以通过 `&i` 来获取变量 `i` 的内存地址，值类型的变量的值存储在栈中。\n\n在 Go 语言中，指针属于引用类型，其它的引用类型还包括 slices，maps和 channel。被引用的变量会存储在堆中，以便进行垃圾回收，且比栈拥有更大的内存空间。\n\n### 多变量**并行** 或 **同时** 赋值\n\n多变量声明及赋值可以在同一行进行。\n\n如果你想要交换两个变量的值，则可以简单地使用 `a, b = b, a`。\n\n## 打印Printf\n\n函数 `Printf` 可以在 `fmt` 包外部使用，这是因为它以大写字母 P 开头。\n\n```\nfunc Printf(format string, list of variables to be printed)\n```\n\n格式化字符串为：`\"The operating system is: %s\\n\"`。\n\n这个格式化字符串可以含有一个或多个的格式化标识符，例如：`%..`，其中 `..` 可以被不同类型所对应的标识符替换，如 `%s` 代表字符串标识符、`%v` 代表使用类型的默认输出格式的标识符。这些标识符所对应的值从格式化字符串后的第一个逗号开始按照相同顺序添加，如果参数超过 1 个则同样需要使用逗号分隔。使用这些占位符可以很好地控制格式化输出的文本。\n\n函数 `fmt.Sprintf` 与 `Printf` 的作用是完全相同的，不过前者将格式化后的字符串以返回值的形式返回给调用者，因此你可以在程序中使用包含变量的字符串。\n\n### **格式化说明符**\n\n在格式化字符串里，\n\n`%d` 用于格式化整数（`%x` 和 `%X` 用于格式化 16 进制表示的数字），\n\n`%g` 用于格式化浮点型\n\n`%f` 输出浮点数，\n\n`%c` 输出字符，\n\n`%e` 输出科学计数表示法，\n\n`%0nd` 用于规定输出长度为 n 的整数，其中开头的数字 0 是必须的。\n\n`%n.mg` 用于表示数字 n 并精确到小数点后 m 位，除了使用 g 之外，还可以使用 e 或者 f，例如：使用格式化字符串 `%5.2e` 来输出 3.4 的结果为 `3.40e+00`。\n\n\n\n## init 函数\n\n## 数字类型\n\n### 整型int\n\nGo 也有基于架构的类型，例如：`int`、`uint` 和 `uintptr`。\n\n这些类型的长度都是根据运行程序所在的操作系统类型所决定的：\n\n- `int` 和 `uint` 在 32 位操作系统上，它们均使用 32 位（4 个字节），在 64 位操作系统上，它们均使用 64 位（8 个字节）。\n- `uintptr` 的长度被设定为足够存放一个指针即可。\n\n整数：\n\n- `int8`（-128 -> 127）\n- `int16`（-32768 -> 32767）\n- `int32`（-2,147,483,648 -> 2,147,483,647）\n- `int64`（-9,223,372,036,854,775,808 -> 9,223,372,036,854,775,807）\n\n无符号整数：\n\n- `uint8`（0 -> 255）\n- `uint16`（0 -> 65,535）\n- `uint32`（0 -> 4,294,967,295）\n- `uint64`（0 -> 18,446,744,073,709,551,615）\n\n浮点型（IEEE-754 标准）：\n\n- `float32`（+- 1e-45 -> +- 3.4 * 1e38）\n- `float64`（+- 5 * 1e-324 -> 107 * 1e308）\n\n`int` 型是计算最快的一种类型。\n\n整型的零值为 `0`，浮点型的零值为 `0.0`。\n\n`float32` 精确到小数点后 7 位，`float64` 精确到小数点后 15 位。应该尽可能地使用 `float64`，因为 `math` 包中所有有关数学运算的函数都会要求接收这个类型。\n\n###  复数\n\nGo 拥有以下复数类型：\n\n```\ncomplex64 (32 位实数和虚数)\ncomplex128 (64 位实数和虚数)\n```\n\n复数使用 `re+imI` 来表示，其中 `re` 代表实数部分，`im` 代表虚数部分，`I` 代表根号负 1。\n\n示例：\n\n```\nvar c1 complex64 = 5 + 10i\nfmt.Printf(\"The value is: %v\", c1)\n// 输出： 5 + 10i\n```\n\n如果 `re` 和 `im` 的类型均为 `float32`，那么类型为 `complex64` 的复数 `c` 可以通过以下方式来获得：\n\n```\nc = complex(re, im)\n```\n\n函数 `real(c)` 和 `imag(c)` 可以分别获得相应的实数和虚数部分。\n\n在使用格式化说明符时，可以使用 `%v` 来表示复数，但当你希望只表示其中的一个部分的时候需要使用 `%f`。\n\n## 位运算\n\n位运算只能用于整数类型的变量，且需当它们拥有等长位模式时。\n\n`%b` 是用于表示位的格式化标识符。\n\n### **二元运算符**\n\n- 按位与 `&`：同1则为1\n- 按位或 `|`：有1则为1\n- 按位异或 `^`：同样则为0\n- 位清除 `&^`：将指定位置上的值设置为 `0`。\n\n### **一元运算符**\n\n- 按位补足 `^`：\n\n  该运算符与异或运算符一同使用，即 `m^x`，对于无符号 `x` 使用 “全部位设置为 1” 的规则，对于有符号 `x` 时使用 `m=-1`。例如：\n\n  ```\n    ^10 = -01 ^ 10 = -11\n  ```\n\n- 位左移 `<<`：\n\n- 位右移 `>>`：\n\n- **位左移常见实现存储单位的用例**\n\n  使用位左移与 `iota` 计数配合可优雅地实现存储单位的常量枚举：\n\n  ```\n  type ByteSize float64\n  const (\n  \t_ = iota // 通过赋值给空白标识符来忽略值\n  \tKB ByteSize = 1<<(10*iota)\n  \tMB\n  \tGB\n  \tTB\n  \tPB\n  \tEB\n  \tZB\n  \tYB\n  )\n  ```\n\n## 逻辑运算符\n\nGo 中拥有以下逻辑运算符：`==`、`!=`（第 4.5.1 节）、`<`、`<=`、`>`、`>=`。\n\n它们之所以被称为逻辑运算符是因为它们的运算结果总是为布尔值 `bool`。例如：\n\n```\nb3 := 10 > 5 // b3 is true\n```\n\n## 算术运算符\n\n常见可用于整数和浮点数的二元运算符有 `+`、`-`、`*` 和 `/`。\n\n## 随机数\n\n一些像游戏或者统计学类的应用需要用到随机数。`rand` 包实现了伪随机数的生成。\n\n函数 `rand.Float32` 和 `rand.Float64` 返回介于 [0.0,1.0) 之间的伪随机数，其中包括 `0.0` 但不包括 `1.0`。函数 `rand.Intn` 返回介于 [0,n) 之间的伪随机数。\n\n","tags":["Go","learning"],"categories":["Go"]},{"title":"加密算法学习","url":"/2021/12/20/加密算法学习/","content":"\n在项目开发中经常用到一些加密算法，其应用场景常包括用户登录，通讯，支付等。\n\n常见的加密算法可以分成三类，对称加密算法，非对称加密算法和Hash算法。\n\n## **对称加密**\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29S4VsGiaXx_OVU-W/root/content)\n\n指加密和解密使用相同密钥的加密算法。对称加密算法的优点在于加解密的高速度和使用长密钥时的难破解性。假设两个用户需要使用对称加密方法加密然后交换数据，则用户最少需要2个密钥并交换使用，如果企业内用户有n个，则整个企业共需要n×(n-1) 个密钥。对称加密算法的安全性取决于加密密钥的保存情况。\n\n一段明文通过密钥进行加密，可以生成一段密文；这段密文通过同样的密钥进行解密，可以还原成明文。这样一来，只要双方事先约定好了密钥，就可以使用密文进行往来通信。\n\n除了通信过程中的加密以外，数据库存储的敏感信息也可以通过这种方式进行加密。这样即使数据泄露到了外界，泄露出去的也都是密文。\n\n**常见的对称加密算法：**DES、3DES、DESX、Blowfish、IDEA、RC4、RC5、RC6和AES\n\n**DES**（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。DES 加密算法是一种 分组密码，以 64 位为 分组对数据 加密，它的 密钥长度 是 56 位，加密解密 用 同一算法。\n\nDES 加密算法是对 密钥 进行保密，而 公开算法，包括加密和解密算法。这样，只有掌握了和发送方 相同密钥 的人才能解读由 DES加密算法加密的密文数据。因此，破译 DES 加密算法实际上就是 搜索密钥的编码。对于 56 位长度的 密钥 来说，如果用 穷举法 来进行搜索的话，其运算次数为 2 ^ 56 次。\n\n**3DES**（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。\n\n**AES**（Advanced Encryption Standard）：AES 加密算法是密码学中的 高级加密标准，该加密算法采用 对称分组密码体制，密钥长度的最少支持为 128 位、 192 位、256 位，分组长度 128 位，算法应易于各种硬件和软件实现。这种加密算法是美国联邦政府采用的 区块加密标准。\n\nAES 本身就是为了取代 DES 的，AES 具有更好的 安全性、效率 和 灵活性。\n\n\n### AES与3DES的比较\n\n| 算法名称 | 算法类型        | 密钥长度        | 速度 | 解密时间（建设机器每秒尝试255个密钥） | 资源消耗 |\n| -------- | --------------- | --------------- | ---- | ------------------------------------- | -------- |\n| AES      | 对称block密码   | 128、192、256位 | 高   | 1490000亿年                           | 低       |\n| 3DES     | 对称feistel密码 | 112位或168位    | 低   | 46亿年                                | 中       |\n\n对称算法的好处是加密解密的效率比较高。相应的，对称算法的缺点是不够安全。为什么呢？通信双方约定的密钥是相同的，只要密钥本身被任何一方泄露出去，通信的密文就会被破解；此外，在双方建立通信之初，服务端把密钥告诉给客户端的时候，也有被拦截到的危险。\n\n## **非对称加密**\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29S83L4FNy1LSl8C1/root/content)\n\n指加密和解密使用不同密钥的加密算法，也称为公私钥加密。假设两个用户要加密交换数据，双方交换公钥，使用时一方用对方的公钥加密，另一方即可用自己的私钥解密。如果企业中有n个用户，企业需要生成n对密钥，并分发n个公钥。由于公钥是可以公开的，用户只要保管好自己的私钥即可，因此加密密钥的分发将变得十分简单。同时，由于每个用户的私钥是唯一的，其他用户除了可以可以通过信息发送者的公钥来验证信息的来源是否真实，还可以确保发送者无法否认曾发送过该信息。非对称加密的缺点是加解密速度要远远慢于对称加密，在某些极端情况下，甚至能比非对称加密慢上1000倍。\n\n### 通信的过程\n\n1.在双方建立通信的时候，服务端只要把公钥告诉给客户端，自己保留私钥。\n\n2.客户端利用获得的公钥。加密另外一个密钥X（可以是对称加密的密钥），发送给服务端。\n\n3.服务端获得消息后，用自己的私钥解密，得到里面隐含的密钥X。\n\n4.从此以后，双方可以利用密钥X进行对称加密的通信了。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TAA1WE2z_L34wy3/root/content)\n\n\n\n**常见的非对称加密算法：**RSA、ECC（移动设备用）、Diffie-Hellman、El Gamal、DSA（数字签名用）\n\nRSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的。RSA 加密算法是目前最有影响力的 公钥加密算法，并且被普遍认为是目前 最优秀的公钥方案 之一。RSA 是第一个能同时用于 加密 和 数字签名 的算法，它能够 抵抗 到目前为止已知的 所有密码攻击，已被 ISO 推荐为公钥数据加密标准。\n\nRSA 加密算法 基于一个十分简单的数论事实：将两个大 素数 相乘十分容易，但想要对其乘积进行 因式分解 却极其困难，因此可以将 乘积 公开作为 加密密钥。\n\nDSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准）；\n\nECC（Elliptic Curves Cryptography）：椭圆曲线密码编码学。\n\n`ECC` 也是一种 **非对称加密算法**，主要优势是在某些情况下，它比其他的方法使用 **更小的密钥**，比如 `RSA` **加密算法**，提供 **相当的或更高等级** 的安全级别。不过一个缺点是 **加密和解密操作** 的实现比其他机制 **时间长** (相比 `RSA` 算法，该算法对 `CPU` 消耗严重)。\n\n\n\nECC和RSA相比，在许多方面都有对绝对的优势，主要体现在以下方面：\n\n抗攻击性强。相同的密钥长度，其抗攻击性要强很多倍。\n\n计算量小，处理速度快。ECC总的速度比RSA、DSA要快得多。\n\n存储空间占用小。ECC的密钥尺寸和系统参数与RSA、DSA相比要小得多，意味着它所占的存贮空间要小得多。这对于加密算法在IC卡上的应用具有特别重要的意义。\n\n带宽要求低。当对长消息进行加解密时，三类密码系统有相同的带宽要求，但应用于短消息时ECC带宽要求却低得多。带宽要求低使ECC在无线网络领域具有广泛的应用前景。\n\n\n\n## **Hash算法**（**散列算法**）\n\nHash算法特别的地方在于它是一种单向算法，用户可以通过Hash算法对目标信息生成一段特定长度的唯一的Hash值，却不能通过这个Hash值重新获得目标信息。其中一个重要的作用就是**生成信息摘要**，用以验证原信息的完整性和来源的可靠性。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。\n\n**常见的Hash算法：**MD2、MD4、MD5、HAVAL、SHA、SHA-1、HMAC、HMAC-MD5、HMAC-SHA1\n\n 单向散列函数一般用于产生消息摘要，密钥加密等，常见的有：\n\n**MD5**（Message Digest Algorithm 5）128位：是RSA数据安全公司开发的一种单向散列算法，非可逆，相同的明文产生相同的密文。`MD5` 用的是 **哈希函数**，它的典型应用是对一段信息产生 **信息摘要**，以 **防止被篡改**。严格来说，`MD5` 不是一种 **加密算法** 而是 **摘要算法**。无论是多长的输入，`MD5` 都会输出长度为 `128bits` 的一个串 (通常用 `16` **进制** 表示为 `32` 个字符)。\n\n**SHA**（Secure Hash Algorithm）：SHA1 是和 MD5 一样流行的 消息摘要算法，然而 SHA1 比 MD5 的 安全性更强。对于长度小于 2 ^ 64 位的消息，SHA1 会产生一个 160 位的 消息摘要。基于 MD5、SHA1 的信息摘要特性以及 不可逆 (一般而言)，可以被应用在检查 文件完整性 以及 数字签名 等场景。\n\n### **SHA-1与MD5的比较**\n\n因为二者均由MD4导出，SHA-1和MD5彼此很相似。相应的，他们的强度和其他特性也是相似，但还有以下几点不同：\n\n**对强行供给的安全性**：最显著和最重要的区别是SHA-1摘要比MD5摘要长32 位。使用强行技术，产生任何一个报文使其摘要等于给定报摘要的难度对MD5是2128数量级的操作，而对SHA-1则是2160数量级的操作。这样，SHA-1对强行攻击有更大的强度。\n\n**对密码分析的安全性**：由于MD5的设计，易受密码分析的攻击，SHA-1显得不易受这样的攻击。\n\n**速度**：在相同的硬件上，SHA-1的运行速度比MD5慢。\n\n## **加密算法的选择**\n\n由于非对称加密算法的运行速度比对称加密算法的速度慢很多，当我们需要加密大量的数据时，建议采用对称加密算法，提高加解密速度。\n\n对称加密算法不能实现签名，因此签名只能非对称算法。\n\n由于对称加密算法的密钥管理是一个复杂的过程，密钥的管理直接决定着他的安全性，因此当数据量很小时，我们可以考虑采用非对称加密算法。\n\n在实际的操作过程中，我们通常采用的方式是：采用非对称加密算法管理对称算法的密钥，然后用对称加密算法加密数据，这样我们就集成了两类加密算法的优点，既实现了加密速度快的优点，又实现了安全方便管理密钥的优点。\n\n那采用多少位的密钥呢？ RSA建议采用1024位的数字，ECC建议采用160位，AES采用128为即可。\n\n","tags":["learn","算法","加密"],"categories":["学习"]},{"title":"阿里云部署单机服务","url":"/2021/11/21/阿里云部署单机服务/","content":"\n​       之前白嫖的阿里云学生服务器到期了，所以重新买了一年的阿里云轻量应用服务器来部署之前的服务，今天特意把整个过程记录下来，以备查看。\n\n​        该服务所需安装的服务有不少，分别是nginx，maven，tomcat，elasticsearch，kafka，mysql，redis\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Rsfbj-qx3p03uur/root/content)\n\n# 部署\n\n## 宝塔面板\n\n### 安装\n\nyum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh 6dca892c\n\n### 使用\n\nbt \n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29RzU7G3djYH44uIx/root/content)\n\n## Jre\n\n### 安装\n\nyum list java*\n\nyum install -y java-latest-openjdk.x86_64\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29R0MZYO1ZODuMw03/root/content)\n\n## Maven\n\n### 安装\n\n tar -zvxf apache-maven-3.8.2-bin.tar.gz -C /opt\n\n```\n[root@iZbp1e959bxugmpmsl1j1cZ ~]# cd /opt\n[root@iZbp1e959bxugmpmsl1j1cZ opt]# ls\napache-maven-3.8.2\n```\n\n### 配置环境变量\n\nvim /etc/profile\n\nexport PATH=$PATH:/opt/apache-maven-3.8.2/bin\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29R4TYHIOhgKANuX2/root/content)\n\n重新加载\n\nsource /etc/profile\n\nmvn -vesion\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29R9UgqXW9ekY8BIn/root/content)\n\n### 设置\n\nC:\\Program Files\\Java\\apache-maven-3.8.1\\conf\n\n```\n   <mirror>\n        <id>nexus-aliyun</id>\n        <mirrorOf>central</mirrorOf>\n        <name>Nexus aliyun</name>\n        <url>http://maven.aliyun.com/nexus/content/groups/public</url>\n</mirror>\n```\n\n插入到/opt/apache-maven-3.8.2/conf\n\n\n\n## mysql\n\n### 安装\n\nyum list mysql*\n\nyum install -y mysql-community-server.x86_64\n\n### 启动\n\nsystemctl start mysqld\n\nsystemctl statusmysqld\n\n### 更改密码\n\ngrep ‘password’  /var/log/mysqld.log\n\nalter user root@localhost identified by 'Xinyu_521';\n\n### windows数据库导出备份Linux还原\n\ncmd> cd D:\\Java\\MySQL\\bin\n\nmysqldump -u root -p community > community.sql\n\nbin目录下有coummuity.sql文件，上传到linux服务器\n\n进入mysql创建新数据库community并导入备份\n\nsource /root/community.sql\n\n### 数据库增加表情支持emoji\n\n表情是4个字节的奇葩，而utf8只能存3字节数据，所以我们要改数据库、表、存表情的字段的编码为utf8mb4\n\nalter table discuss_post convert to character set utf8mb4 collate utf8mb4_general_ci;\n\nalter table comment convert to character set utf8mb4 collate utf8mb4_general_ci;\n\nalter table message convert to character set utf8mb4 collate utf8mb4_general_ci;\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SC9VPXBy7nomJvN/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SG-Bj8DAOoK0WXb/root/content)\n\n这样就支持了\n\n## redis\n\n### 安装\n\nyum install -y redis.x86_64\n\n### 启动\n\n启动redis服务器\n\nsystemctl start redis\n\n```\nredis-server /etc/redis.conf\n```\n\n访问redis  `redis-cli`\n\n## kafka\n\n### 安装\n\ntar -zvxf kafka_2.13-2.8.0.tgz -C /opt\n\n### 配置\n\n### 启动\n\n### Linux\n\nhttps://www.cnblogs.com/miamianfighting/p/14087091.html\n\n**firewall-cmd --state**查看防火墙\n\n启动\n\ncd /opt/kafka_2.13-2.8.0\n\nbin/zookeeper-server-start.sh -daemon config/zookeeper.properties\n\nnohup bin/kafka-server-start.sh config/server.properties 1>/dev/null 2>&1 &\n\n- 查看kafka topic列表，使用–list参数\n\nbin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list\n\n## Elasticsearch\n\n### 安装\n\ntar -zxvf elasticsearch-7.12.1-linux-x86_64.tar.gz -C /opt\n\n解压缩分词插件\n\nunzip -d /opt/elasticsearch-7.12.1/plugins/ik elasticsearch-analysis-ik-7.12.1.zip\n\n### 设置\n\nE:\\Javastudy\\elasticsearch-7.12.1\\config\\elasticsearch.yml\n\n然后更改一下占用内存jvmoptions\n\n```\n-Xms256m\n-Xmx512m\n```\n\nelastic不允许root用户  需要新建普通用户\n\ngroupadd community\n\nuseradd brook -p xinyu521 -g community\n\n设置权限\n\ncd /opt\n\nchown -R brook:community *\n\n cd /tmp\n\nchown -R brook:community *\n\n### 启动\n\nsu - brook\n\ncd /opt/elasticsearch-7.12.1\n\nbin/elasticsearch -d\n\ncurl http://localhost:9200/_cat/health?v\n\n## wkhtmltopdf\n\nyum list wkhtmltopdf*\n\nyum install wkhtmltopdf.x86_64\n\nlinux没有gui  需要安装虚拟gui\n\nyum install xorg-x11-server-Xvfb.x86_64\n\n## tomcat\n\n### 安装\n\n tar -zxvf apache-tomcat-9.0.52.tar.gz -C /opt\n\n### 环境变量\n\n/opt/apache-tomcat-9.0.52/bin\n\n打开ip:8080\n\n打不开就是防火墙问题\n\n**systemctl stop firewalld service**\n\n## nginx\n\n反向代理\n\n```\nupstream myserver {\n           server 127.0.0.1:8080 max_fails=3 fail_timeout=30s;\n\n}\nserver {\n        listen 80;\n        server_name 47.113.190.16;\n        location / {\n          proxy_pass http://myserver;\n}\n}\n```\n\n配置完别忘了云服务器安全组放行端口\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SK1xFtIBvqNAiSL/root/content)\n\n\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SOprbqT7ElXlWkr/root/content)\n\n默认访问的是tomcat下的ROOT\n\n如果要访问examples，则在浏览器网址改为：域名/examples\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SSyzfAM5fwc0k4P/root/content)\n\n将root路径删除 打包war  对项目路径做出修改\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SW8n524MNkLf5sP/root/content)\n\n将统一项目名改为空值\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SZQ92E97gxANeqG/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Se6Tu_NgPHNnTCu/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29ShMng_xBpybpgmm/root/content)\n\n打包war包\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SnJoJD1YJ4z9a9S/root/content)\n\n打包名ROOT\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Srr3ZIehsfaCFRB/root/content)\n\n多套配置文件\n\n生产一套\n\n部署一套\n\n将之前开发的appliaction.properties和logback-spring.xml各复制两份\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29StjN37z338B3mba/root/content)\n\n然后载application。properties中定义哪一个配置文件生效\n\n```xml\n# profile\nspring.profiles.active=produce\n\n# logback\nlogging.config=classpath:logback-spring-${spring.profiles.active}.xml\n```\n\n启动文件配置\n\n```\npackage com.nowcoder.community;\n\nimport org.springframework.boot.builder.SpringApplicationBuilder;\nimport org.springframework.boot.web.servlet.support.SpringBootServletInitializer;\n\npublic class CommuntityServletInitializer extends SpringBootServletInitializer {\n    @Override\n    protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {\n        return builder.sources(CommunityApplication.class);\n    }\n}\n```\n\n清除target 文件包小\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29SzrS9HN933SECV9/root/content)\n\n找到项目位置并打包上传到服务器\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29S3biRt0YzINTSjL/root/content)\n\n\n\n\n\nstartup.sh  \n\n然后访问主页\n\n","tags":["linux","aliyun","project"],"categories":["项目"]},{"title":"线上kafka问题Timeout","url":"/2021/09/07/线上kafka问题Timeout/","content":"\n## 问题解决\n\nkafka 版本2.13-2.8.0\n\n今天查看论坛项目，发现点赞和回复的时候出现502服务器问题。\n\n仔细查看发现点赞和回复数据库操作能成功，但是并没有触发Kafka producer发送消息，windows本地部署是成功的，代码层面没有问题。\n\n查看项目日志cd /tmp/community   \n\nvim log_error.log发现\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29mTbThREkZZix3a_/root/content)\n\n发送消息代码\n\n```\npublic String addComment(@PathVariable(\"discussPostId\")int discussPostId, Comment comment){\n        //添加评论\n        comment.setUserId(hostHolder.getUser().getId());\n        comment.setStatus(0);\n        comment.setCreateTime(new Date());\n        commentService.addComment(comment);\n\n\n//触发评论事件\n        Event event = new Event()\n                .setTopic(TOPIC_COMMENT)\n                .setUserId(hostHolder.getUser().getId())\n                .setEntityType(comment.getEntityType())\n                .setEntityId(comment.getEntityId())\n                .setData(\"postId\",discussPostId);\n\n        if (comment.getEntityType()== ENTITY_TYPE_POST){\n            DiscussPost target = discussPostService.findDiscussPostById(comment.getEntityId());\n            event.setEntityUserId(target.getUserId())\n                    .setData(\"sortNo\",comment.getId());\n        }\n        eventProducer.fireEvent(event);\n}\n```\n\n写入评论成功，但是eventProducer.fireEvent(event)执行失败，应该是kafka和zookeeper连接问题。\n\nconfig/server.config有如下描述：\n\n> \\# The address the socket server listens on. It will get the value returned from \n>\n> \\# java.net.InetAddress.getCanonicalHostName() if not configured.\n>\n> \\# FORMAT:\n>\n> \\#  listeners = listener_name://host_name:port\n>\n> \\# EXAMPLE:\n>\n> \\#  listeners = PLAINTEXT://your.host.name:9092\n>\n> \\#listeners=PLAINTEXT://:9092\n\n将#listeners=PLAINTEXT://:9092,改成\n\n> listeners=PLAINTEXT://localhost:9092\n\n重启kafaka,再次尝试写消息，成功了。\n\n## kafka常用操作\n\n### 安装\n\nhttps://www.cnblogs.com/miamianfighting/p/14087091.html\n\n### 启动\n\ncd /opt/kafka\n\n```\nbin/zookeeper-server-start.sh -daemon config/zookeeper.properties\n\nnohup bin/kafka-server-start.sh config/server.properties 1>/dev/null 2>&1 &  //后台启动zookeeper和kafka\n```\n\n### 查看kafka进程\n\n```\nps -ef|grep kafka\n```\n\n### 创建topic\n\n```\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic my_topic\n```\n\n### 查看topic\n\n```\nbin/kafka-topics.sh --list --zookeeper localhost:2181\n```\n\n### 生产者\n\n```\nbin/kafka-console-producer.sh --broker-list 192.168.38.131:9092 --topic my_topic\n```\n\n### 消费者\n\n```\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.38.131:9092 --topic my_topic \n```\n","tags":["tool","kafka","problem"],"categories":["项目"]},{"title":"使用coding CI服务实现hexo自动化发布部署","url":"/2021/09/01/使用coding CI服务实现hexo自动化发布部署/","content":"\n# 引言\n\nhexo是一个操作简单方便的静态网页式博客，但是这也带来了几个问题。\n\n- 每次`hexo new post \"\"`写作好以后，都要进行生成网页部署网页的操作，这种重复操作是程序员极为讨厌的行为。\n- 同样，每次想要在新的设备上写作就更加麻烦，新设备上要和原设备上有一样的环境，重新配置环境的时候还有可能出现各种问题。花费了一段时间配好环境，开始写作了，又要经历上一个问题。\n\n而各家的持续集成服务就能解决这样的问题，这里推荐coding的CI服务，每个月有1000次的免费持续集成次数，而且提供的服务器配置也很可以了。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VU3qY_5Un28Ajdj/root/content)\n\n下面介绍一些基本概念，不需要的朋友可以直接向下调到教程。\n\n# 基本概念\n\n## 持续集成\n\n在软件工程中，持续集成（CI）是指将所有开发者的工作副本每天多次合并到主干的做法。持续集成在现代软件研发流程中，扮演了十分重要的角色。通过对每次提交的代码进行自动化的单元测试、代码检查、编译构建、契约测试，甚至自动部署，能够大大降低了开发人员的工作负担，减少了许多不必要的重复劳动，持续提升代码质量和开发效率。毫无疑问，持续集成是开发者和研发团队的福音。\n\n持续集成是指软件发布流程的构建和单元测试阶段。提交的每一个修订都会触发自动化的构建和测试操作。\n\n采用[持续交付](https://aws.amazon.com/cn/devops/continuous-delivery/)时，系统会自动构建、测试并准备代码变更，以便发布到生产环境中。持续交付通过在构建阶段后将所有代码变更部署到测试环境和/或生产环境中，实现对持续集成的扩展。\n\n当然我们想要实现自动部署并不需要完整的持续集成功能，只需要自动构建。\n\n## Jenkins\n\nJenkins 是一个开源软件项目，是基于 Java 开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。\n\n没错，它就是一个具体的持续集成解决方案。基于 Java 实现。 可以实现：\n\n1. 持续版本发布/测试；\n2. 监控外部调用执行的工作；\n\n# 教程\n\n## 工具\n\n1. 能够正常发布使用的hexo本地项目。\n2. coding账户\n3. Git\n\n## coding访问令牌\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Vbp_Rej8lA87Vvp/root/content)\n\n新建访问令牌\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Vfoo1OCCjuuJ2xn/root/content)\n\n保存好令牌和用户名备用。\n\n## coding项目\n\n本项目中需要一个git仓库，可以使用github||gitee||coding。建议使用coding，因为是采用的coding的集成服务，同平台稳定性高一些。\n\n首先直接创建一个全功能DevOps项目。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Viw44joEveG6NbD/root/content)\n\n进入项目\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Vk3MMRsfrRuNG-3/root/content)\n\n进入代码仓库，新建一个仓库，因为里面会有配置文件，含有密码等敏感信息，请选择私有仓库。\n\n创建完成后本地文件夹绑定远程仓库。\n\n```\ngit remote set-url origin https://e.coding.net/仓库地址.git\n```\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VprZXjOY_dwW_9i/root/content)\n\n本地hexo目录，编辑——config.yml配置文件。找到deploy\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Vsy3p2dQ5xQBLti/root/content)\n\n采用coding 免费CI构建部署时候每次都是一个新的环境，相当于新的设备，每次都要输入凭证才可以成功部署。我是同时部署在github和gitee，格式为：\n\n```\n github: https://username:token@github.com/项目地址.git\n gitee: https://用户名:密码@gitee.com/项目地址.git\n```\n\ngithub需要采用用户名加token的方式访问，不要使用密码！不要使用密码！会构建失败！\n\n### 获取token\n\n在https://github.com登录你的帐号，登录以后点击右上角你的头像的Settings\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29Vyxwy2n0RbzsdAK/root/content)\n\n2、 点击Developer settings下的Personal access tokens\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29V2U_bRddj1_cs1q/root/content)\n\n3、点击https://github.com/settings/tokens/new这个超链接，就是创建你的token。\n\n!![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29V4tTyGS6fFDkHBJ/root/content)\n\n4、在Token description中随便填一个描述名称，下面的复选框是你这个token需要的权限，全部勾上就可以了。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29V-7kAJBkvBPH6m2/root/content)\n\n然后点击下面这个绿色的按钮：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WDe8061HpMLmCaT/root/content)\n\n5、下面这个就是你的token了，可以直接复制使用。将其填入配置文件。\n\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WHFpK3ICtyWV8Rv/root/content)\n\n## 配置持续集成\n\n进入coding项目选择持续集成--构建计划--创建构建计划\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WJa2YrVolLg-zO_/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WOv-k2e9fNvyg4w/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WR83hFKnGmy4xGs/root/content)\n\n上文提到的仓库是新建了coding仓库，在代码仓库中选择你创建的仓库，如果你是放在githu或者其他仓库服务，请选择相应的仓库并授权。之后点击确定。\n\n之后在流程设置中进行设置。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WVC0V5czptZfjHZ/root/content)\n\n下面贴上代码\n\n```\npipeline {\n    agent any\n    stages  {\n       stage(\"pull\") {\n            steps {\n               sh 'ls'\n              sh 'git config --global user.name \"username\"'  \n             sh 'git config --global user.email \"email\"'\n              sh 'ls'\n              sh 'git clone https://用户名:令牌@e.coding.net/仓库地址.git .'//输入上面提到的coding用户名和令牌\n            }\n        \n        }\n        stage(\"hexo\")\n         {\n           steps\n           {\n              sh 'npm install -g hexo-cli'  \n              sh 'npm install hexo --save'\n              //如果你的hexo项目有其他特别功能需要的服务，可以在此添加相应指令\n           }\n         }\n         stage(\"发布\")\n         {\n             steps\n           {\n           sh 'hexo cl'  //hexo clean\n           sh 'hexo g'  //hexo generate\n           \n           sh 'hexo d'  //hexo deploy\n           }\n         }\n        \n    }\n}\n```\n\n\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29WZ2nB-Itjh-A3bg/root/content)\n\n开启缓存，加快部署速度。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29W3QgSMazHvn3V1l/root/content)\n\n之后就可以构建了，确认上述操作无误后。点击保存。\n\n\n\n## 自动部署\n\n将hexo本地项目git push到你绑定的的仓库，coding就会自动帮你构建啦。\n\n成功截图。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29W7qbi9YcW5TzN_d/root/content)\n\n# 常见问题\n\n1.\n\nfatal: unable to access 'https://-----@github.com/----.git/': Failed to connect to  port 443: Connection timed out\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29W_22XZCZiYQNEkb/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29XCPcX9ipQ21MqyX/root/content)\n\n一般是config文件中部署设置的用户名或密码错误。\n\n2.fatal: could not read Username for '[https://gitee.com](https://gitee.com/)': No such device or address\n\n同上 用户名错误\n\n3.!![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29XGCtK64F8MTW7An/root/content)\n\n将config中highlight enable改为false\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29XJusC-zdtbc8Kut/root/content)\n\n如有疑问欢迎与我沟通。\n\n我的博客：\n\nhttps://brook2bubble.gitee.io/\n\nhttps://brookdeng.github.io/\n\n# 多端协作\n\n关于多端写作，网上有Hexo同步语雀文章，感兴趣的可以搜一搜看一看，但是这样的方法会导致每次写作都要使用语雀来写作，配置起来也更加麻烦。\n\n### 常用电脑\n\n写作后直接push到仓库\n\n### 其他电脑\n\n编辑md文档后，上传到仓库_post文件夹。注意文档格式。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29XNLGVt9_T3YojyG/root/content)\n\nmd文档头文件\n\n```\n---\ntitle: 使用coding CI服务实现hexo自动化发布部署\ndate: yyyy-MM-dd HH:mm:ss\ncategories: [Hexo]\ntags: [CI,Coding,hexo,git]\n\n---\n```\n\n### 手机端\n\n同上，比较麻烦，不过也很少有手机写博客的吧。\n\n> # 参考\n>\n> 1. [持续集成介绍](https://help.coding.net/docs/ci/intro.html)\n> 2. [hexo利用coding自动化持续集成云端部署多平台](http://www.misaka10013.cn/p/1967088261.html)\n> 3. [Hexo+coding实现自动化部署](https://www.cnblogs.com/antmoe/p/12287711.html)","tags":["hexo","CI","Coding","git"],"categories":["Hexo"]},{"title":"FactoryBean和BeanFactory的区别","url":"/2021/08/20/FactoryBean和BeanFactory的区别/","content":"\n# BeanFactory、FactoryBean和ObjectFactory\n\n- BeanFactory就是对象工厂，用于实例化和保存对象。\n- FactoryBean是一个工厂对象，用于实例化创建过程比较复杂的对象。\n- ObjectFactory是某个特定的工厂，用于在项目启动时，延迟实例化对象，解决循环依赖问题。\n\n## BeanFactory\n\n是一个接口，`public interface BeanFactory`，提供如下方法：\n\n- `Object getBean(String name)`\n- `<T> T getBean(String name, Class<T> requiredType)`\n- `<T> T getBean(Class<T> requiredType)`\n- `Object getBean(String name, Object... args)`\n- `boolean containsBean(String name)`\n- `boolean isSingleton(String name)`\n- `boolean isPrototype(String name)`\n- `boolean isTypeMatch(String name, Class<?> targetType)`\n- `Class<?> getType(String name)`\n- `String[] getAliases(String name)`\n\n在 Spring 中，`BeanFactory`是 IoC 容器的核心接口。它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。\n\n`BeanFactory` 提供的高级配置机制，使得管理任何性质的对象成为可能。\n `ApplicationContext` 是 `BeanFactory` 的扩展，功能得到了进一步增强，比如更易与 Spring AOP 集成、消息资源处理(国际化处理)、事件传递及各种不同应用层的 context 实现(如针对 web 应用的`WebApplicationContext`)。\n\n用的比较多的 `BeanFactory` 的子类是 `ClassPathXmlApplicationContext`，这是   `ApplicationContext`接口的一个子类，`ClassPathXmlApplicationContext`从 xml 的配置文件中获取 bean 并且管理他们，例如：\n\n```java\npublic static void main(String[] args) throws Exception {\n    BeanFactory bf = new ClassPathXmlApplicationContext(\"student.xml\");\n    Student studentBean = (Student) bf.getBean(\"studentBean\");\n    studentBean.print();\n}\n```\n\nXML配置如下：\n\n```jsx\n<bean id=\"studentBean\" class=\"advanced.Student\">\n    <property name=\"name\" value=\"Tom\"/>\n    <property name=\"age\" value=\"18\"/>\n</bean>\n```\n\n## FactoryBean\n\nSpring 中为我们提供了两种类型的 bean，一种就是普通的 bean，我们通过 `getBean(id)` 方法获得是该 bean 的实际类型，另外还有一种 bean 是 `FactoryBean`，也就是工厂 bean，我们通过 `getBean(id)` 获得是该工厂所产生的 Bean 的实例，而不是该 `FactoryBean` 的实例。\n\n`FactoryBean` 从名字上能看出这是一个Bean。Bean就是Spring对对象的一种定义，一个Bean就是一个或者一些同类型的对象。\nFactoryBean是一个接口。\n\n实现了 `FactoryBean` 接口的类有能力改变 bean，`FactoryBean` 希望你实现了它之后返回一些内容，Spring 会按照这些内容去注册 bean。\n `public interface FactoryBean<T>`，提供如下方法：\n\n```java\npublic interface FactoryBean<T> {\n\n    //返回的对象实例\n    T getObject() throws Exception;\n    //Bean的类型\n    Class<?> getObjectType();\n    //true是单例，false是非单例  在Spring5.0中此方法利用了JDK1.8的新特性变成了default方法，返回true\n    boolean isSingleton();\n}\n```\n\n `getObject`用来返回实例化后的对象。\n `getObjectType`用来返回对象的类型。\n `isSingleton`用来标识对象是否为单例的，这里默认为true，Spring会将实例化后的对象放入BeanFactory容器中。\n\n通常情况下，bean 无须自己实现工厂模式，Spring 容器担任工厂 角色；但少数情况下，容器中的 bean 本身就是工厂，作用是产生其他 bean 实例。由工厂 bean 产生的其他 bean 实例，不再由 Spring 容器产生，因此与普通 bean 的配置不同，不再需要提供 class 元素。\n\n凡是实现了FactoryBean接口的类，负责返回这个java类的实例化对象。\n从设计模式的角度来看这就是典型的工厂方法模式。由一个特定的工厂来生产特定的java类的实例化对象。\n\n那么这种写法有哪些好处呢？\n 正常情况下，Spring中在实例化对象的时候，都是由BeanFactory从上下文中获取BeanDefinition信息，然后通过反射，调用这个java类的构造方法进行实例化。而现在这种形式，我们相当于将实例化的功能交给了FactoryBean去实现。这种方式主要使用在一些比较复杂的实例化过程中，并非简单地设置一些参数或者设置的参数过多，过程中可能需要做一些复杂的解析、判断和逻辑处理，这个时候交由Spring去通过反射进行实例化可能就不太灵活了，\n\nSpring容器中有两种Bean，一种是普通的Bean对象，一种是实现了FactoryBean的工厂Bean对象。如果从BeanFactory中getBean的时候，获取到的Bean对象是工厂Bean，会自动的调用它的getObject方法返回真实实例化对象。\n 如果就是需要获取FactoryBean对象，需要在getBean的时候加上前缀'&'。\n\nSpring自身就对FactoryBean有70多种实现，比较常见的就是Proxy，Jndi等场景。AOP中使用的ProxyFactoryBean。\n Dubbo中使用的ReferenceBean。\n Mybatis中使用的SqlSessionFactoryBean。\n\n示例：\n 构造一个 `FactoryBean` 的实现：\n\n```java\npublic class StudentFactoryBean implements FactoryBean<Student> {\n    private String name;\n    private int age;\n    @Override\n    public Student getObject() throws Exception {\n        return new Student(name, age);\n    }\n    @Override\n    public Class<?> getObjectType() {\n        return Student.class;\n    }\n    /**\n     * 工厂所管理的对象是否为单例的\n     * 即如果该方法返回true，那么通过getObject()方法返回的对象都是同一个对象\n     */\n    @Override\n    public boolean isSingleton() {\n        return true;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n}\n```\n\nXML配置如下：\n\n```jsx\n<bean id=\"studentFactoryBean\" class=\"spring.StudentFactoryBean\">\n    <property name=\"name\" value=\"Tom\"/>\n    <property name=\"age\" value=\"28\"/>\n</bean>\n```\n\n使用：\n\n```java\npublic static void main(String[] args) throws Exception {\n    BeanFactory bf = new ClassPathXmlApplicationContext(\"student.xml\");\n    Student studentBean = (Student) bf.getBean(\"studentFactoryBean\");\n\n    studentBean.print();\n}\n```\n\n## ObjectFactory\n\n```java\npublic interface ObjectFactory<T> {\n\n    //返回的对象实例\n    T getObject() throws BeansException;\n}\n```\n\n这用于延迟查找的场景，它就是一个普通工厂，当得到 ObjectFactory 对象时，相当于 Bean 没有被创建，只有当 getObject() 方法时，才会触发 Bean 实例化等生命周期。\n 主要用于暂时性地获取某个 Bean Holder 对象，如果过早的加载，可能会引起一些意外的情况，比如当 Bean A 依赖 Bean B 时，如果过早地初始化 A，那么 B 里面的状态可能是中间状态，这时候使用 A 容易导致一些错误。\n\n\n\n> \n>\n> 引用：\n> https://www.jianshu.com/p/05c909c9beb0\n>\n> https://www.jianshu.com/p/a2807797fed0\n","tags":["Spring","BeanFactory"],"categories":["Spring"]},{"title":"正则表达式","url":"/2021/08/19/正则表达式/","content":"\n\\b代表着单词的开头或结尾，也就是单词的分界处。\n\n.是另一个元字符，匹配除了换行符以外的任意字符。\n\n**同样是元字符，不过它代表的不是字符，也不是位置，而是数量——它指定*前边的内容可以连续重复使用任意次以使整个表达式得到匹配。因此，.*连在一起就意味着任意数量的不包含换行的字符。\n\n\\d是个新的元字符，匹配一位数字(0，或1，或2，或……)。\n\n0\\d{2}-\\d{8}。这里\\d后面的{2}({8})的意思是前面\\d必须连续重复匹配2次(8次)。\n\n| 代码     |                    说明                    |\n| :------- | :----------------------------------------: |\n| .        |         匹配除换行符以外的任意字符         |\n| \\w       |        匹配字母或数字或下划线或汉字        |\n| \\s       |              匹配任意的空白符              |\n| \\d       |                  匹配数字                  |\n| \\b       |            匹配单词的开始或结束            |\n| ^        |              匹配字符串的开始              |\n| $        |              匹配字符串的结束              |\n| *        |              重复零次或更多次              |\n| +        |              重复一次或更多次              |\n| ?        |               重复零次或一次               |\n| {n}      |                  重复n次                   |\n| {n,}     |              重复n次或更多次               |\n| {n,m}    |                 重复n到m次                 |\n| \\W       | 匹配任意不是字母，数字，下划线，汉字的字符 |\n| \\S       |          匹配任意不是空白符的字符          |\n| \\D       |            匹配任意非数字的字符            |\n| \\B       |        匹配不是单词开头或结束的位置        |\n| [^x]     |          匹配除了x以外的任意字符           |\n| [^aeiou] |   匹配除了aeiou这几个字母以外的任意字符    |\n|          |                                            |\n|          |                                            |\n|          |                                            |\n|          |                                            |\n|          |                                            |\n\n| 分类         | 代码/语法                                                    | 说明                                                         |\n| :----------- | :----------------------------------------------------------- | :----------------------------------------------------------- |\n| 捕获         | (exp)                                                        | 匹配exp,并捕获文本到自动命名的组里                           |\n| (?<name>exp) | 匹配exp,并捕获文本到名称为name的组里，也可以写成(?'name'exp) |                                                              |\n| (?:exp)      | 匹配exp,不捕获匹配的文本，也不给此分组分配组号               |                                                              |\n| 零宽断言     | (?=exp)                                                      | 匹配exp前面的位置                                            |\n| (?<=exp)     | 匹配exp后面的位置                                            |                                                              |\n| (?!exp)      | 匹配后面跟的不是exp的位置                                    |                                                              |\n| (?<!exp)     | 匹配前面不是exp的位置                                        |                                                              |\n| 注释         | (?#comment)                                                  | 这种类型的分组不对正则表达式的处理产生任何影响，用于提供注释让人阅读 |\n\n常用正则表达式\n\n## 一、校验数字的表达式\n\n- 数字：**^[0-9]\\*$**\n- n位的数字：**^\\d{n}$**\n- 至少n位的数字**：^\\d{n,}$**\n- m-n位的数字：**^\\d{m,n}$**\n- 零和非零开头的数字：**^(0|[1-9][0-9]\\*)$**\n- 非零开头的最多带两位小数的数字：**^([1-9][0-9]\\*)+(\\.[0-9]{1,2})?$**\n- 带1-2位小数的正数或负数：**^(\\-)?\\d+(\\.\\d{1,2})$**\n- 正数、负数、和小数：**^(\\-|\\+)?\\d+(\\.\\d+)?$**\n- 有两位小数的正实数：**^[0-9]+(\\.[0-9]{2})?$**\n- 有1~3位小数的正实数：**^[0-9]+(\\.[0-9]{1,3})?$**\n- 非零的正整数：**^[1-9]\\d\\*$ 或 ^([1-9][0-9]\\*){1,3}$ 或 ^\\+?[1-9][0-9]\\*$**\n- 非零的负整数：**^\\-[1-9][]0-9\"\\*$ 或 ^-[1-9]\\d\\*$**\n- 非负整数：**^\\d+$ 或 ^[1-9]\\d\\*|0$**\n- 非正整数：**^-[1-9]\\d\\*|0$ 或 ^((-\\d+)|(0+))$**\n- 非负浮点数：**^\\d+(\\.\\d+)?$ 或 ^[1-9]\\d\\*\\.\\d\\*|0\\.\\d\\*[1-9]\\d\\*|0?\\.0+|0$**\n- 非正浮点数：**^((-\\d+(\\.\\d+)?)|(0+(\\.0+)?))$ 或 ^(-([1-9]\\d\\*\\.\\d\\*|0\\.\\d\\*[1-9]\\d\\*))|0?\\.0+|0$**\n- 正浮点数：**^[1-9]\\d\\*\\.\\d\\*|0\\.\\d\\*[1-9]\\d\\*$ 或 ^(([0-9]+\\.[0-9]\\*[1-9][0-9]\\*)|([0-9]\\*[1-9][0-9]\\*\\.[0-9]+)|([0-9]\\*[1-9][0-9]\\*))$**\n- 负浮点数：**^-([1-9]\\d\\*\\.\\d\\*|0\\.\\d\\*[1-9]\\d\\*)$ 或 ^(-(([0-9]+\\.[0-9]\\*[1-9][0-9]\\*)|([0-9]\\*[1-9][0-9]\\*\\.[0-9]+)|([0-9]\\*[1-9][0-9]\\*)))$**\n- 浮点数：**^(-?\\d+)(\\.\\d+)?$ 或 ^-?([1-9]\\d\\*\\.\\d\\*|0\\.\\d\\*[1-9]\\d\\*|0?\\.0+|0)$**\n\n------\n\n## 二、校验字符的表达式\n\n- 汉字：**^[\\u4e00-\\u9fa5]{0,}$**\n- 英文和数字：**^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$**\n- 长度为3-20的所有字符：**^.{3,20}$**\n- 由26个英文字母组成的字符串：**^[A-Za-z]+$**\n- 由26个大写英文字母组成的字符串：**^[A-Z]+$**\n- 由26个小写英文字母组成的字符串：**^[a-z]+$**\n- 由数字和26个英文字母组成的字符串：**^[A-Za-z0-9]+$**\n- 由数字、26个英文字母或者下划线组成的字符串：**^\\w+$ 或 ^\\w{3,20}$**\n- 中文、英文、数字包括下划线：**^[\\u4E00-\\u9FA5A-Za-z0-9_]+$**\n- 中文、英文、数字但不包括下划线等符号：**^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$**\n- 可以输入含有^%&',;=?$\\\"等字符：**[^%&',;=?$\\x22]+**\n- 禁止输入含有~的字符：**[^~\\x22]+**\n\n------\n\n## 三、特殊需求表达式\n\n- Email地址：**^\\w+([-+.]\\w+)\\*@\\w+([-.]\\w+)\\*\\.\\w+([-.]\\w+)\\*$**\n- 域名：**[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\\.?**\n- InternetURL：**[a-zA-z]+://[^\\s]\\* 或 ^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]\\*)?$**\n- 手机号码：**^(13[0-9]|14[5|7]|15[0|1|2|3|4|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d{8}$**\n- 电话号码(\"XXX-XXXXXXX\"、\"XXXX-XXXXXXXX\"、\"XXX-XXXXXXX\"、\"XXX-XXXXXXXX\"、\"XXXXXXX\"和\"XXXXXXXX)：**^(\\(\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$**\n- 国内电话号码(0511-4405222、021-87888822)：**\\d{3}-\\d{8}|\\d{4}-\\d{7}**\n- 电话号码正则表达式（支持手机号码，3-4位区号，7-8位直播号码，1－4位分机号）: **((\\d{11})|^((\\d{7,8})|(\\d{4}|\\d{3})-(\\d{7,8})|(\\d{4}|\\d{3})-(\\d{7,8})-(\\d{4}|\\d{3}|\\d{2}|\\d{1})|(\\d{7,8})-(\\d{4}|\\d{3}|\\d{2}|\\d{1}))$)**\n- 身份证号(15位、18位数字)，最后一位是校验位，可能为数字或字符X：**(^\\d{15}$)|(^\\d{18}$)|(^\\d{17}(\\d|X|x)$)**\n- 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：**^[a-zA-Z][a-zA-Z0-9_]{4,15}$**\n- 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：**^[a-zA-Z]\\w{5,17}$**\n- 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在 8-10 之间)：**^(?=.\\*\\d)(?=.\\*[a-z])(?=.\\*[A-Z])[a-zA-Z0-9]{8,10}$**\n- 强密码(必须包含大小写字母和数字的组合，可以使用特殊字符，长度在8-10之间)：**^(?=.\\*\\d)(?=.\\*[a-z])(?=.\\*[A-Z]).{8,10}$**\n- 日期格式：**^\\d{4}-\\d{1,2}-\\d{1,2}**\n- 一年的12个月(01～09和1～12)：**^(0?[1-9]|1[0-2])$**\n- 一个月的31天(01～09和1～31)：**^((0?[1-9])|((1|2)[0-9])|30|31)$**\n- 钱的输入格式：\n  1. 有四种钱的表示形式我们可以接受:\"10000.00\" 和 \"10,000.00\", 和没有 \"分\" 的 \"10000\" 和 \"10,000\"：**^[1-9][0-9]\\*$**\n  2. 这表示任意一个不以0开头的数字,但是,这也意味着一个字符\"0\"不通过,所以我们采用下面的形式：**^(0|[1-9][0-9]\\*)$**\n  3. 一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：**^(0|-?[1-9][0-9]\\*)$**\n  4. 这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧。下面我们要加的是说明可能的小数部分：**^[0-9]+(.[0-9]+)?$**\n  5. 必须说明的是,小数点后面至少应该有1位数,所以\"10.\"是不通过的,但是 \"10\" 和 \"10.2\" 是通过的：**^[0-9]+(.[0-9]{2})?$**\n  6. 这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：**^[0-9]+(.[0-9]{1,2})?$**\n  7. 这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：**^[0-9]{1,3}(,[0-9]{3})\\*(.[0-9]{1,2})?$**\n  8. 1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：**^([0-9]+|[0-9]{1,3}(,[0-9]{3})\\*)(.[0-9]{1,2})?$**\n  9. 备注：这就是最终结果了,别忘了\"+\"可以用\"*\"替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里\n- xml文件：**^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\\\.[x|X][m|M][l|L]$**\n- 中文字符的正则表达式：**[\\u4e00-\\u9fa5]**\n- 双字节字符：**[^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))**\n- 空白行的正则表达式：**\\n\\s\\*\\r (可以用来删除空白行)**\n- HTML标记的正则表达式：**<(\\S\\*?)[^>]\\*>.\\*?|<.\\*? /> ( 首尾空白字符的正则表达式：^\\s\\*|\\s\\*$或(^\\s\\*)|(\\s\\*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)**\n- 腾讯QQ号：**[1-9][0-9]{4,} (腾讯QQ号从10000开始)**\n- 中国邮政编码：**[1-9]\\d{5}(?!\\d) (中国邮政编码为6位数字)**\n- IPv4地址：**((2(5[0-5]|[0-4]\\d))|[0-1]?\\d{1,2})(\\.((2(5[0-5]|[0-4]\\d))|[0-1]?\\d{1,2})){3}**\n","tags":["tool","learn","正则表达式"],"categories":["Java"]},{"title":"任务执行和调度","url":"/2021/08/19/任务执行和调度/","content":"\n任务调度组件基于多线程，但凡用多线程，一定会用到线程池，因为创建线程是有开销的，且开销较大。使用线程池来管理线程，能够让线程复用，提高处理能力，节约资源。\n\n## 线程池思想概述\n\n我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题：\n\n如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。\n\n那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？\n\n在Java中可以通过线程池来达到这样的效果。\n\n## 线程池概念\n\n* **线程池：**其实就是一个容纳多个线程的容器，其中的线程可以反复使用，省去了频繁创建线程对象的操作，无需反复创建线程而消耗过多资源。\n\n​    线程池的工作原理：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UAjQlROOYSJDFl5/root/content)\n\n合理利用线程池能够带来三个好处：\n\n1. 降低资源消耗。减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。\n2. 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。\n3. 提高线程的可管理性。可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。\n\n## 线程池的使用\n\nJava里面线程池的顶级接口是`java.util.concurrent.Executor`，但是严格意义上讲`Executor`并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是`java.util.concurrent.ExecutorService`。\n\n要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在`java.util.concurrent.Executors`线程工厂类里面提供了一些静态工厂，生成一些常用的线程池。官方建议使用Executors工程类来创建线程池对象。\n\nExecutors类中有个创建线程池的方法如下：\n\n* `public static ExecutorService newFixedThreadPool(int nThreads)`：返回线程池对象。(创建的是有界线程池,也就是池中的线程个数可以指定最大数量)\n\n获取到了一个线程池ExecutorService 对象，那么怎么使用呢，在这里定义了一个使用线程池对象的方法如下：\n\n* `public Future<?> submit(Runnable task)`:获取线程池中的某一个线程对象，并执行\n\n  > Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用。\n\n使用线程池中线程对象的步骤：\n\n1. 创建线程池对象。\n2. 创建Runnable接口子类对象。(task)\n3. 提交Runnable接口子类对象。(take task)\n4. 关闭线程池(一般不做)。\n\n## JDK线程池\n\n```Java\npublic class ThreadPoolTest {\n    private static final Logger logger = LoggerFactory.getLogger(ThreadPoolTest.class);\n    // JDK普通线程池\n    private ExecutorService executorService = Executors.newFixedThreadPool(5);//通过工厂Executors来实例化，实例化后包含五个线程，反复复用这五个线程\n    // JDK可执行定时任务的线程池\n    private ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5);\n    // Spring普通线程池\n    @Autowired\n    private ThreadPoolTaskExecutor taskExecutor;\n    // Spring可执行定时任务的线程池\n    @Autowired\n    private ThreadPoolTaskScheduler taskScheduler;\n    @Autowired\n    private AlphaService alphaService;\n    \n   /* ThreadPoolTest是junit测试方法，其和main方法不一样，如果在main方法里启动线程，该线程不挂掉的话，\n   main会挡着ThreadPoolTest执行，使得main会挡着ThreadPoolTest执行，不会立刻结束。\n    但是junit测试方法 每启动一个子线程，和当前线程是并发的，如果test方法没有逻辑，立刻就结束了，不管启动的线程有没有完成。\n    因此当test方法启动完一个线程以后，等其执行完以后在关闭线程。则让当前主线程sleep（阻塞）一会儿*/\n   private void sleep(long m) {//m单位是毫秒\n       try {\n           Thread.sleep(m);//当前线程阻塞\n       } catch (InterruptedException e) {\n           e.printStackTrace();\n       }\n   }\n\n}\n```\n\n### ExecutorService\n\n```java\n// 1.JDK普通线程池\n@Test\npublic void testExecutorService() {//需要给线程池一个任务 来使得线程池 分配一个线程去执行。任务即是线程体。\n    Runnable task = new Runnable() {\n        @Override\n        public void run() {\n            logger.debug(\"Hello ExecutorService\");\n        }\n    };\n\n    for (int i = 0; i < 10; i++) {//执行10次\n        executorService.submit(task);//每调用一个submit方法，线程池都会给其分配一个线程以执行线程体。\n    }\n\n    sleep(10000);//不然，线程还没执行完，方法就结束了。1w毫秒就是10s\n}\n```\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UH5olRNXh6dQqQw/root/content)\n\n### ScheduledExecutorService\n\n```java\n// 2.JDK定时任务线程池（设置时间间隔不断执行，要提供一个线程体）\n@Test\npublic void testScheduledExecutorService() {\n    Runnable task = new Runnable() {\n        @Override\n        public void run() {\n            logger.debug(\"Hello ScheduledExecutorService\");\n        }\n    };\n\n    scheduledExecutorService.scheduleAtFixedRate(task, 10000, 1000, TimeUnit.MILLISECONDS);\n    //第一个参数是任务。第二个参数是该任务延迟多少ms才执行。第三个参数是时间间隔ms，第三个参数是声明时间单位TimeUnit.MILLISECONDS\n\n    sleep(30000);\n}\n```\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UIhyBroVAOfMX2N/root/content)\n\n## Spring线程池\n\n在application properties中增加\n\n```xml\n# TaskExecutionProperties spring普通线程池的配置\n# 线程池中有几个核心线程\nspring.task.execution.pool.core-size=5\n# 当核心线程不够用，最多扩展到15个\nspring.task.execution.pool.max-size=15\n#queue-capacity指队列容量，当15个线程还是不够用，需要将其放在队列中等候。设置队列能缓冲一百个任务\nspring.task.execution.pool.queue-capacity=100\n\n# TaskSchedulingProperties spring能启动定时任务的线程池的配置\nspring.task.scheduling.pool.size=5\n```\n\n### ThreadPoolTaskExecutor\n\n```java\n// Spring普通线程池\n@Autowired\nprivate ThreadPoolTaskExecutor taskExecutor;\n// 3.Spring普通线程池\n@Test\npublic void testThreadPoolTaskExecutor() {\n    Runnable task = new Runnable() {//声明线程体\n        @Override\n        public void run() {\n            logger.debug(\"Hello ThreadPoolTaskExecutor\");\n        }\n    };\n\n    for (int i = 0; i < 10; i++) {\n        taskExecutor.submit(task);\n    }\n\n    sleep(10000);\n}\n```\n\n执行的时候会报错\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UN7bZ2z1ygRZgK9/root/content)\n\n```\n@Configuration\n@EnableScheduling\n//如果不加EnableScheduling，则表明定时任务没有开启\n\n@EnableAsync//使AlphaService中的@Async注解生效\npublic class ThreadPoolConfig {\n}\n```\n\n执行结果：![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29USWCgTlEPXs4k1r/root/content)\n\n**Spring普通线程池 比jdk线程池更灵活，因为可以设置 核心线程个数，扩展线程个数**\n\n### ThreadPoolTaskScheduler\n\n```java\n// Spring可执行定时任务的线程池\n//@Autowired\n//private ThreadPoolTaskScheduler taskScheduler;\n\n// 4.Spring定时任务线程池\n@Test\npublic void testThreadPoolTaskScheduler() {\n    Runnable task = new Runnable() {\n        @Override\n        public void run() {\n            logger.debug(\"Hello ThreadPoolTaskScheduler\");\n        }\n    };\n\n    Date startTime = new Date(System.currentTimeMillis() + 10000);//当前时间延迟一万毫秒，就是现在的时间\n    taskScheduler.scheduleAtFixedRate(task, startTime, 1000);//以固定频率执行，执行时间间隔\n\n    sleep(30000);//阻塞三十秒\n}\n```\n\n结果：![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UW_b0gq-Vu7aLHf/root/content)\n\njdk线程池是jdk自带的，spring线程池是spring自带的， 其中ExecutorService和ThreadPoolTaskExecutor是普通线程池。\n\nScheduledExecutorService以及ThreadPoolTaskScheduler所创建的线程可以执行定时任务。但是分布式的时候，这俩是有问题的，scheduler不合适，因为scheduler程序运行所依赖的参数都是存在数据库中的，scheduler没有解决分布式的问题。\n比如，每隔十分钟，删掉一个临时文件，两个都会这样做，会产生一定冲突。\njdk和spring的定时任务组件，都是基于内存的，配置多长时间运行一次，配置参数都在内存中，但是服务器1和2内存不共享，不能知道各自正在干嘛，因此会产生一定冲突。因此分布式下用Quartz更多。\n\nQuartz程序运行所依赖的参数都是存在数据库（DB）里面的，因此不管部署多少个Quartz，都会访问同一个数据库。（服务器可以有多个，但是数据库只有一个）。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UanjULNbCoAQXbA/root/content)\n\n浏览器把请求发给Nginx，Nginx依据一定策略，选择服务器对请求进行处理，如果是普通请求，则是分配给controller处理。如果改为Quartz，可以对不同的请求进行排队操作。\n\n## 分布式定时任务\n\n### Spring Quartz\n\nDB有一套表，需要我们提前创建。这个表就是Quartz 所需要的表\n该表即为Quartz依赖的表\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UdF3mPl7u1ywGCP/root/content)\n\n在maven里导入Quartz的包\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UhjBni3rt7-uciA/root/content)\n\n```xml\n <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-quartz</artifactId>\n </dependency>\n```\n\n然后看看源码：\njob、Scheduler、jobdetail（用来配置job）、trigger触发器（设置以什么样的频率反复运行）\n\n通过job接口定义一个任务，通过jobdetail以及trigger接口来配置job，主要做这三个事情。\n配置好，重新启动，Quartz就会重新启动配置信息，并将读到的配置信息存到数据库（表）中，Quartz以后都会读取表中这些信息，来执行任务。\ntrigger第一次启动服务时用，以后就不用了\n通过jobdetail配置的信息，都存到这个表里。\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29UmQrRwDs2RH705b/root/content)\n\n任务的名字\njob的名字\njob的分组\njob的描述\njob对应的类\n…\n\n### QuartzConfig\n\n\n```java\n// 配置（仅在第一次被读取到） -> 信息被初始化到数据库 -> quartz访问数据库去调用该任务，不在访问配置文件\n@Configuration\npublic class QuartzConfig {\n    //FactoryBean和之前一开始学的IOC 学到的 BeanFactory有本质区别；BeanFactory是整个IOC容器的顶层接口\n    // FactoryBean主要目的是 简化Bean的实例化过程，因为有的Bean实例化过程比较复杂:\n    // 1.通过FactoryBean封装Bean的实例化过程.\n    // 2.将FactoryBean装配到Spring容器里.\n    // 3.将FactoryBean注入给其他的Bean.\n    // 4.该Bean得到的是FactoryBean所管理的对象实例.\n// 配置JobDetail\n// @Bean\npublic JobDetailFactoryBean alphaJobDetail() {//Bean的名字是alphaJobDetail。初始化该bean，想当于将其装配到容器中\n    JobDetailFactoryBean factoryBean = new JobDetailFactoryBean();//实例化对象\n    factoryBean.setJobClass(AlphaJob.class);\n    factoryBean.setName(\"alphaJob\");//声明job任务的名字\n    factoryBean.setGroup(\"alphaJobGroup\");//声明任务的组\n    factoryBean.setDurability(true);//声明任务是否长久保存，哪怕任务不再运行。连触发器都没有了，也会一直报存\n    factoryBean.setRequestsRecovery(true);//声明任务是否可恢复\n    return factoryBean;\n}\n\n// 配置Trigger(SimpleTriggerFactoryBean比较简单，每十天要做...； CronTriggerFactoryBean复杂，每个月月底前两天要做...)\n// @Bean\npublic SimpleTriggerFactoryBean alphaTrigger(JobDetail alphaJobDetail) {//Trigger依赖于JobDetail，因此需要读取\n    SimpleTriggerFactoryBean factoryBean = new SimpleTriggerFactoryBean();\n    factoryBean.setJobDetail(alphaJobDetail);\n    factoryBean.setName(\"alphaTrigger\");\n    factoryBean.setGroup(\"alphaTriggerGroup\");\n    factoryBean.setRepeatInterval(3000);//多长时间执行一次任务\n    factoryBean.setJobDataMap(new JobDataMap());//Trigger底层需要存储一些状态，新建JobDataMap对象来存储\n    return factoryBean;\n}\n```\n\n测试：![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VAFa8eYLWbJCLyJ/root/content)\n\nQuartz底层也依赖于线程池，线程池有一默认配置，如果想重新配置底层线程池，需要在application properties中进行配置。\n\n```c\n# QuartzProperties\nspring.quartz.job-store-type=jdbc//任务用jdbc来存储\nspring.quartz.scheduler-name=communityScheduler//调度器的名字\nspring.quartz.properties.org.quartz.scheduler.instanceId=AUTO//调度器的id 自动生成\nspring.quartz.properties.org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX\nspring.quartz.properties.org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate//驱动StdJDBCDelegate\nspring.quartz.properties.org.quartz.jobStore.isClustered=true//是否采用集群方式，是\nspring.quartz.properties.org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool//用org.quartz.simpl.SimpleThreadPool线程池\nspring.quartz.properties.org.quartz.threadPool.threadCount=5//线程数量\n```\n\n做了如上配置以后，\n表里出现了如下信息：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VH7JbtJ1b_m7xBv/root/content)\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VIB-YTAd8pUQtyS/root/content)\n\n新建QuartzTests\n\n    @RunWith(SpringRunner.class)\n    @SpringBootTest\n    @ContextConfiguration(classes = CommunityApplication.class)\n    public class QuartzTests {\n    @Autowired\n    private Scheduler scheduler;\n    \n    @Test\n    public void testDeleteJob() {\n        try {\n            boolean result = scheduler.deleteJob(new JobKey(\"alphaJob\", \"alphaJobGroup\"));\n            System.out.println(result);\n        } catch (SchedulerException e) {\n            e.printStackTrace();\n        }\n    }\n    }\n\n返回true\n确实删除了\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VMSEVKpwBrm5h7u/root/content)\n这里面存着不是job，而是scheduler，所以东西还在\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29VT4CNbMlAlcQ5ox/root/content)\n","tags":["Quartz","线程池"]},{"title":"github hexo搭建博客","url":"/2021/08/19/github-hexo搭建博客/","content":"\n## 初始化\n\n在电脑的某个地方新建一个名为hexo的文件夹（名字可以随便取），比如我的是`F:\\Workspaces\\hexo`，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放。\n\n```bash\n$ cd /f/Workspaces/hexo/\n$ hexo init\n```\n\nhexo会自动下载一些文件到这个目录，包括node_modules，目录结构如下图：\n\n![img](http://image.liuxianan.com/201608/20160818_115922_773_1148.png)\n\n```bash\n$ hexo g # 生成\n$ hexo s # 启动服务\n```\n\n执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：\n\n![img](http://image.liuxianan.com/201608/20160818_120700_028_2426.png)\n\n`hexo s`是开启本地预览服务，打开浏览器访问 [http://localhost:4000](http://localhost:4000/) 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故，因为4000这个端口太常见了，解决端口冲突问题请参考这篇文章：\n\nhttp://blog.liuxianan.com/windows-port-bind.html\n\n## 上传到github\n\n如果你一切都配置好了，发布上传很容易，一句`hexo d`就搞定，当然关键还是你要把所有东西配置好。\n\n首先，`ssh key`肯定要配置好。\n\n其次，配置`_config.yml`中有关deploy的部分：\n\n正确写法：\n\n```\ndeploy:\n  type: git\n  repository: git@github.com:liuxianan/liuxianan.github.io.git\n  branch: master\n```\n\n错误写法：\n\n```\ndeploy:\n  type: github\n  repository: https://github.com/liuxianan/liuxianan.github.io.git\n  branch: master\n```\n\n后面一种写法是hexo2.x的写法，现在已经不行了，无论是哪种写法，此时直接执行`hexo d`的话一般会报如下错误：\n\n```\nDeployer not found: github 或者 Deployer not found: git\n```\n\n原因是还需要安装一个插件：\n\n```\nnpm install hexo-deployer-git --save\n```\n\n其它命令不确定，部署这个命令一定要用git bash，否则会提示`Permission denied (publickey).`\n\n打开你的git bash，输入`hexo d`就会将本次有改动的代码全部提交，没有改动的不会：\n\n## 保留CNAME、README.md等文件\n\n提交之后网页上一看，发现以前其它代码都没了，此时不要慌，一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29mXwhJuiPxza3DOz/root/content)\n\n由于hexo默认会把所有md文件都转换成html，包括README.md，所有需要每次生成之后、上传之前，手动将README.md复制到public目录，并删除README.html。\n\n## 常用hexo命令\n\n常见命令\n\n```\nhexo new \"postName\" #新建文章\nhexo new page \"pageName\" #新建页面\nhexo generate #生成静态页面至public目录\nhexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）\nhexo deploy #部署到GitHub\nhexo help  # 查看帮助\nhexo version  #查看Hexo的版本\n```\n\n缩写：\n\n```\nhexo n == hexo new\nhexo g == hexo generate\nhexo s == hexo server\nhexo d == hexo deploy\n```\n\n组合命令：\n\n```\nhexo s -g #生成并本地预览\nhexo d -g #生成并上传\n```\n\n## _config.yml\n\n这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。\n\n需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。\n\n## 写博客\n\n定位到我们的hexo根目录，执行命令：\n\n```\nhexo new 'my-first-blog'\n```\n\nhexo会帮我们在`_posts`下生成相关md文件：\n\n![img](http://image.liuxianan.com/201608/20160823_183047_352_1475.png)\n\n我们只需要打开这个文件就可以开始写博客了，默认生成如下内容：\n\n![img](http://image.liuxianan.com/201608/20160823_183325_470_9306.png)\n\n当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。\n\n一般完整格式如下：\n\n```markdown\n---\ntitle: postName #文章页面上的显示名称，一般是中文\ndate: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改\ncategories: 默认分类 #分类\ntags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格\ndescription: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面\n---\n\n以下是正文\n```\n\n那么`hexo new page 'postName'`命令和`hexo new 'postName'`有什么区别呢？\n\n```\nhexo new page \"my-second-blog\"\n```\n\n生成如下：\n\n![img](http://image.liuxianan.com/201608/20160823_184852_854_6502.png)\n\n最终部署时生成：`hexo\\public\\my-second-blog\\index.html`，但是它不会作为文章出现在博文目录。\n\n### 何让博文列表不显示全部内容\n\n默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？\n\n答案是在合适的位置加上`<!--more-->`即可，例如：\n\n```markdown\n# 前言\n\n使用github pages服务搭建博客的好处有：\n\n1. 全是静态文件，访问速度快；\n2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；\n3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；\n\n<!--more-->\n\n4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；\n5. 博客内容可以轻松打包、转移、发布到其它平台；\n6. 等等；\n```\n\n最终效果：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TVTEcVa4uR_88G0/root/content)\n\n## 本地调试\n\n```\nhexo server\n```\n\n> 上面命令在cmd命令行执行后，打开http://localhost:4000/，找到刚才编辑的文章，查看无误后执行下一步\n\n## 发布\n\n> 生成静态网页\n\n```\nhexo generate\n```\n\n> 发布网站（推送到github或者gitee）\n\n```\nhexo deploy \n```\n\n> 也可简写为（一起执行上边两个命令）\n\n```\nhexo g -d\n或\nhexo d -g\n```\n\n\n\n> # 参考\n>\n> http://www.cnblogs.com/zhcncn/p/4097881.html\n>\n> http://www.jianshu.com/p/05289a4bc8b2\n","tags":["hexo","blog"],"categories":["Hexo"]},{"title":"图片文件压缩并上传至阿里云OSS","url":"/2021/06/22/图片文件压缩并上传至阿里云OSS/","content":"\n# 图片处理\n\n## Thumbnails\n\n在进行Java开发时可以使用Thumbnails工具类对图片进行处理，旋转、裁剪、格式转换、加水印等。\n\n### 使用步骤\n\n#### 导包\n\n```\n<dependency>\n    <groupId>net.coobird</groupId>\n    <artifactId>thumbnailator</artifactId>\n    <version>0.4.8</version>\n</dependency>\n```\n\n#### 方法\n\n##### 1.读入源图片\n\n能够批量处理，多个文件或者文件夹:\n\n`Thumbnails.of(BufferedImage... images)` 从`BufferedImage`读入源；\n\n`Thumbnails.of(File... files)` 从文件或者文件夹读入源；\n\n`Thumbnails.of(InputStream... inputStreams)` 从流读入源；\n\n`Thumbnails.of(String... files)` \n\n`Thumbnails.of(URL... urls)` \n\n##### 2.设置大小，按比例或者拉伸\n\n`.size(int width, int height)` 按比例，使原图撑满size大小；\n\n`.width(int width)` 设置宽，高按比例；\n\n`.height(int height)` 设置高，宽按比例；\n\n`.forceSize(int width, int height)` 设置宽高，不按比例，会按照设置的宽高拉伸；\n\n`.scale(double scale)` 按比例缩放，0~1缩小，1原比例，>1放大；\n\n`.scale(double scaleWidth, double scaleHeight)` 长宽各自设置比例，会拉伸；\n\n`.scalingMode(ScalingMode config)` 缩放模式（ScalingMode枚举BICUBIC、BILINEAR、PROGRESSIVE_BILINEAR）；\n\n`.keepAspectRatio(boolean keep)` 设置是否按比例，false不按比例；\n\n**注**：size、width/height、scale、forceSize不能并用；size至关于width+height；forceSize关于设置长款+keepAspectRatio=false，因此forceSize不能跟其余设置长款属性、keepAspectRatio并用；\n\n##### 3.剪裁\n\n`.sourceRegion(int x, int y, int width, int height)` 剪裁原图，坐标x,y起始，剪裁出宽度width高度height的图像，x向右为正，y向下为正，width（向右）和height（向下）必须大于0；\n\n`.sourceRegion(Position position, int width, int height)` 剪裁原图，区域位置position可用Positions枚举的9个位置或者实现Position接口的实现类；\n\n`.sourceRegion(Position position, Size size)` \n\n`.sourceRegion(Rectangle region)` \n\n`.sourceRegion(Region sourceRegion)` \n\n`.crop(Position position)` 剪裁生成的缩略图，按照size设定剪裁；\n\n##### 4.旋转\n\n`.rotate(double angle)` 旋转角度，顺时针为正；\n\n##### 5.水印\n\n`.watermark(BufferedImage image)` 中心位置50%透明度设置水印；\n\n`.watermark(BufferedImage image, float opacity)` 中心位置，opacity的不透明度设置水印（0.0<=opacity<=1.0）；\n\n`.watermark(Position position, BufferedImage image, float opacity)` 在position位置，opacity不透明度设置水印；\n\n`.watermark(Watermark w)` \n\n##### 6.质量\n\n`.outputQuality(double quality)` 质量0.0<=quality<=1.0；\n\n`.outputQuality(float quality)` \n\n##### 7.输出格式\n\n`.outputFormat(String format)` 设置输出格式（可用`ImageIO.getWriterFormatNames()`得到支持的格式），[JPG, jpg, bmp, BMP, gif, GIF, WBMP, png, PNG, wbmp, jpeg, JPEG]；\n\n`.outputFormatType(String formatType)` \n\n`.useOriginalFormat()` 使用原图格式；\n\n##### 8.输出图片\n\n`.asBufferedImage()` 返回`BufferedImage`对象；\n\n`.asBufferedImages()` 返回多个`BufferedImage`对象；\n\n`.asFiles(Rename rename)` 返回文件列表，并按照重命名规则生成文件（Rename抽象类属性：Rename.NO_CHANGE 名称不变，Rename.PREFIX_DOT_THUMBNAIL 名称前缀“thumbnail.”，Rename.PREFIX_HYPHEN_THUMBNAIL 名称前缀“thumbnail-”，Rename.SUFFIX_DOT_THUMBNAIL 名称后缀“.thumbnail”，Rename.SUFFIX_HYPHEN_THUMBNAIL 名称后缀“-thumbnail”）；\n\n`.asFiles(File destinationDir, Rename rename)` 返回文件列表，并按照指定的重命名规则生成到指定目录里（文件夹要存在）；\n\n`.asFiles(Iterable<File> iterable)` \n\n`.toFile(File outFile)` 无返回，写入文件里（若是没有后缀名会自动添加，下同）；\n\n`.toFile(String outFilepath)` \n\n`.toFiles(File destinationDir, Rename rename)` 无返回，按照重命名规则生成到文件夹里；\n\n`.toFiles(Iterable<File> iterable)` \n\n`.toFiles(Rename rename)` \n\n`.toOutputStream(OutputStream os)` 无返回，写入outputStream里；\n\n`.toOutputStreams(Iterable<? extends OutputStream> iterable)` \n\n`.allowOverwrite(boolean allowOverwrite)` 设置是否覆盖已存在的文件（只对toFile、toFiles、asFiles有效）；\n\n##### 示例：\n\n```Java\nThumbnails.of(image).size(200, 300).toFile(filePathAndName);//指定大小进行缩放\nThumbnails.of(image).scale(0.25f).toFile(filePathAndName);//指定比例进行缩放\nThumbnails.of(image).size(120, 120).keepAspectRatio(false).toFile(filePathAndName);//不按照比例指定大小进行缩放\n.rotate(90)//旋转   rotate(角度),正数：顺时针 负数：逆时针\n.watermark(Positions.BOTTOM_RIGHT, ImageIO.read(new File(\"images/watermark.png\")), 0.5f)  // watermark(位置，水印图，透明度)\n.sourceRegion()  // 裁剪\n.outputFormat(\"png\")  //转化图像格式\nThumbnails.of(image).scale(0.25f).toOutputStream(os); //输出到OutputStream\nThumbnails.of(image).scale(0.25f).asBufferedImage();  //输出到BufferedImage\n```\n\n# 阿里云OSS文件上传\n\n## 简介\n\n阿里云对象存储服务，简称 OSS，是一种面向海量数据规模的分布式存储服务。\n\n## 注册开通略\n\n## 配置OSS\n\nAccessKey\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29XReyHZPQ03RifSc/root/content)\n\n创建Bucket \n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29mALscR5FV7ZmMQH/root/content)\n\n## 学习使用API\n\nhttps://help.aliyun.com/document_detail/31948.html?spm=5176.208357.1107607.18.1e88390fheeEwP\n\n### 导包\n\n```\n<dependency>\n    <groupId>com.aliyun.oss</groupId>\n    <artifactId>aliyun-sdk-oss</artifactId>\n    <version>3.10.2</version>\n</dependency>\n//如果使用的是Java 9及以上的版本，则需要添加jaxb相关依赖。添加jaxb相关依赖示例代码如下：\n<dependency>\n    <groupId>javax.xml.bind</groupId>\n    <artifactId>jaxb-api</artifactId>\n    <version>2.3.1</version>\n</dependency>\n<dependency>\n    <groupId>javax.activation</groupId>\n    <artifactId>activation</artifactId>\n    <version>1.1.1</version>\n</dependency>\n<!-- no more than 2.3.3-->\n<dependency>\n    <groupId>org.glassfish.jaxb</groupId>\n    <artifactId>jaxb-runtime</artifactId>\n    <version>2.3.3</version>\n</dependency>\n```\n\n### 初始化配置\n\napplication.properties\n\n```xml\n#阿里云 OSS\n#不同的服务器，地址不同   ==前面后面都不能加空格！！！！！！！！！！！！！！！！！1\naliyun.oss.endpoint=oss-cn-beijing.aliyuncs.com\naliyun.oss.accessKeyId=LTAI5t7hmUCakcQsHTSedsfE\naliyun.oss.accessKeySecret=PwAZRnMx4p5GKFFF2ksdsaffdsiG\n#bucket可以在控制台创建，也可以使用java代码创建\naliyun.oss.bucketName=greatbrook\naliyun.oss.url=https://greatbrook.oss-cn-beijing.aliyuncs.com //文件存储地址\n```\n\n### 以用户上传头像为例\n\n头像链接headerUrl保存在user表中，用户在网页选择并上传头像时\n\n1.后端接收headerImage，并判断接收文件是否为jpg或png文件，不是则返回\"文件格式不正确\"。\n\n2.使用Thumbnails工具对传入的图片进行处理，压缩图片尺寸，并输出BufferedImage对象。\n\n3.根据配置创建文件上传客户端，使用OSSClientBuilder()。\n\n4.上传处理过后的图片inputStream，更改文件名。关闭客户端。\n\n5.将返回的用户头像路径写入user表。\n\n#### 用户表\n\n#### 用户表 user\n\n| 字段            | 类型      | 备注                               |\n| --------------- | --------- | ---------------------------------- |\n| id              | int       | 主键、自增                         |\n| username        | varchar   | 用户名，创建索引                   |\n| password        | varchar   | 用户密码                           |\n| salt            | varchar   | 加密盐值                           |\n| email           | varchar   | 用户邮箱，创建索引                 |\n| type            | int       | 用户类型：0 普通、1 管理员、2 版主 |\n| status          | int       | 用户状态：0 未激活、1 已激活       |\n| activation_code | varchar   | 激活码                             |\n| header_url      | varchar   | 用户头像地址                       |\n| create_time     | timestamp | 注册时间                           |\n\n#### user_mapper.xml\n\n```\n<update id=\"updateHeader\">\n    update User set header_url = #{headerUrl} where id = #{id}\n</update>\n```\n\n#### UserMapper\n\n```\n@Mapper\npublic interface UserMapper {\n    User selectById(int id);\n    User selectByName(String username);\n    User selectByEmail(String email);\n    int insertUser(User user);\n    int updateStatus(int id,int status);\n    int updateHeader(int id, String headerUrl);\n    int updatePassword(int id, String password);\n}\n```\n\n#### UserService\n\n```\n@Service\npublic class UserService{\n//更新头像  引入redis缓存user所以要先更新再清除缓存 不然会引起mysql和redis的冲突\n    public int updateHeader(int userId, String headerUrl) {\n        //return userMapper.updateHeader(userId, headerUrl);  mysql实现方式\n        int rows = userMapper.updateHeader(userId, headerUrl);\n        clearCache(userId);\n        return rows;\n\n    }\n}\n```\n\n#### UserController\n\n```\n    private static final Logger logger = LoggerFactory.getLogger(UserController.class);\n//导入相关路径\n    @Value(\"${community.path.upload}\")\n    private String uploadPath;\n    @Value(\"${community.path.domain}\")\n    private String domain;\n    @Value(\"${server.servlet.context-path}\")\n    private String contextPath;\n    @Value(\"${aliyun.oss.endpoint}\")\n    private String endpoint;\n    @Value(\"${aliyun.oss.accessKeyId}\")\n    private String accessKeyId;\n    @Value(\"${aliyun.oss.accessKeySecret}\")\n    private String accessKeySecret;\n    @Value(\"${aliyun.oss.bucketName}\")\n    private String bucketName;\n    @Value(\"${aliyun.oss.url}\")\n    private String url;\n    //文件存储目录\n    private String filedir = \"header/\";\n\n    @Autowired\n    private UserService userService;\n    @Autowired\n    private HostHolder hostHolder;\n//上传头像\n    @LoginRequired\n    @RequestMapping(path = \"/upload\",method = RequestMethod.POST)\n    public String uploadHeader(MultipartFile headerImage, Model model){\n          if (headerImage.isEmpty()){\n            model.addAttribute(\"error\",\"您还没有选择图片！\");\n            return \"/site/setting\";\n        } //如果图片为空返回error\n        String fileName = headerImage.getOriginalFilename();\n        String suffix = fileName.substring(fileName.lastIndexOf(\".\") + 1 );\n        //只允许上传.jpg和.png文件 方法很原始 不安全可以采用头文件判断 \n        if (StringUtils.isBlank(suffix)||!(\"jpg\".equals(suffix)||\"png\".equals(suffix)||\"jpeg\".equalsIgnoreCase(suffix))){\n            model.addAttribute(\"error\",\"文件格式不正确\");\n            return \"/site/setting\";\n        }\n\n        try {\n            //生成随机文件名\n            fileName = CommunityUtil.generateUUID() + \".\" + suffix;\n           //Thumbnails处理图片\n            BufferedImage bi = Thumbnails.of(headerImage.getInputStream())\n                    .scale(0.25f)\n                    .asBufferedImage();\n            //图片处理为正方形\n            int init_width = bi.getWidth();\n            int init_height = bi.getHeight();\n            if (init_width != init_height){\n                int width_height = 0;\n                int x = 0;\n                int y = 0;\n                if (init_width > init_height) {\n                    width_height = init_height;//原图是宽大于高的长方形\n                    x = (init_width-init_height)/2;\n                    y = 0;\n                } else if (init_width < init_height) {\n                    width_height = init_width;//原图是高大于宽的长方形\n                    y = (init_height-init_width)/2;\n                    x = 0;\n                }\n                bi = bi.getSubimage(x, y, width_height, width_height);\n            }\n            ByteArrayOutputStream os = new ByteArrayOutputStream();\n            //ImageIO.write(image, \"JPEG\", out);\n            ImageIO.write(bi, suffix, os); //图片写入到 ImageOutputStream 和之前格式一致\n           InputStream inputStream = new ByteArrayInputStream(os.toByteArray());\n\n            //文件上传\n            //设置文件路径和名称\n            String fileUrl = filedir + fileName;\n            //上传文件\n            //阿里云文件上传客户端  创建OSSClient实例。\n            OSS client = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret);\n            //调用oss方法实现上传\n            //参数1：Bucket名称\n            //参数2：上传到oss的文件路径和文件名\n            //参数3：上传文件输入流\n            client.putObject(bucketName, fileUrl, inputStream);\n            //删除旧头像\n            User user = hostHolder.getUser();\n\n            if ( user.getHeaderUrl() != null){\n                String[] objectNames = user.getHeaderUrl().split(\"/\");\n                String objectName = filedir + objectNames[4];\n                if (objectName != null) {\n                    client.deleteObject(bucketName, objectName);\n                    logger.info(\"删除旧头像成功\"+objectName);\n                }\n            }\n\n            // 关闭OSSClient\n            client.shutdown();\n            //更新当前用户头像的路径（web访问 Http://loacalhost:8080/community/user/header/xxx.png）\n            User user = hostHolder.getUser();\n            //String headerUrl = domain + contextPath +\"/user/header/\" +fileName;\n            String headerUrl = url + \"/\" + fileUrl;\n            userService.updateHeader(user.getId(),headerUrl);\n     \n            return \"redirect:/index\";\n        } catch (IOException e) {\n            model.addAttribute(\"error\",e.getMessage());\n            return \"/site/setting\";\n        }\n}\n```\n\n## 测试：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29mFFJ4BqEqPIIqph/root/content)\n\n原图片2.07MB\n\n上传成功并获取返回链接写入user表\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29mKz81o6_SPTQHZ4/root/content)\n\n\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29mMsnWVsGGXKKw6m/root/content)\n\n查看OSS中图片确实上传成功 且图片是压缩过后的21.97kb\n\n而且Thumbnails的一系列处理也杜绝了shell等文件通过修改后缀名为jpg和png等格式绕过检测上传到服务器的问题。\n\n\n\n以上就是对图片文件处理并上传到阿里云OSS的简单介绍，如果有疑问或者纠错可以通过邮件与我联系。\n\n\n\n\n\n\n\n> 引用：\n>\n> https://www.shangmayuan.com/a/24fb08cae151401f973f0f60.html\n>\n> https://blog.csdn.net/qq_41950447/article/details/115962254\n>\n> https://bbs.csdn.net/topics/392077729?list=lz\n>\n> https://help.aliyun.com/document_detail/32008.html?spm=5176.208357.1107607.21.331b390f9Z4W5C\n","tags":["aliyun","oss","project"],"categories":["项目"]},{"title":"论坛项目总结","url":"/2021/06/20/论坛项目总结/","content":"\n# 简介\n\n涉及到Spring、SpringMVC、Mybatis的整合，以及SpringBoot去简化Spring的配置开发\n\n主要的技术点：\n\n登录注册功能：使用kaptcha去生成验证码，使用邮件完成注册，Redis优化验证码的保存，解决分布式session问题\n\n使用拦截器拦截用户请求，将用户信息绑定在ThreadLocal上\n\n构建Trie数据结构，实现对发表帖子评论的敏感词过滤\n\n支持对帖子评论，也支持对评论进行回复\n\n利用AOP对service的业务代码实现日志记录\n\n利用Redis的zset并结合Redis实现点赞关注的功能\n\n点赞关注后的系统通知，实时性不需要特别高，使用kafka实现异步的发送系统通知\n\n使用ElasticSearch实现对帖子的搜索功能，以及结果的高亮显示\n\nSpringQuartz实现定时任务，完成热门帖子的分数计算模块\n\n使用本地缓存Quartz缓存热门帖子优化热门帖子页面，提高了QPS（10 - 200） [![image](https://user-images.githubusercontent.com/39627757/115350664-f7181500-a1e7-11eb-90df-d3b38eea2991.png)](https://user-images.githubusercontent.com/39627757/115350664-f7181500-a1e7-11eb-90df-d3b38eea2991.png) [![image](https://user-images.githubusercontent.com/39627757/115350723-06975e00-a1e8-11eb-821f-1352b36bef15.png)](https://user-images.githubusercontent.com/39627757/115350723-06975e00-a1e8-11eb-821f-1352b36bef15.png) [![image](https://user-images.githubusercontent.com/39627757/115350746-0eef9900-a1e8-11eb-90d8-7e37992131fb.png)](https://user-images.githubusercontent.com/39627757/115350746-0eef9900-a1e8-11eb-90d8-7e37992131fb.png) [![image](https://gitee.com/brook2bubble/pic-go/raw/master/img/115350771-19aa2e00-a1e8-11eb-99df-68c08d23ae56.png)](https://user-images.githubusercontent.com/39627757/115350771-19aa2e00-a1e8-11eb-99df-68c08d23ae56.png) [![image](https://gitee.com/brook2bubble/pic-go/raw/master/img/115350801-2169d280-a1e8-11eb-8dfc-7b1431c8953a.png)](https://user-images.githubusercontent.com/39627757/115350801-2169d280-a1e8-11eb-8dfc-7b1431c8953a.png)\n\n处理服务器请求SpringMVC 处理数据库 MyBatis\n\nSSM框架\n\n构建工具：Apache Maven\n\n集成开发工具：IDEA\n\n数据库：Mysql Redis\n\n应用服务器：Tomcat\n\n版本控制工具：Git\n\n# 准备阶段\n\n## 数据库表\n\n#### 用户表 user\n\n| 字段            | 类型      | 备注                               |\n| --------------- | --------- | ---------------------------------- |\n| id              | int       | 主键、自增                         |\n| username        | varchar   | 用户名，创建索引                   |\n| password        | varchar   | 用户密码                           |\n| salt            | varchar   | 加密盐值                           |\n| email           | varchar   | 用户邮箱，创建索引                 |\n| type            | int       | 用户类型：0 普通、1 管理员、2 版主 |\n| status          | int       | 用户状态：0 未激活、1 已激活       |\n| activation_code | varchar   | 激活码                             |\n| header_url      | varchar   | 用户头像地址                       |\n| create_time     | timestamp | 注册时间                           |\n\n\n\n#### 评论表 comment\n\n| 字段        | 类型      | 备注                                 |\n| ----------- | --------- | ------------------------------------ |\n| id          | int       | 主键、自增                           |\n| user_id     | int       | 评论的用户 id，创建索引              |\n| entity_id   | int       | 评论实体 id，创建索引                |\n| entity_type | int       | 评论实体类型：1 帖子评论、2 评论回复 |\n| target_id   | int       | 评论目标 id                          |\n| content     | text      | 评论内容                             |\n| status      | int       | 评论状态：0 有效、1 无效             |\n| create_time | timestamp | 评论发表时间                         |\n\n#### 帖子表 discuss_post\n\n| 字段          | 类型      | 备注                             |\n| ------------- | --------- | -------------------------------- |\n| id            | int       | 主键、自增                       |\n| user_id       | int       | 发帖的用户 id，创建索引          |\n| title         | varchar   | 帖子表标题                       |\n| content       | text      | 帖子内容                         |\n| type          | int       | 帖子类型：0 普通、1 置顶         |\n| comment_count | int       | 评论数量                         |\n| status        | int       | 帖子状态：0 普通、1 精华、2 拉黑 |\n| create_time   | timestamp | 评论发表时间                     |\n\n#### 用户登录凭证表 login_ticket\n\n| 字段    | 类型      | 备注                     |\n| ------- | --------- | ------------------------ |\n| id      | int       | 主键、自增               |\n| user_id | int       | 登录用户 id              |\n| ticket  | varchar   | 登录凭证，随机字符串     |\n| status  | int       | 登录状态：0 有效、1 无效 |\n| expired | timestamp | 过期时间                 |\n\n#### 消息表 message\n\n| 字段            | 类型      | 备注                                  |\n| --------------- | --------- | ------------------------------------- |\n| id              | int       | 主键、自增                            |\n| from_id         | int       | 发消息的 id，创建索引                 |\n| to_id           | int       | 收消息的 id，创建索引                 |\n| conversation_id | varchar   | 会话 id，由通信双方 id 拼接，创建索引 |\n| content         | text      | 消息内容                              |\n| status          | int       | 消息状态：0 未读、1 已读、2 删除      |\n| create_time     | timestamp | 消息发送时间                          |\n\n## 搭建开发环境\n\n### Maven\n\n帮助构建项目管理项目中的jar包\n\nMaven仓库：存放构件的位置\n\n   -本地仓库：默认是~/.m2/repository\n\n   -远程仓库：中央仓库，镜像仓库，私服仓库\n\nhttps://maven.apache.org/\n\n## Maven 构建 Java 项目\n\nMaven 使用原型 **archetype** 插件创建项目。要创建一个简单的 Java 应用，我们将使用 **maven-archetype-quickstart** 插件。\n\n在下面的例子中，我们将在 C:\\MVN 文件夹下创建一个基于 maven 的 java 应用项目。\n\n\n\n命令格式如下：\n\n```\nmvn archetype:generate \"-DgroupId=com.companyname.bank\" \"-DartifactId=consumerBanking\" \"-DarchetypeArtifactId=maven-archetype-quickstart\" \"-DinteractiveMode=false\"\n```\n\n参数说明：\n\n- **-DgroupId**: 组织名，公司网址的反写 + 项目名称\n- **-DartifactId**: 项目名-模块名\n- **-DarchetypeArtifactId**: 指定 ArchetypeId，maven-archetype-quickstart，创建一个简单的 Java 应用\n- **-DinteractiveMode**: 是否使用交互模式\n\n本地仓库地址：E:\\Javastudy\\maven-repository\\repository\n\n配置文件地址：C:\\Program Files\\Java\\apache-maven-3.8.1\\conf\\settings.xml\n\n# Spring\n\nSpring框架的核心功能有两个：\n\n- Spring容器作为超级大工厂，负责创建、管理所有的Java对象，这些Java对象被称为Bean。\n- Spring容器管理容器中Bean之间的依赖关系，Spring使用一种被称为\"依赖注入\"的方式来管理Bean之间的依赖关系。\n\n使用依赖注入，不仅可以为Bean注入普通的属性值，还可以注入其他Bean的引用。依赖注入是一种优秀的解耦方式，其可以让Bean以配置文件组织在一起，而不是以硬编码的方式耦合在一起。\n\nRod Johnson是第一个高度重视以配置文件来管理Java实例的协作关系的人，他给这种方式起了一个名字：**控制反转（Inverse of Control，IoC）**。后来Martine Fowler为这种方式起了另一个名称：**依赖注入（Dependency Injection）**，因此不管是依赖注入，还是控制反转，**其含义完全相同**。当某个Java对象（调用者）需要调用另一个Java对象（被依赖对象）的方法时，在传统模式下通常有两种做法：\n\n1. 原始做法: 调用者**主动**创建被依赖对象，然后再调用被依赖对象的方法。\n2. 简单工厂模式: 调用者先找到被依赖对象的工厂，然后**主动**通过工厂去获取被依赖对象，最后再调用被依赖对象的方法。\n\n## IoC Inversion of Control\n\n控制反转，面向对象编程。\n\n在Java开发中，**Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。**\n\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TZHi5ApTE14Fcxh/root/content)\n\n图1-1 传统应用程序示意图\n\n　　当有了IoC/DI的容器后，在客户端类中不再主动去创建这些对象了，如图2-2所示:\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TdaS3TyMx33Wm6w/root/content)\n\n图1-2有IoC/DI容器后程序结构示意图\n\n传统应用程序都是由我们在类内部主动创建依赖对象，从而导致类与类之间高耦合，难于测试；有了IoC容器后，把创建和查找依赖对象的控制权交给了容器，由容器进行注入组合对象，所以对象与对象之间是 松散耦合，这样也方便测试，利于功能复用，更重要的是使得程序的整个体系结构变得非常灵活。\n\n**对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。**\n\n**Spring所倡导的开发方式**就是如此，**所有的类都会在spring容器中登记，告诉spring你是个什么东西，你需要什么东西，然后spring会在系统运行到适当的时候，把你要的东西主动给你，同时也把你交给其他需要你的东西。所有的类的创建、销毁都由 spring来控制，也就是说控制对象生存周期的不再是引用它的对象，而是spring。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被spring控制，所以这叫控制反转。**\n\n## DI(依赖注入)\n\n**DI—Dependency Injection，即“依赖注入”**：**组件之间依赖关系**由容器在运行期决定，形象的说，即**由容器动态的将某个依赖关系注入到组件之中**。**依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。**通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。Java 1.3之后一个重要特征是反射（reflection），它允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性，spring就是通过反射来实现注入的。\n\n**“谁依赖谁，为什么需要依赖，谁注入谁，注入了什么”**\n\n　　●**谁依赖于谁：**当然是**应用程序依赖于IoC容器**；\n\n　　●**为什么需要依赖：****应用程序需要IoC容器来提供对象需要的外部资源**；\n\n　　●**谁注入谁：**很明显是**IoC容器注入应用程序某个对象，应用程序依赖的对象**；\n\n　　**●注入了什么：**就是**注入某个对象所需要的外部资源（包括对象、资源、常量数据）**。\n\n## **IoC和DI**由什么**关系**呢？\n\n其实它们**是同一个概念的不同角度描述**，由于控制反转概念比较含糊（可能只是理解为容器控制对象这一个层面，很难让人想到谁来维护对象关系）。\n\n## IoC容器\n\n实现依赖注入的关键，本质上就是一个工厂。\n\n## 设值注入\n\n设值注入是指IoC容器通过成员变量的setter方法来注入被依赖对象。这种注入方式简单、直观，因而在Spring的依赖注入里大量使用。\n\n## 构造注入\n\n利用构造器来设置依赖关系的方式，被称为构造注入。通俗来说，就是驱动Spring在底层以反射方式执行带指定参数的构造器，当执行带参数的构造器时，就可利用构造器参数对成员变量执行初始化——这就是构造注入的本质。\n\n## 两种注入方式的对比\n\n设值注入有如下优点：\n\n- 与传统的JavaBean的写法更相似，程序开发人员更容易理解、接受。通过setter方法设定依赖关系显得更加直观、自然。\n- 对于复杂的依赖关系，如果采用构造注入，会导致构造器过于臃肿，难以阅读。Spring在创建Bean实例时，需要同时实例化其依赖的全部实例，因而导致性能下降。而使用设值注入，则能避免这些问题。\n- 尤其在某些成员变量可选的情况下，多参数的构造器更加笨重。\n\n构造注入优势如下：\n\n- 构造注入可以在构造器中决定依赖关系的注入顺序，优先依赖的优先注入。\n- 对于依赖关系无需变化的Bean，构造注入更有用处。因为没有setter方法，所有的依赖关系全部在构造器内设定，无须担心后续的代码对依赖关系产生破坏。\n- 依赖关系只能在构造器中设定，则只有组件的创建者才能改变组件的依赖关系，对组件的调用者而言，组件内部的依赖关系完全透明，更符合高内聚的原则。\n\n注意：\n建议采用设值注入为主，构造注入为辅的注入策略。对于依赖关系无须变化的注入，尽量采用构造注入；而其他依赖关系的注入，则考虑采用设值注入。\n\n# Spring容器中的Bean\n\n对于开发者来说，开发者使用Spring框架主要是做两件事：①开发Bean；②配置Bean。对于Spring框架来说，它要做的就是根据配置文件来创建Bean实例，并调用Bean实例的方法完成\"依赖注入\"——这就是所谓IoC的本质。\n\n## 容器中Bean的作用域\n\n当通过Spring容器创建一个Bean实例时，不仅可以完成Bean实例的实例化，还可以为Bean指定特定的作用域。Spring支持如下五种作用域：\n\n1. singleton: 单例模式，在整个Spring IoC容器中，singleton作用域的Bean将只生成一个实例。\n2. prototype: 每次通过容器的getBean()方法获取prototype作用域的Bean时，都将产生一个新的Bean实例。\n3. request: 对于一次HTTP请求，request作用域的Bean将只生成一个实例，这意味着，在同一次HTTP请求内，程序每次请求该Bean，得到的总是同一个实例。只有在Web应用中使用Spring时，该作用域才真正有效。\n4. session：该作用域将 bean 的定义限制为 HTTP 会话。 只在web-aware Spring ApplicationContext的上下文中有效。\n5. global session: 每个全局的HTTP Session对应一个Bean实例。在典型的情况下，仅在使用portlet context的时候有效，同样只在Web应用中有效。\n\n如果不指定Bean的作用域，Spring默认使用singleton作用域。prototype作用域的Bean的创建、销毁代价比较大。而singleton作用域的Bean实例一旦创建成果，就可以重复使用。因此，应该尽量避免将Bean设置成prototype作用域。\n\n## 使用自动装配注入合作者Bean\n\nSpring能自动装配Bean与Bean之间的依赖关系，即无须使用ref显式指定依赖Bean，而是由Spring容器检查XML配置文件内容，根据某种规则，为调用者Bean注入被依赖的Bean。\nSpring自动装配可通过`<beans/>`元素的`default-autowire`属性指定，该属性对配置文件中所有的Bean起作用；也可通过对`<bean/>`元素的`autowire`属性指定，该属性只对该Bean起作用。\n\n`autowire`和`default-autowire`可以接受如下值：\n\n- `no`: 不使用自动装配。Bean依赖必须通过ref元素定义。这是默认配置，在较大的部署环境中不鼓励改变这个配置，显式配置合作者能够得到更清晰的依赖关系。\n- `byName`: 根据setter方法名进行自动装配。Spring容器查找容器中全部Bean，找出其id与setter方法名去掉set前缀，并小写首字母后同名的Bean来完成注入。如果没有找到匹配的Bean实例，则Spring不会进行任何注入。\n- `byType`: 根据setter方法的形参类型来自动装配。Spring容器查找容器中的全部Bean，如果正好有一个Bean类型与setter方法的形参类型匹配，就自动注入这个Bean；如果找到多个这样的Bean，就抛出一个异常；如果没有找到这样的Bean，则什么都不会发生，setter方法不会被调用。\n- `constructor`: 与byType类似，区别是用于自动匹配构造器的参数。如果容器不能恰好找到一个与构造器参数类型匹配的Bean，则会抛出一个异常。\n- `autodetect`: Spring容器根据Bean内部结构，自行决定使用constructor或byType策略。如果找到一个默认的构造函数，那么就会应用byType策略。\n\n**当一个Bean既使用自动装配依赖，又使用ref显式指定依赖时，则显式指定的依赖覆盖自动装配依赖；对于大型的应用，不鼓励使用自动装配。虽然使用自动装配可减少配置文件的工作量，但大大将死了依赖关系的清晰性和透明性。依赖关系的装配依赖于源文件的属性名和属性类型，导致Bean与Bean之间的耦合降低到代码层次，不利于高层次解耦。**\n\n```\n<!--通过设置可以将Bean排除在自动装配之外-->\n<bean id=\"\" autowire-candidate=\"false\"/>\n\n<!--除此之外，还可以在beans元素中指定，支持模式字符串，如下所有以abc结尾的Bean都被排除在自动装配之外-->\n<beans default-autowire-candidates=\"*abc\"/>\n```\n\n# 创建Bean的3种方式\n\n## 使用构造器创建Bean实例\n\n使用构造器来创建Bean实例是最常见的情况，如果不采用构造注入，Spring底层会调用Bean类的无参数构造器来创建实例，因此要求该Bean类提供无参数的构造器。\n\n采用默认的构造器创建Bean实例，Spring对Bean实例的所有属性执行默认初始化，即所有的基本类型的值初始化为0或false；所有的引用类型的值初始化为null。\n\n## 使用静态工厂方法创建Bean\n\n使用静态工厂方法创建Bean实例时，class属性也必须指定，但此时class属性并不是指定Bean实例的实现类，而是静态工厂类，Spring通过该属性知道由哪个工厂类来创建Bean实例。\n\n除此之外，还需要使用factory-method属性来指定静态工厂方法，Spring将调用静态工厂方法返回一个Bean实例，一旦获得了指定Bean实例，Spring后面的处理步骤与采用普通方法创建Bean实例完全一样。如果静态工厂方法需要参数，则使用`<constructor-arg.../>`元素指定静态工厂方法的参数。\n\n## 调用实例工厂方法创建Bean\n\n实例工厂方法与静态工厂方法只有一个不同：调用静态工厂方法只需使用工厂类即可，而调用实例工厂方法则需要工厂实例。使用实例工厂方法时，配置Bean实例的`<bean.../>`元素无须class属性，配置实例工厂方法使用`factory-bean`指定工厂实例。\n采用实例工厂方法创建Bean的`<bean.../>`元素时需要指定如下两个属性：\n\n- factory-bean: 该属性的值为工厂Bean的id。\n- factory-method: 该属性指定实例工厂的工厂方法。\n\n若调用实例工厂方法时需要传入参数，则使用`<constructor-arg.../>`元素确定参数值。\n\n# 协调作用域不同步的Bean\n\n当singleton作用域的Bean依赖于prototype作用域的Bean时，会产生不同步的现象，原因是因为当Spring容器初始化时，容器会预初始化容器中所有的`singleton Bean`，由于`singleton Bean`依赖于`prototype Bean`，因此Spring在初始化`singleton Bean`之前，会先创建`prototypeBean`——然后才创建`singleton Bean`，接下里将`prototype Bean`注入`singleton Bean`。\n解决不同步的方法有两种：\n\n- 放弃依赖注入: singleton作用域的Bean每次需要prototype作用域的Bean时，主动向容器请求新的Bean实例，即可保证每次注入的`prototype Bean`实例都是最新的实例。\n- 利用方法注入: 方法注入通常使用lookup方法注入，使用lookup方法注入可以让Spring容器重写容器中Bean的抽象或具体方法，返回查找容器中其他Bean的结果，被查找的Bean通常是一个`non-singleton Bean`。Spring通过使用JDK动态代理或cglib库修改客户端的二进制码，从而实现上述要求。\n\n建议采用第二种方法，使用方法注入。为了使用lookup方法注入，大致需要如下两步：\n\n1. 将调用者Bean的实现类定义为抽象类，并定义一个抽象方法来获取被依赖的Bean。\n2. 在`<bean.../>`元素中添加`<lookup-method.../>`子元素让Spring为调用者Bean的实现类实现指定的抽象方法。\n\n***注意：\\***\n\n> Spring会采用运行时动态增强的方式来实现`<lookup-method.../>`元素所指定的抽象方法，如果目标抽象类实现过接口，Spring会采用JDK动态代理来实现该抽象类，并为之实现抽象方法；如果目标抽象类没有实现过接口，Spring会采用cglib实现该抽象类，并为之实现抽象方法。Spring4.0的spring-core-xxx.jar包中已经集成了cglib类库。\n\n# 两种后处理器\n\nSpring提供了两种常用的后处理器：\n\n- Bean后处理器: 这种后处理器会对容器中Bean进行后处理，对Bean进行额外加强。\n- 容器后处理器: 这种后处理器会对IoC容器进行后处理，用于增强容器功能。\n\n## Bean后处理器\n\nBean后处理器是一种特殊的Bean，这种特殊的Bean并不对外提供服务，它甚至可以无须id属性，它主要负责对容器中的其他Bean执行后处理，例如为容器中的目标Bean生成代理等，这种Bean称为Bean后处理器。Bean后处理器会在Bean实例创建成功之后，对Bean实例进行进一步的增强处理。Bean后处理器必须实现`BeanPostProcessor`接口，同时必须实现该接口的两个方法。\n\n1. `Object postProcessBeforeInitialization(Object bean, String name) throws BeansException`: 该方法的第一个参数是系统即将进行后处理的Bean实例，第二个参数是该Bean的配置id\n2. `Object postProcessAfterinitialization(Object bean, String name) throws BeansException`: 该方法的第一个参数是系统即将进行后处理的Bean实例，第二个参数是该Bean的配置id\n\n容器中一旦注册了Bean后处理器，Bean后处理器就会自动启动，在容器中每个Bean创建时自动工作，Bean后处理器两个方法的回调时机如下图：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TjcHIDsNajtK1_w/root/content)\n\n注意一点，如果使用`BeanFactory`作为Spring容器，则必须手动注册Bean后处理器，程序必须获取Bean后处理器实例，然后手动注册。\n\n```\nBeanPostProcessor bp = (BeanPostProcessor)beanFactory.getBean(\"bp\");\nbeanFactory.addBeanPostProcessor(bp);\nPerson p = (Person)beanFactory.getBean(\"person\");\n```\n\n## 容器后处理器\n\nBean后处理器负责处理容器中的所有Bean实例，而容器后处理器则负责处理容器本身。容器后处理器必须实现`BeanFactoryPostProcessor`接口，并实现该接口的一个方法`postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory)`实现该方法的方法体就是对Spring容器进行的处理，这种处理可以对Spring容器进行自定义扩展，当然也可以对Spring容器不进行任何处理。\n\n类似于`BeanPostProcessor`，`ApplicationContext`可自动检测到容器中的容器后处理器，并且自动注册容器后处理器。但若使用`BeanFactory`作为Spring容器，则必须手动调用该容器后处理器来处理`BeanFactory`容器。\n\n# SpringBoot配置文件&运行原理\n\n## **1. 前言**\n\nSpringBoot最核心的就是自动配置类，而自动配置类需要读取配置文件的信息，来自动创建实例，因此配置文件就显得非常重要了。本文主要介绍SpringBoot的配置文件、以及自动配置类和配置文件之间的关系，即SpringBoot的运行原理。\n\n## **2. SpringBoot 配置文件**\n\nSpringBoot**默认加载**的配置文件是在classpath根目录的**application.properties**或者\n\n**application.yml**配置文件。\n\n**--注意：**\n\n> [1] 文件名不能写错，因为默认的文件名写死在SpringBoot配置代码中。\n> [2] SpringBoot支持properties和yml两个格式的配置文件。\n\n## **2.1. 配置 Web 服务器**\n\n--问题1：为什么SpringBoot明明是一个jar项目而且没有选择服务器组件，但是仍然可以启动项目？\n\n> 因为SpringBoot默认内嵌了一个Web服务器（Tomcat）\n\n--问题2：那么我们如何修改内嵌的Web服务器的参数呢？\n\n> 既然已经内嵌在程序里面了，我们也知道SpringBoot的参数就是配置在SpringBoot配置文件里面的。那么当然就是在 SpringBoot配置文件里面配置。\n\n### **2.1.1. properties 格式配置**\n\n**--Properties 文件的属性，使用的平铺方式书写**\n\n```text\n## 设置server参数\n## 端口\nserver.port=8080\n## 设置下上文路径\nserver.servlet.context-path=/community\n```\n\n### **2.1.2. yml 格式配置**\n\n**--Yml 文件的属性使用折叠的方式书写**\n\n```text\n## 设置server参数\n## 注意事项：\n## [1] 冒号和参数值之间必须要隔一个空格，否则报错\n## [2] 属性设置是有层级之分的\nserver:\n  port: 8080\n  servlet:\n    context-path: /community\n```\n\n## **2.2. 多配置文件**\n\n需求：希望可以配置多个配置文件，分类存放配置信息。\n\n\n\n### **2.2.1. Properties 配置步骤**\n\n### **第一步：编写三个配置文件**\n\n![img](https://pic4.zhimg.com/80/v2-adee1ecaccfbe79d0f9eb259023d5237_720w.jpg)\n\n### **第二步：编写配置文件内容**\n\n**--注意：**\n\n> [1] SpringBoot启动的时候加载的是 application.properties配置文件，再通过application.properties配置文件的**spring.profiles.active属性**指定加载的其他配置文件。\n> [2] 其他配置文件的文件名格式为：**application-XXX.properties。**\n\n![img](https://pic1.zhimg.com/80/v2-68966117de00d740cadefb0031bccbf8_720w.jpg)\n\n**--application.properties**\n\n```text\n## 指定加载其他配置文件\nspring.profiles.active=server1,server2\n```\n\n**--application-server1.properties**\n\n```text\n## 端口\nserver.port=8083\n```\n\n**--application-server2.properties**\n\n```text\n## 设置下上文路径\nserver.servlet.context-path=/springboot-quickStart-properties\n```\n\n### **第三步：运行项目**\n\n**--成功结果**\n\n\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TH7kmeZMw-HMKJ3/root/content)\n\n\n\n### **2.2.2. Yml 配置步骤**\n\n### **第一步：编写三个 yml 配置文件**\n\n![img](https://pic2.zhimg.com/80/v2-a1d4921cb76e1fa9d5abc9d664382b11_720w.jpg)\n\n### **第二步：分别编写配置信息**\n\n**--注意：**\n\n> [1] SpringBoot启动的时候加载的是 application.yml 配置文件，再通过application.yml配置文件的**spring.profiles.active属性**指定加载的其他配置文件。\n> [2] 其他配置文件的文件名格式为：**application-.yml。**\n\n![img](https://pic2.zhimg.com/80/v2-fd0296faf2d4504d7d407e539584f305_720w.jpg)\n\n\n\n**--application.yml**\n\n```text\n## 指定加载其他配置文件\nspring:\n  profiles:\n    active: server1,server2\n```\n\n**--application-server1.yml**\n\n```text\n## 端口\nserver:\n  port: 8084\n```\n\n**--application-server2.yml**\n\n```text\n## 设置下上文路径\nserver:\n  servlet:\n    context-path: /springboot-quickStart-yml\n```\n\n### **第三步：启动测试**\n\n**--成功结果**\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TouymBo9qdwo6PW/root/content)\n\n\n\n## **3. SpringBoot 运行原理**\n\n> 通过理解**SpringBoot运行流程图**，来理解功能组件的属性是放在哪里的，通过边学边找的方式来记忆规律。\n\n\n\n**--如图所示：**\n\n![img](https://pic1.zhimg.com/80/v2-945cd56e31bd68dc2db05472ed7f692c_720w.jpg)\n\n\n\n**启动流程：**\n\n> 第一步：SpringBoot通过加载贴在入口执行类上面的@SpringBootApplication注解，来启动 SpringBoot 项目。\n> 第二步：根据贴在@SpringBootApplication注解上的三个注@SpringBootConfiguraton、 @EnableAutoConfiguration、@ComponentScan，来加载SpringBoot配置类、自动加载的配置类、组件类。\n\n**3个注解的功能如下：**\n\n> **@SpringBootConfiguraton：**标识一个类是配置类。\n> **@EnableAutoConfiguration：**标识这是一个自动加载的配置类，在SpringBoot启动的时候就自动加载配置类中的组件到容器中。\n> **@ComponentScan：**标识需要组件扫描的包，在SpringBoot中，包扫描给入口类所在包及其入口类的子包。\n\n***\\*注意事项：**SpringBoot内置支持的组件在**spring-boot-autoconfigure-2.2.2.RELEASE.jar** 里面。如该**包下的jdbc分包下的DataSourceAutoConfiguration：**\n\n![img](https://pic3.zhimg.com/80/v2-424af7413e15f2657999b7ccde2a2996_720w.png)\n\n**其中的EnableConfigurationProperties注解用于加载用户配置的参数信息。**\n\n**DataSourceProperties的作用就是标识配置文件中那些信息是DataSource使用的，标识的方式就是使用“spring.datasource”前缀。**\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TkABG0mIjpwsukG/root/content)\n\n\n\n**--根据分析，可以得出结论：**自动加载的配置类信息都在 Xxx**AutoConfiguration**里面，配\n\n置的属性参数都在Xxxxx**Properties**里面。\n\n**--执行原理图**：\n\n![img](https://pic4.zhimg.com/80/v2-98fdaa5758d40191cf671ac792d39593_720w.jpg)\n\n**总结：通过执行原理图，可以知道SpringBoot是如何实现自动配置的。**\n\n# Spring的\"零配置\"支持\n\n## 搜索Bean类\n\nSpring提供如下几个Annotation来标注Spring Bean：\n\n- `@Component`: 标注一个普通的Spring Bean类\n- `@Controller`: 标注一个控制器组件类\n- `@Service`: 标注一个业务逻辑组件类\n- `@Repository`: 标注一个DAO组件类\n\n在Spring配置文件中做如下配置，指定自动扫描的包：\n\n```\n<context:component-scan base-package=\"edu.shu.spring.domain\"/>\n```\n\n## 使用@Resource配置依赖\n\n`@Resource`位于`javax.annotation`包下，是来自JavaEE规范的一个`Annotation`，Spring直接借鉴了该`Annotation`，通过使用该`Annotation`为目标Bean指定协作者Bean。使用`@Resource`与`<property.../>`元素的ref属性有相同的效果。\n`@Resource`不仅可以修饰setter方法，也可以直接修饰实例变量，如果使用`@Resource`修饰实例变量将会更加简单，此时Spring将会直接使用JavaEE规范的Field注入，此时连setter方法都可以不要。\n\n## 使用@PostConstruct和@PreDestroy定制生命周期行为\n\n`@PostConstruct`和`@PreDestroy`同样位于javax.annotation包下，也是来自JavaEE规范的两个Annotation，Spring直接借鉴了它们，用于定制Spring容器中Bean的生命周期行为。它们都用于修饰方法，无须任何属性。其中前者修饰的方法时Bean的初始化方法；而后者修饰的方法时Bean销毁之前的方法。\n\n## Spring4.0增强的自动装配和精确装配\n\nSpring提供了`@Autowired`注解来指定自动装配，`@Autowired`可以修饰setter方法、普通方法、实例变量和构造器等。当使用`@Autowired`标注setter方法时，默认采用byType自动装配策略。在这种策略下，符合自动装配类型的候选Bean实例常常有多个，这个时候就可能引起异常，为了实现精确的自动装配，Spring提供了`@Qualifier`注解，通过使用`@Qualifier`，允许根据Bean的id来执行自动装配。\n\n# 异步请求ajax\n\n \\* asynchronous javascript and xml：异步的js和xml\n\n \\* 它能使用js访问服务器，而且是异步访问\n\n \\* 服务器给客户端的响应一般是整个页面，一个html完整页面！但在ajax中因为是局部刷新，那么服务器就不用再响应整个页面！而只是数据\n\n  \\> text：纯文本\n\n  \\> xml：大家都熟悉\n\n  \\> json：它是js提供的数据交互格式，它在ajax中最受欢迎\n\n## 四个步骤\n\n### 1.创建Ajax对象（得到XMLHttpRequest）\n\n\\* ajax其实只需要学习一个对象：XMLHttpRequest，如果掌握了它，就掌握了ajax！\n\n```\nvar request=new XMLHttpRequest();\n\n注意：如果要兼容IE6以下浏览器则需要编写如下代码\n\nvar request;\n\nif(window.XMLRequest){\nrequest=new XMLRequestHttpRequest();  //IE7、IE8、360等\n\n}else{\nrequest=new ActiveXObject(\"Microsoft.XMLHTTP\");//IE5、IE6\n\n}\n\n```\n\n\n\n### 2.链接到服务器（打开与服务器的连接）\n\n### 3.发送请求（发送请求）\n\n如需将请求发送到服务器，我们使用 XMLHttpRequest 对象的 open() 和 send() 方法。\n\n语法：open(method,url,async)和xmlhttp.send()。\n\n### 4.接受返回值\n\n\\* xmlHttp对象一共有5个状态：\n\n  \\> 0状态：刚创建，还没有调用open()方法; \n\n  \\> 1状态：请求开始：调用了open()方法，但还没有调用send()方法\n\n  \\> 2状态：调用完了send()方法了；\n\n  \\> 3状态：服务器已经开始响应，但不表示响应结束了！\n\n  \\> 4状态：服务器响应结束！（通常我们只关心这个状态！！！）\n\n# Spring的AOP\n\n## 为什么需要AOP\n\nAOP（Aspect Orient Programming）也就是面向切面编程，作为面向对象编程的一种补充，已经成为一种比较成熟的编程方式,面向切面编程将程序运行过程分解成各个切面。\n\nAOP专门用于处理系统中分布于各个模块（不同方法）中的交叉关注点的问题，在JavaEE应用中，常常通过AOP来处理一些具有横切性质的系统级服务，如事务管理、安全检查、缓存、对象池管理等，AOP已经成为一种非常常用的解决方案。\n\n## 使用AspectJ实现AOP\n\nAspectJ是一个基于Java语言的AOP框架，提供了强大的AOP功能，其他很多AOP框架都借鉴或采纳其中的一些思想。其主要包括两个部分：一个部分定义了如何表达、定义AOP编程中的语法规范，通过这套语法规范，可以方便地用AOP来解决Java语言中存在的交叉关注点的问题；另一个部分是工具部分，包括编译、调试工具等。\n\nAOP实现可分为两类：\n\n1. 静态AOP实现: AOP框架在编译阶段对程序进行修改，即实现对目标类的增强，生成静态的AOP代理类，以AspectJ为代表。\n2. 动态AOP实现: AOP框架在运行阶段动态生成AOP代理，以实现对目标对象的增强，以Spring AOP为代表。\n\n一般来说，静态AOP实现具有较好的性能，但需要使用特殊的编译器。动态AOP实现是纯Java实现，因此无须特殊的编译器，但是通常性能略差。\n\n## AOP的基本概念\n\n关于面向切面编程的一些术语：\n\n- 切面（Aspect）: 切面用于组织多个Advice，Advice放在切面中定义。\n- 连接点（Joinpoint）: 程序执行过程中明确的点，如方法的调用，或者异常的抛出。在Spring AOP中，连接点总是方法的调用。\n- 增强处理（Advice）: AOP框架在特定的切入点执行的增强处理。处理有\"around\"、\"before\"和\"after\"等类型\n- 切入点（Pointcut）: 可以插入增强处理的连接点。简而言之，当某个连接点满足指定要求时，该连接点将被添加增强处理，该连接点也就变成了切入点。\n\n## Spring的AOP支持\n\nSpring中的AOP代理由Spring的IoC容器负责生成、管理，其依赖关系也由IoC容器负责管理。\n为了在应用中使用`@AspectJ`支持，Spring需要添加三个库：\n\n- `aspectjweaver.jar`\n- `aspectjrt.jar`\n- `aopalliance.jar`\n\n并在Spring配置文件中做如下配置：\n\n```\n<!--启动@AspectJ支持-->\n<aop:aspectj-autoproxy/>\n\n<!--指定自动搜索Bean组件、自动搜索切面类-->\n<context:component-scan base-package=\"edu.shu.sprint.service\">\n    <context:include-filter type=\"annotation\" expression=\"org.aspectj.lang.annotation.Aspect\"/>\n</context:component-scan>\n```\n\n# @Repository\n\n@Repository和@Controller、@Service、@Component的作用差不多，都是把对象交给spring管理。@Repository用在持久层的接口上，这个注解是将接口的一个实现类交给spring管理。\n\n## Spring的核心机制\n\n### 管理Bean\n\n程序主要是通过Spring容器来访问容器中的Bean，ApplicationContext是Spring容器最常用的接口，该接口有如下两个实现类：\n\n- ClassPathXmlApplicationContext: 从类加载路径下搜索配置文件，并根据配置文件来创建Spring容器。\n- FileSystemXmlApplicationContext: 从文件系统的相对路径或绝对路径下去搜索配置文件，并根据配置文件来创建Spring容器。\n\n```\npublic class BeanTest{\n    public static void main(String args[]) throws Exception{\n        ApplicationContext ctx = new ClassPathXmlApplicationContext(\"beans.xml\");\n        Person p = ctx.getBean(\"person\", Person.class);\n        p.say();\n    }\n```\n\n## AOP 面向切面编程\n\n​\t面向切面编程思想，是对OOP的补充 进一步提高编程效率。web层级设计中，web层->网关层->服务层->数据层，每一层之间也是一个切面。编程中，对象与对象之间，方法与方法之间，模块与模块之间都是一个个切面。能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并**有利于未来的可拓展性和可维护性**。\n\n### 相关概念\n\n#### Aspect（切面）：\n\n Aspect 声明类似于 Java 中的类声明，在 Aspect 中会包含着一些 Pointcut 以及相应的 Advice。\n\n#### Joint point（连接点）：\n\n表示在程序中明确定义的点，典型的包括方法调用，对类成员的访问以及异常处理程序块的执行等等，它自身还可以嵌套其它 joint point。\n\n#### Pointcut（切点）：\n\n表示一组 joint point，这些 joint point 或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的 Advice 将要发生的地方。\n\n#### Advice（增强）：\n\nAdvice 定义了在 Pointcut 里面定义的程序点具体要做的操作，它通过 before、after 和 around 来区别是在每个 joint point 之前、之后还是代替执行的代码。\n\n#### Target（目标对象）：\n\n织入 Advice 的目标对象.。\n\n#### Weaving（织入）：\n\n将 Aspect 和其他对象连接起来, 并创建 Adviced object 的过程\n\n### AOP的实现\n\n#### AspectJ\n\n​\t\t\tAspectJ是语言级的实现，它扩展了Java语言，定义了AOP语法\n​\t\t\tAspectJ在编译期织入代码，他有一个专门的编译器，用来生成遵守Java字节码规范的class文件，基于字节码操作\n\n#### Spring AOP\n\n​\t\t\tSpring AOP 使用纯Java实现，不需要专门的编译过程，也不需要特殊的类装载器。\n​\t\t\tSpring AOP在运行时通过代理的方式织入代码，只支持方法类型的连接点\n​\t\t\tSpring支持对AspectJ的集成\n\n### 代理\n\n**Spring AOP就是基于动态代理的**，如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用**Cglib** ，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理，如下图所示：\n\n![SpringAOPProcess](https://gitee.com/brook2bubble/pic-go/raw/master/img/SpringAOPProcess.jpg)\n\n#### JDK动态代理\n\n​\t\t\t\t\tJava提供的动态代理技术 可以在运行时创建接口的代理事例\n​\t\t\t\t\tSpring　AOP 默认采用此种技术 在接口的代理实例中织入代码\n\n#### CGLib动态代理\n\n​\t\t\t\t\t采用底层的字节码技术 在运行时创建子类代理实例\n​\t\t\t\t\t当目标对象不存在接口时 SpringAOP会采用此种方式 在子类实例中织入代码\n\n# Redis\n\n## 简介\n\n- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。\n- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。\n- Redis支持数据的备份，即master-slave模式的数据备份。\n\nredis是一种高级的key:value存储系统，其中value支持五种数据类型：\n\n1.字符串（strings）\n2.字符串列表（lists）\n3.字符串集合（sets）\n4.有序字符串集合（sorted sets）\n5.哈希（hashes）\n\n而关于key，有几个点要提醒大家：\n\n1.key不要太长，尽量不要超过1024字节，这不仅消耗内存，而且会降低查找的效率；\n2.key也不要太短，太短的话，key的可读性会降低；\n3.在一个项目中，key最好使用统一的命名模式，例如user:10000:passwd。\n\n## Redis 优势\n\n- 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。\n- 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。\n- 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。\n- 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。\n\n## 典型应用场景\n\n缓存，排行榜，计数器，社交网络，消息队列等\n\n## windows安装\n\nhttps://github.com/MicrosoftArchive/redis/releases\n\n安装后最好配置一下系统环境变量\n\n### 使用 cmd\n\n```shell\nC:\\Users\\dgx19>redis-cli  //启动\n127.0.0.1:6379> select 1 //选择数据库\nOK\n127.0.0.1:6379[1]> select 0 //选择默认数据库\nOK\n127.0.0.1:6379> flushdb  //清除缓冲区\nOK\n\n1.字符串（strings）\n2.字符串列表（lists）\n3.字符串集合（sets）\n4.有序字符串集合（sorted sets）\n5.哈希（hashes）\n\n//Strings类型 \n\n127.0.0.1:6379> set test:count 1  //设置String键值\nOK\n127.0.0.1:6379> get test:count  //获取键值\n\"1\"\n127.0.0.1:6379> incr test:count  //值加1\n(integer) 2\n127.0.0.1:6379> decr test:count  //值减1\n(integer) 0\n\n//hashes类型\n\n127.0.0.1:6379> hset test:user id 1 //设置Hash键值\n(integer) 1\n127.0.0.1:6379> hset test:user username zhangsan\n(integer) 1\n127.0.0.1:6379> hget test:user id  //获取hash键值\n\"1\"\n127.0.0.1:6379> hget test:user username\n\"zhangsan\"\n\n//Lists类型\n\n127.0.0.1:6379> lpush test:ids 101 102 103 104 //左进\n(integer) 4\n127.0.0.1:6379> llen test:ids  //list长度查询\n(integer) 4\n127.0.0.1:6379> lindex test:ids 0  //左部索引\n\"104\"\n127.0.0.1:6379> lrange test:ids 0 2 //区域元素索引\n1) \"104\"\n2) \"103\"\n3) \"102\"\n127.0.0.1:6379> rpop test:ids  //右出为先进先出队列 左出为先进后出栈\n\"101\"\n127.0.0.1:6379> rpop test:ids \n\"102\"\n\n//集合sets\n\n127.0.0.1:6379> sadd test:teachers aaa bbb vvv ccc //集合添加元素\n(integer) 4\n127.0.0.1:6379> scard test:teachers  //统计元素数量\n(integer) 4\n127.0.0.1:6379> spop test:teachers  //随即弹出一个元素\n\"vvv\"\n127.0.0.1:6379> spop test:teachers\n\"bbb\"\n127.0.0.1:6379> smembers test:teachers  //显示当前集合所有元素\n1) \"aaa\"\n2) \"ccc\"\n\n//sorted sets 有序集合 按照score排序\n\n127.0.0.1:6379>zadd test:students 01 aaa 02 bbb 03 ccc\n127.0.0.1:6379>zcard test:students\n127.0.0.1:6379>zscore test:students aaa\n127.0.0.1:6379>zrank test:students aaa \n127.0.0.1:6379>zrange test:students 0 3\n\n//全局命令\n\nkeys * 查询当前库里共有多少key\nkey test* 查询当前库里test开头的key\ntype test:user  查询test：user是什么类型的key\nexists test:user 查询是否存在此key\ndel test:user  删除key\nexpire test:students n 设置key存在时间 n秒\n\n```\n\n## Spring整合Redis\n\n### 引入依赖\n\nspring-boot-starter-data-redis\n\n### 配置Redis\n\n配置数据库参数\n\n编写配置类，构造RedisTemplate\n\n### 访问Redis\n\nredisTemplate.opsForValue()\n\nredisTemplate.opsForHash()\n\nredisTemplate.opsForList()\n\nredisTemplate.opsForSet()\n\nredisTemplate.opsForZSet()\n\n### 编程式事务\n\n```\n// 编程式事务\n    @Test\n    public void testTransaction() {\n        Object result = redisTemplate.execute(new SessionCallback() {\n            @Override\n            public Object execute(RedisOperations redisOperations) throws DataAccessException {\n                String redisKey = \"text:tx\";\n                // 启用事务\n                redisOperations.multi();               redisOperations.opsForSet().add(redisKey, \"zhangsan\");              redisOperations.opsForSet().add(redisKey, \"lisi\");             redisOperations.opsForSet().add(redisKey, \"wangwu\");               System.out.println(redisOperations.opsForSet().members(redisKey));\n                // 提交事务\n                return redisOperations.exec();\n            }\n        });\n        System.out.println(result);\n    }\n```\n\n## Redis高级数据类型\n\n## 数据类型\n\n### HyperLogLog\n\n采用一种基数算法，用于完成独立总数的统计\n占据空间小，无论统计多少个数据，只占12k的内存\n不精确的统计算法，标准误差为0.81%\n\n### Bitmap（统计用户的签到情况）\n\n不是一种独立的数据结构，实际上就是字符串\n支持按位存取数据，可以将其看成是byte数组\n适合存储大量的联系的数据的布尔值\\\n\n## 实际应用\n\n### UV（Unique Visitor）\n\n独立访客，需通过用户ip排重统计数据。\n每次访问都要进行统计\nHyperLogLog，性能好且存储空间小\n\n### DAU（Daily Active User）\n\n日活跃用户，需通过用户ID排重统计数据\n访问过一次，则认为其活跃\nBitMap，性能好且可以统计精确的结果\n\n# Kafka\n\n## 消息系统介绍\n\n一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：**点对点传递模式、发布-订阅模式**。大部分的消息系统选用发布-订阅模式。**Kafka就是一种发布-订阅模式**。\n\n### 点对点消息传递模式\n\n在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29TsMrFYg0AgY0k9-/root/content)\n\n\n\n**生产者发送一条消息到queue，只有一个消费者能收到**。\n\n### 发布-订阅消息传递模式\n\n在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：\n\n![img](https://gitee.com/brook2bubble/pic-go/raw/master/img/1228818-20180507190443404-1266011458.png)\n\n**发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息**。\n\n## Kafka的优点\n\n解耦  冗余（副本） 扩展性 灵活性&峰值处理能力 可恢复性　顺序保证　缓冲　异步通信\n\n## 术语解释\n\n### 概述\n\n在深入理解Kafka之前，先介绍一下Kafka中的术语。下图展示了Kafka的相关术语以及之间的关系：\n\n![img](https://gitee.com/brook2bubble/pic-go/raw/master/img/1228818-20180507190731172-1317551019.png)\n\n上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。\n\n如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。\n\n### broker\n\nKafka 集群包含一个或多个服务器，服务器节点称为broker。\n\nbroker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。\n\n如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。\n\n如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。\n\n### Topic\n\n每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n类似于数据库的表名\n\n### **Partition**\n\ntopic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。\n\n### Producer\n\n生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息**追加**到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。\n\n### Consumer\n\n消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。\n\n### Consumer Group\n\n每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\n### Leader\n\n每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。\n\n### Follower\n\nFollower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。\n\n## 配置\n\nE:\\Javastudy\\kafka\\kafka_2.13-2.8.0\\config\n\nzookeeper.properties  server.properties 更改存储位置\n\n## 启动\n\n### 启动zookeeper\n\n```\ne:\\Javastudy\\kafka\\kafka_2.13-2.8.0>bin\\windows\\zookeeper-server-start.bat config\\zookeeper.properties\n```\n\n### 启动kafka server\n\n```\ne:\\Javastudy\\kafka\\kafka_2.13-2.8.0>bin\\windows\\kafka-server-start.bat config\\server.properties\n```\n\n### 配置主题\n\n```\ne:\\Javastudy\\kafka\\kafka_2.13-2.8.0\\bin\\windows>kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test\nCreated topic test.\n// --replication-factor 1 用来设置主题的副本数。每个主题可以有多个副本，副本位于集群中不同的broker上，也就是说副本的数量不能超过broker的数量，否则创建主题时会失败。\n//localhost:9092 服务器地址  \n//--partitions 1   　主题分区数\n//--topic 主题名称\n```\n\n### 查看主题\n\n```\ne:\\Javastudy\\kafka\\kafka_2.13-2.8.0\\bin\\windows>kafka-topics.bat --list --bootstrap-server localhost:9092\ntest\n```\n\n### 创建消息（生产者）\n\n```\ne:\\Javastudy\\kafka\\kafka_2.13-2.8.0\\bin\\windows>kafka-console-producer.bat --broker-list localhost:9092 --topic test\n>hello\n```\n\n### 查看消息（消费者）\n\n```\ne:\\Javastudy\\kafka\\kafka_2.13-2.8.0\\bin\\windows>kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from-beginning\nhello\n```\n\n# spring整合kafka\n\n## 引入依赖\n\n```\n<dependency>\n    <groupId>org.springframework.kafka</groupId>\n    <artifactId>spring-kafka</artifactId>\n    <version>2.7.5</version>\n</dependency>\npom.xml\n```\n\n## 配置application.properties\n\n```\n#KafkaProperties\nspring.kafka.bootstrap-servers=localhost:9092\nspring.kafka.consumer.group-id=community-consumer-group \nspring.kafka.consumer.enable-auto-commit=true  //自动提交 \nspring.kafka.consumer.auto-commit-interval=3000  //自动提交间隔3s\n```\n\n\n\n\n\n# 系统消息通知\n\n点赞 评论 回复\n\n## 系统设计\n\n使用kafka消息分发，message表存储消息\n\n主要消息内容content采用json存储\n\n```\n{\"entityType\":1,\"entityId\":280,\"postId\":280,\"userId\":149}\n```\n\n### 实体类Event\n\n```\npublic class Event {\n    private String topic;\n    private int userId;\n    private int entityType;\n    private int entityId;\n    private int entityUserId;\n    private Map<String,Object> data = new HashMap<>();\n    public String getTopic() {\n        return topic;\n    }\n    public Event setTopic(String topic) {\n        this.topic = topic;\n        return this;\n    }\n    public int getUserId() {\n        return userId;\n    }\n    public Event setUserId(int userId) {\n        this.userId = userId;\n        return this;\n    }\n    public int getEntityType() {\n        return entityType;\n    }\n    public Event setEntityType(int entityType) {\n        this.entityType = entityType;\n        return this;\n    }\n    public int getEntityId() {\n        return entityId;\n    }\n    public Event setEntityId(int entityId) {\n        this.entityId = entityId;\n        return this;\n    }\n    public int getEntityUserId() {\n        return entityUserId;\n    }\n    public Event setEntityUserId(int entityUserId) {\n        this.entityUserId = entityUserId;\n        return this;\n    }\n    public Map<String, Object> getData() {\n        return data;\n    }\n    public Event setData(String key, Object value) {\n        this.data.put(key,value);\n        return this;\n    }\n}\n```\n\n### 设置kafka eventConsumer eventProducer\n\n在conroller层触发点赞关注回复事件时调用eventProducer.fireEvent（event）向用户发送消息\n\n### 用户在消息页面查看所有消息\n\n```\n查看系统通知详情页 分类显示\n但是原项目查看点赞回复时是直接到相应帖子首页\n后续想实现直接跳转到具体点赞和回复所在的页面\n```\n\n```\n1.新加查询 \n通过message表中消息create_time\n在comment中查询相应的排序数 通过（i-1）/5 +1 为sortNo值\n然后通过controller传递给页面，页面因为本身还要传递postId 就需要th：href解析两个变量\n之前是\nth:href=\"@{|/discuss/detail/${map.postId}|}\"\n解析后地址http://localhost:8080/community/discuss/detail/283\n实现方式为\nth:href=\"${'/community/discuss/detail/'}+${map.postId}+${'?current='}+${map.sortNo}\"\n解析后地址http://localhost:8080/community/discuss/detail/283?current=1\n\n但是由于点赞关注采用Redis实现 两个表的相关数据创建时间出现了偏差，导致系统查询排序数返回null 导致500错误，只能从底层改造\n\n\n\n\n```\n\n2.在消息content中加入sortNo\n\nCommentController\n\n```\n//触发评论事件\n        Event event = new Event()\n                .setTopic(TOPIC_COMMENT)\n                .setUserId(hostHolder.getUser().getId())\n                .setEntityType(comment.getEntityType())\n                .setEntityId(comment.getEntityId())\n                .setData(\"postId\",discussPostId);\n\n        if (comment.getEntityType()== ENTITY_TYPE_POST){\n            DiscussPost target = discussPostService.findDiscussPostById(comment.getEntityId());\n            event.setEntityUserId(target.getUserId())\n                    .setData(\"sortNo\",commentService.findIdFromCreateDate(comment.getCreateTime()));\n        }\n        eventProducer.fireEvent(event);\n```\n\nMessageController\n\n```\n/**\n                 * 如果topic是评论帖子或者回复就返回到该评论所在页数\n                 * 如果topic是点赞帖子 返回帖子 点赞对象是评论就返回到评论所在页数\n                 */\n                if(topic.equals(TOPIC_COMMENT)){\n                    int sortNo = 0;\n                    if ((Integer)data.get(\"entityType\")==ENTITY_TYPE_POST){\n                       sortNo= commentService.findCommentSortById(ENTITY_TYPE_POST, (Integer) data.get(\"postId\"), (Integer) data.get(\"sortNo\"));\n                    }else if ((Integer)data.get(\"entityType\")==ENTITY_TYPE_COMMENT){\n                        sortNo= commentService.findCommentSortById(ENTITY_TYPE_POST, (Integer) data.get(\"postId\"), (Integer) data.get(\"entityId\"));\n\n                    }\n                    sortNo = (sortNo - 1) / 5 + 1;\n                        map.put(\"sortNo\",sortNo);\n                }\n                if(topic.equals(TOPIC_LIKE)){\n                    int sortNo = 0;\n                    if ((Integer)data.get(\"entityType\")==ENTITY_TYPE_COMMENT){\n                        Comment comment = commentService.findCommentById((Integer) data.get(\"entityId\"));\n                        if (comment.getEntityType() == ENTITY_TYPE_POST){\n                            sortNo= commentService.findCommentSortById(ENTITY_TYPE_POST, (Integer) data.get(\"postId\"), (Integer) data.get(\"entityId\"));\n                        }else if (comment.getEntityType() == ENTITY_TYPE_COMMENT){\n                            sortNo= commentService.findCommentSortById(ENTITY_TYPE_POST, (Integer) data.get(\"postId\"), comment.getEntityId());\n                        }\n\n\n                        sortNo = (sortNo - 1) / 5 + 1;\n                    }\n\n                    map.put(\"sortNo\",sortNo);\n                }\n```\n\n# ElasticSearch\n\n```\nhttps://zhuanlan.zhihu.com/p/358744225\n```\n\n\n\n## 下载安装\n\n```\nhttps://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0-windows-x86_64.zip\n```\n\n直接解压到文件夹Javastudy/elasticSearch\n\n## 配置\n\nconfig/elasticsearch.yml\n\n```\ncluster.name: brook\nnode.name: node01\npath.data: e:\\Javastudy\\data\\elasticsearch-7.12.1\\data\npath.logs: e:\\Javastudy\\data\\elasticsearch-7.12.1\\logs\ncluster.initial_master_nodes: [\"node01\"]\n```\n\n## 添加中文的分词插件\n\n默认是英文分词\n\n```\nhttps://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.12.1\n```\n\n解压到\n\n```\nE:\\Javastudy\\elasticsearch-7.12.1\\plugins\\ik\n```\n\n## 启动与使用\n\nbin目录 .bat\n\n查看健康状况\n\n```\ncurl -X GET \"localhost:9200/_cat/health?v\"\n```\n\n```\n查看节点数\nC:\\Users\\dgx19>curl -X GET \"localhost:9200/_cat/nodes?v\"\nip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name\n127.0.0.1           28          60  23                          cdfhilmrstw *      BROOK\n```\n\n```\n创建和查看索引\nC:\\Users\\dgx19>curl -X PUT \"localhost:9200/test\"\n{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"test\"}\nC:\\Users\\dgx19>curl -X GET \"localhost:9200/_cat/indices?v\"\nhealth status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   test  f1n0-1QkQjOB8aDSiEGFOA   1   1          0            0       208b           208b\n```\n\n```\n删除索引\nC:\\Users\\dgx19>curl -X DELETE \"localhost:9200/test\"\n{\"acknowledged\":true}\n```\n\n\n\n## Postman安装与使用\n\nPostman一款非常流行的API调试工具。其实，开发人员用的更多。因为测试人员做接口测试会有更多选择，例如Jmeter、soapUI等。不过，对于开发过程中去调试接口，Postman确实足够的简单方便，而且功能强大\n\n### 安装\n\n1、Postman最早是作用chrome浏览器插件存在的，所以，你可以到chrome商店搜索下载安装，因为重所周知的原因，所以，大家都会找别人共享的postman插件文件来安装。由于2018年初Chrome停止对Chrome应用程序的支持。\n\n2、Postman提供了独立的安装包，不再依赖于Chrome浏览器了。同时支持MAC、Windows和Linux，推荐你使用这种方式安装。\n\n```\nhttps://dl.pstmn.io/download/latest/win64\n```\n\n### 使用\n\n#### 查询\n\n#### 创建\n\n#### 删除\n\n```\nDELETE　　　　　　localhost:9200/test\n```\n\n#### 创建表数据\n\nlocalhost:9200/test/_doc/1　　test下id为1的数据提交   __doc是占位符\n\n#### 查询表数据\n\n```\nGET      localhost:9200/_search?q=content:个人 关键词“个人”查询 单选项查询\n```\n\n#### 多个索引\n\n在body中用json格式查询\n\n```\nGET  localhost:9200/_search\nbody:\n{\n    \"query\":{\n        \"multi_match\":{\n            \"query\":\"论坛\",\n            \"fields\":[\"title\",\"content\"]\n        }\n    }\n}\n```\n\n# Spring整合ElasticeSearch\n\nhttps://www.freesion.com/article/41621087939/\n\nhttps://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.12/java-rest-high-getting-started-initialization.html\n\nhttps://cloud.tencent.com/developer/article/1795660?from=article.detail.1757034\n\n\n\n引入依赖\n\n   -spring-boot-start-data-elasticsearch\n\n配置Elasticsearch\n\n  -cluster-name、cluster-nodes\n\nSpring Data Elasticsearch\n\n  -ElastcsearchTemple  过时了 不再使用 使用ElasticsearchRestTemplate\n\n  -ElasticsearchRespository search方法也过时了改用ElasticsearchRestTemplate的search()方法\n\n## 注意\n\nElasticsearchTemplate不建议使用了，改为使用ElasticsearchRestTemplate，ElasticsearchRepository实现复杂查询的方法也不建议使用了。从此我们简单的数据操作可以使用ElasticsearchRepository，而复杂的数据操作只能使用ElasticsearchRestTemplate了\n\n## Maven引入依赖\n\n```\n <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-data-elasticsearch</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.elasticsearch</groupId>\n            <artifactId>elasticsearch</artifactId>\n            <version>7.12.1</version>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.elasticsearch</groupId>\n            <artifactId>elasticsearch</artifactId>\n        </dependency>\n\n```\n\n## application.properties\n\ncluster-nodes=\n\ncluster-name=  不再使用\n\n```\n#ElasticsearchProperties\n//端口配置\nspring.elasticsearch.rest.uris=localhost:9200\nspring.data.elasticsearch.repositories.enabled = true\n```\n\n```\n@Repository\npublic interface DiscussPostRepository extends ElasticsearchRepository<DiscussPost,Integer> {\n}\n```\n\n### 接口需要继承ElasticSearchRepository\n\n```java\n@Repository\npublic interface ItemRepository extends ElasticsearchRepository<Item, Long> {\n\n}\n```\n\n### 接口基础用法\n\n#### 实体类\n\n```java\n@Document(indexName = \"discusspost\")\npublic class DiscussPost {\n    @Id\n    private int id;\n\n    @Field(type = FieldType.Integer)\n    private int userId;\n\n    @Field(type = FieldType.Text,analyzer = \"ik_max_word\",searchAnalyzer = \"ik_smart\")\n    private  String title;\n\n    @Field(type = FieldType.Text,analyzer = \"ik_max_word\",searchAnalyzer = \"ik_smart\")\n    private  String content;\n\n    @Field(type = FieldType.Integer)\n    private int type;\n    @Field(type = FieldType.Integer)\n    private int status;\n    @Field(type =FieldType.Date)\n    private Date createTime;\n    @Field(type = FieldType.Integer)\n    private int commentCount;\n    @Field(type = FieldType.Double)\n    private  int score;\n}\n```\n\n#### ElasticSearchRepository已封装方法\n\n```java\n  @Autowired\n    private DiscussPostRepository discussPostRepository;\n @Autowired\n    private ElasticsearchRestTemplate elasticsearchRestTemplate;\n\n public void saveDiscussPost(DiscussPost post){\n        discussPostRepository.save(post);\n    }\n    public void deleteDiscussPost(int id){\n        discussPostRepository.deleteById(id);\n    }\n\n//保存 或 更新\nitemRepository.save(item);\n//删除\nitemRepository.deleteById(id);\n\n/**\n     * 通过id获取信息\n     *\n     * @param id id\n     * @return {@link Item}\n     */\npublic Item esGetInfoById(Long id){\n     Optional<Item> item = itemRepository.findById(id); \n     return  item.get();\n}\n```\n\n基于SPRINGBOOT解决ELASTICSEARCH与REDIS的NETTY冲突问题https://www.freesion.com/article/59921236212/\n\n# 项目进阶\n\n## Spring Scurity\n\n### 简介\n\nSpring Security是一个功能强大且高度可定制的身份验证和访问控制框架。提供了完善的**认证机制**和方法级的**授权功能**。是一款非常优秀的权限管理框架。它的核心是一组过滤器链，不同的功能经由不同的过滤器。\n\n一般来说，常见的安全管理技术栈的组合是这样的：\n\n- SSM + Shiro\n- Spring Boot/Spring Cloud + Spring Security\n\n### 特征\n\n  身份的认证和授权\n\n  防止各种攻击\n\n  支持与Servlet API Spring MVC 等web技术集成\n\n### 原理\n\n- 底层使用Filter（javaEE标准）进行拦截\n- Filter-->DispatchServlet-->Interceptor-->Controller(后三者属于Spring MVC)\n\n\n\n## 任务的执行和调度\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29T4SYDBj70musnkc/root/content)\n\n\n\n# Spring MVC\n\n![](https://api.onedrive.com/v1.0/shares/s!AtrhubmDW-n29T_o0NVF6rCvlfok/root/content)\n\n# 项目问题解决\n\n## 1.AOP没生效\n\n### 解决：没有引入aop依赖，不需要引入aspectJ\n\n```\n <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-aop</artifactId>\n        </dependency>\n```\n\n# 设计模式\n\nhttps://www.yimipuzi.com/1156.html\n\n","tags":["project","spring","spring-boot","Maven"],"categories":["项目"]},{"title":"口水鸡","url":"/2021/02/11/口水鸡/","content":"\n# 材料\n\n制作口水鸡需要的材料：\n\n土鸡一只，大葱两根，生姜3块，大蒜6颗，青花椒十几个，料酒30克，小米辣4个，食用盐适量，白糖3克，生抽酱油10克，香醋2克，煮鸡的原汤5克，辣椒红油适量，青花椒面适量。\n\n# 步骤\n\n1、将土鸡整个清理干净，将大葱切成段，生姜拍碎，净锅装满清水，然后将准备好的葱姜下锅，加入食用盐10克，料酒30克，然后将整个鸡下入锅中开大火烧开，中途再加入十几个青花椒去除异味，水开之后关火盖上锅盖将鸡浸泡40分钟，这样可以使鸡肉浸泡熟透，40分钟以后将鸡捞出放入冷水中冷却透凉，这样鸡肉的皮会更紧实滑嫩。\n\n2、我们开始准备料汁：石臼中加入去皮生姜15克，大蒜15克，加入4个小米辣，然后用石臼捣碎，如果想捣的容易一点，可以把生姜、大蒜和小米辣切的碎一点再捣，捣碎以后放入一个干净的碗中，然后加入食用盐2克、白糖3克、生抽酱油10克、香醋2克、煮鸡的原汤5克搅拌均匀备用，然后加入适量的辣椒红油、适量的青花椒面搅拌均匀备用。\n\n3、将冷却好的鸡腿和鸡翅膀取下，然后将鸡肉剁成大小均匀的小块放入盘中备用，然后将调好的料汁均匀的淋到鸡肉上面，然后撒上适量的葱花即可上菜，一道美味的口水鸡就做好了。\n\n# 注意事项\n\n制作口水鸡需要注意的事项：\n\n1、鸡的品种可以自由选择，也可以用三黄鸡来制作，也可以买鲜鸡腿或者冻鸡腿。\n\n2、料汁加红油可以适量加多一点。\n\n3、用石臼捣碎可以使材料的香味更浓郁。\n","tags":["日常","美食","记录"],"categories":["日常"]},{"title":"Mysql数据库","url":"/2020/01/26/Mysql数据库/","content":"\n\n\n## 一、基础\n\n模式定义了数据如何存储、存储什么样的数据以及数据如何分解等信息，数据库和表都有模式。\n\n主键的值不允许修改，也不允许复用（不能将已经删除的主键值赋给新数据行的主键）。\n\nSQL（Structured Query Language)，标准 SQL 由 ANSI 标准委员会管理，从而称为 ANSI SQL。各个 DBMS 都有自己的实现，如 PL/SQL、Transact-SQL 等。\n\n**DDL：Data Definition Language**\n\nDDL允许用户定义数据，也就是创建表、删除表、修改表结构这些操作。通常，DDL由数据库管理员执行。\n\n**DML：Data Manipulation Language**\n\nDML为用户提供添加、删除、更新数据的能力，这些是应用程序对数据库的日常操作。\n\n**DQL：Data Query Language**\n\nDQL允许用户查询数据，这也是通常最频繁的数据库日常操作。\n\nSQL 语句不区分大小写，但是数据库表名、列名和值是否区分依赖于具体的 DBMS 以及配置。\n\nSQL 支持以下三种注释：\n\n```sql\n## 注释\nSELECT *\nFROM mytable; -- 注释\n/* 注释1\n   注释2 */\n```\n\n数据库创建与使用：\n\n```sql\nCREATE DATABASE test;\nUSE test;\n```\n\n\n\n## 二、创建表\n\n```sql\nCREATE TABLE mytable (\n  # int 类型，不为空，自增\n  id INT NOT NULL AUTO_INCREMENT,\n  # int 类型，不可为空，默认值为 1，不为空\n  col1 INT NOT NULL DEFAULT 1,\n  # 变长字符串类型，最长为 45 个字符，可以为空\n  col2 VARCHAR(45) NULL,\n  # 日期类型，可为空\n  col3 DATE NULL,\n  # 设置主键为 id\n  PRIMARY KEY (`id`));\n```\n\n## 三、修改表\n\n添加列\n\n```sql\nALTER TABLE mytable\nADD col CHAR(20);\n```\n\n删除列\n\n```sql\nALTER TABLE mytable\nDROP COLUMN col;\n```\n\n删除表\n\n```sql\nDROP TABLE mytable;\n```\n\n## 四、插入\n\n普通插入\n\n```sql\nINSERT INTO mytable(col1, col2)\nVALUES(val1, val2);\n```\n\n插入检索出来的数据\n\n```sql\nINSERT INTO mytable1(col1, col2)\nSELECT col1, col2\nFROM mytable2;\n```\n\n将一个表的内容插入到一个新表\n\n```sql\nCREATE TABLE newtable ASSELECT * FROM mytable;\n```\n\n## 五、更新\n\n```sql\nUPDATE mytableSET col = valWHERE id = 1;\n```\n\n## 六、删除\n\n```sql\nDELETE FROM mytableWHERE id = 1;\n```\n\n**TRUNCATE TABLE** 可以清空表，也就是删除所有行。\n\n```sql\nTRUNCATE TABLE mytable;\n```\n\n使用更新和删除操作时一定要用 WHERE 子句，不然会把整张表的数据都破坏。可以先用 SELECT 语句进行测试，防止错误删除。\n\n## 七、查询\n\n### DISTINCT\n\n相同值只会出现一次。它作用于所有列，也就是说所有列的值都相同才算相同。\n\n```sql\nSELECT DISTINCT col1, col2FROM mytable;\n```\n\n### LIMIT\n\n限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。\n\n返回前 5 行：\n\n```sql\nSELECT *FROM mytableLIMIT 5;SELECT *FROM mytableLIMIT 0, 5;\n```\n\n返回第 3 ~ 5 行：\n\n```sql\nSELECT *FROM mytableLIMIT 2, 3;\n```\n\n## 八、排序\n\n- **ASC** ：升序（默认）\n- **DESC** ：降序\n\n可以按多个列进行排序，并且为每个列指定不同的排序方式：\n\n```sql\nSELECT *FROM mytableORDER BY col1 DESC, col2 ASC;\n```\n\n## 九、过滤\n\n不进行过滤的数据非常大，导致通过网络传输了多余的数据，从而浪费了网络带宽。因此尽量使用 SQL 语句来过滤不必要的数据，而不是传输所有的数据到客户端中然后由客户端进行过滤。\n\n```sql\nSELECT *FROM mytableWHERE col IS NULL;\n```\n\n下表显示了 WHERE 子句可用的操作符\n\n| 操作符  |     说明     |\n| :-----: | :----------: |\n|    =    |     等于     |\n|    <    |     小于     |\n|    >    |     大于     |\n|  <> !=  |    不等于    |\n|  <= !>  |   小于等于   |\n|  >= !<  |   大于等于   |\n| BETWEEN | 在两个值之间 |\n| IS NULL |  为 NULL 值  |\n\n应该注意到，NULL 与 0、空字符串都不同。\n\n**AND 和 OR** 用于连接多个过滤条件。优先处理 AND，当一个过滤表达式涉及到多个 AND 和 OR 时，可以使用 () 来决定优先级，使得优先级关系更清晰。\n\n**IN** 操作符用于匹配一组值，其后也可以接一个 SELECT 子句，从而匹配子查询得到的一组值。\n\n**NOT** 操作符用于否定一个条件。\n\n## 十、通配符\n\n通配符也是用在过滤语句中，但它只能用于文本字段。\n\n- **%** 匹配 >=0 个任意字符；\n- **_** 匹配 ==1 个任意字符；\n- **[ ]** 可以匹配集合内的字符，例如 [ab] 将匹配字符 a 或者 b。用脱字符 ^ 可以对其进行否定，也就是不匹配集合内的字符。\n\n使用 Like 来进行通配符匹配。\n\n```sql\nSELECT *FROM mytableWHERE col LIKE '[^AB]%'; -- 不以 A 和 B 开头的任意文本\n```\n\n不要滥用通配符，通配符位于开头处匹配会非常慢。\n\n## 十一、计算字段\n\n在数据库服务器上完成数据的转换和格式化的工作往往比客户端上快得多，并且转换和格式化后的数据量更少的话可以减少网络通信量。\n\n计算字段通常需要使用 **AS** 来取别名，否则输出的时候字段名为计算表达式。\n\n```sql\nSELECT col1 * col2 AS aliasFROM mytable;\n```\n\n**CONCAT()** 用于连接两个字段。许多数据库会使用空格把一个值填充为列宽，因此连接的结果会出现一些不必要的空格，使用 **TRIM()** 可以去除首尾空格。\n\n```sql\nSELECT CONCAT(TRIM(col1), '(', TRIM(col2), ')') AS concat_colFROM mytable;\n```\n\n## 十二、函数\n\n各个 DBMS 的函数都是不相同的，因此不可移植，以下主要是 MySQL 的函数。\n\n### 汇总\n\n|  函 数  |      说 明       |\n| :-----: | :--------------: |\n|  AVG()  | 返回某列的平均值 |\n| COUNT() |  返回某列的行数  |\n|  MAX()  | 返回某列的最大值 |\n|  MIN()  | 返回某列的最小值 |\n|  SUM()  |  返回某列值之和  |\n\nAVG() 会忽略 NULL 行。\n\n使用 DISTINCT 可以汇总不同的值。\n\n```sql\nSELECT AVG(DISTINCT col1) AS avg_colFROM mytable;\n```\n\n### 文本处理\n\n|   函数    |      说明      |\n| :-------: | :------------: |\n|  LEFT()   |   左边的字符   |\n|  RIGHT()  |   右边的字符   |\n|  LOWER()  | 转换为小写字符 |\n|  UPPER()  | 转换为大写字符 |\n|  LTRIM()  | 去除左边的空格 |\n|  RTRIM()  | 去除右边的空格 |\n| LENGTH()  |      长度      |\n| SOUNDEX() |  转换为语音值  |\n\n其中， **SOUNDEX()** 可以将一个字符串转换为描述其语音表示的字母数字模式。\n\n```sql\nSELECT *FROM mytableWHERE SOUNDEX(col1) = SOUNDEX('apple')\n```\n\n### 日期和时间处理\n\n- 日期格式：YYYY-MM-DD\n- 时间格式：HH:<zero-width space>MM:SS\n\n|     函 数     |             说 明              |\n| :-----------: | :----------------------------: |\n|   ADDDATE()   |    增加一个日期（天、周等）    |\n|   ADDTIME()   |    增加一个时间（时、分等）    |\n|   CURDATE()   |          返回当前日期          |\n|   CURTIME()   |          返回当前时间          |\n|    DATE()     |     返回日期时间的日期部分     |\n|  DATEDIFF()   |        计算两个日期之差        |\n|  DATE_ADD()   |     高度灵活的日期运算函数     |\n| DATE_FORMAT() |  返回一个格式化的日期或时间串  |\n|     DAY()     |     返回一个日期的天数部分     |\n|  DAYOFWEEK()  | 对于一个日期，返回对应的星期几 |\n|    HOUR()     |     返回一个时间的小时部分     |\n|   MINUTE()    |     返回一个时间的分钟部分     |\n|    MONTH()    |     返回一个日期的月份部分     |\n|     NOW()     |       返回当前日期和时间       |\n|   SECOND()    |      返回一个时间的秒部分      |\n|    TIME()     |   返回一个日期时间的时间部分   |\n|    YEAR()     |     返回一个日期的年份部分     |\n\n```sql\nmysql> SELECT NOW();2018-4-14 20:25:11\n```\n\n### 数值处理\n\n|  函数  |  说明  |\n| :----: | :----: |\n| SIN()  |  正弦  |\n| COS()  |  余弦  |\n| TAN()  |  正切  |\n| ABS()  | 绝对值 |\n| SQRT() | 平方根 |\n| MOD()  |  余数  |\n| EXP()  |  指数  |\n|  PI()  | 圆周率 |\n| RAND() | 随机数 |\n\n## 十三、分组\n\n把具有相同的数据值的行放在同一组中。\n\n可以对同一分组数据使用汇总函数进行处理，例如求分组数据的平均值等。\n\n指定的分组字段除了能按该字段进行分组，也会自动按该字段进行排序。\n\n```sql\nSELECT col, COUNT(*) AS numFROM mytableGROUP BY col;\n```\n\nGROUP BY 自动按分组字段进行排序，ORDER BY 也可以按汇总字段来进行排序。\n\n```sql\nSELECT col, COUNT(*) AS numFROM mytableGROUP BY colORDER BY num;\n```\n\nWHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤。\n\n```sql\nSELECT col, COUNT(*) AS numFROM mytableWHERE col > 2GROUP BY colHAVING num >= 2;\n```\n\n分组规定：\n\n- GROUP BY 子句出现在 WHERE 子句之后，ORDER BY 子句之前；\n- 除了汇总字段外，SELECT 语句中的每一字段都必须在 GROUP BY 子句中给出；\n- NULL 的行会单独分为一组；\n- 大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型。\n\n## 十四、子查询\n\n子查询中只能返回一个字段的数据。\n\n可以将子查询的结果作为 WHRER 语句的过滤条件：\n\n```sql\nSELECT *FROM mytable1WHERE col1 IN (SELECT col2               FROM mytable2);\n```\n\n下面的语句可以检索出客户的订单数量，子查询语句会对第一个查询检索出的每个客户执行一次：\n\n```sql\nSELECT cust_name, (SELECT COUNT(*)                   FROM Orders                   WHERE Orders.cust_id = Customers.cust_id)                   AS orders_numFROM CustomersORDER BY cust_name;\n```\n\n## 十五、连接\n\n连接用于连接多个表，使用 JOIN 关键字，并且条件语句使用 ON 而不是 WHERE。\n\n连接可以替换子查询，并且比子查询的效率一般会更快。\n\n可以用 AS 给列名、计算字段和表名取别名，给表名取别名是为了简化 SQL 语句以及连接相同表。\n\n### 内连接\n\n内连接又称等值连接，使用 INNER JOIN 关键字。\n\n```sql\nSELECT A.value, B.valueFROM tablea AS A INNER JOIN tableb AS BON A.key = B.key;\n```\n\n可以不明确使用 INNER JOIN，而使用普通查询并在 WHERE 中将两个表中要连接的列用等值方法连接起来。\n\n```sql\nSELECT A.value, B.valueFROM tablea AS A, tableb AS BWHERE A.key = B.key;\n```\n\n### 自连接\n\n自连接可以看成内连接的一种，只是连接的表是自身而已。\n\n一张员工表，包含员工姓名和员工所属部门，要找出与 Jim 处在同一部门的所有员工姓名。\n\n子查询版本\n\n```sql\nSELECT nameFROM employeeWHERE department = (      SELECT department      FROM employee      WHERE name = \"Jim\");\n```\n\n自连接版本\n\n```sql\nSELECT e1.nameFROM employee AS e1 INNER JOIN employee AS e2ON e1.department = e2.department      AND e2.name = \"Jim\";\n```\n\n### 自然连接\n\n自然连接是把同名列通过等值测试连接起来的，同名列可以有多个。\n\n内连接和自然连接的区别：内连接提供连接的列，而自然连接自动连接所有同名列。\n\n```sql\nSELECT A.value, B.valueFROM tablea AS A NATURAL JOIN tableb AS B;\n```\n\n### 外连接\n\n外连接保留了没有关联的那些行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。\n\n检索所有顾客的订单信息，包括还没有订单信息的顾客。\n\n```sql\nSELECT Customers.cust_id, Customer.cust_name, Orders.order_idFROM Customers LEFT OUTER JOIN OrdersON Customers.cust_id = Orders.cust_id;\n```\n\ncustomers 表：\n\n| cust_id | cust_name |\n| :-----: | :-------: |\n|    1    |     a     |\n|    2    |     b     |\n|    3    |     c     |\n\norders 表：\n\n| order_id | cust_id |\n| :------: | :-----: |\n|    1     |    1    |\n|    2     |    1    |\n|    3     |    3    |\n|    4     |    3    |\n\n结果：\n\n| cust_id | cust_name | order_id |\n| :-----: | :-------: | :------: |\n|    1    |     a     |    1     |\n|    1    |     a     |    2     |\n|    3    |     c     |    3     |\n|    3    |     c     |    4     |\n|    2    |     b     |   Null   |\n\n## 十六、组合查询\n\n使用 **UNION** 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。\n\n每个查询必须包含相同的列、表达式和聚集函数。\n\n默认会去除相同行，如果需要保留相同行，使用 UNION ALL。\n\n只能包含一个 ORDER BY 子句，并且必须位于语句的最后。\n\n```sql\nSELECT colFROM mytableWHERE col = 1UNIONSELECT colFROM mytableWHERE col =2;\n```\n\n## 十七、视图\n\n视图是虚拟的表，本身不包含数据，也就不能对其进行索引操作。\n\n对视图的操作和对普通表的操作一样。\n\n视图具有如下好处：\n\n- 简化复杂的 SQL 操作，比如复杂的连接；\n- 只使用实际表的一部分数据；\n- 通过只给用户访问视图的权限，保证数据的安全性；\n- 更改数据格式和表示。\n\n```sql\nCREATE VIEW myview ASSELECT Concat(col1, col2) AS concat_col, col3*col4 AS compute_colFROM mytableWHERE col5 = val;\n```\n\n## 十八、存储过程\n\n存储过程可以看成是对一系列 SQL 操作的批处理。\n\n使用存储过程的好处：\n\n- 代码封装，保证了一定的安全性；\n- 代码复用；\n- 由于是预先编译，因此具有很高的性能。\n\n命令行中创建存储过程需要自定义分隔符，因为命令行是以 ; 为结束符，而存储过程中也包含了分号，因此会错误把这部分分号当成是结束符，造成语法错误。\n\n包含 in、out 和 inout 三种参数。\n\n给变量赋值都需要用 select into 语句。\n\n每次只能给一个变量赋值，不支持集合的操作。\n\n```sql\ndelimiter //create procedure myprocedure( out ret int )    begin        declare y int;        select sum(col1)        from mytable        into y;        select y*y into ret;    end //delimiter ;call myprocedure(@ret);select @ret;\n```\n\n##十九、游标\n\n在存储过程中使用游标可以对一个结果集进行移动遍历。\n\n游标主要用于交互式应用，其中用户需要对数据集中的任意行进行浏览和修改。\n\n使用游标的四个步骤：\n\n1. 声明游标，这个过程没有实际检索出数据；\n2. 打开游标；\n3. 取出数据；\n4. 关闭游标；\n\n```sql\ndelimiter //create procedure myprocedure(out ret int)    begin        declare done boolean default 0;        declare mycursor cursor for        select col1 from mytable;        # 定义了一个 continue handler，当 sqlstate '02000' 这个条件出现时，会执行 set done = 1        declare continue handler for sqlstate '02000' set done = 1;        open mycursor;        repeat            fetch mycursor into ret;            select ret;        until done end repeat;        close mycursor;    end // delimiter ;\n```\n\n## 二十、触发器\n\n触发器会在某个表执行以下语句时而自动执行：DELETE、INSERT、UPDATE。\n\n触发器必须指定在语句执行之前还是之后自动执行，之前执行使用 BEFORE 关键字，之后执行使用 AFTER 关键字。BEFORE 用于数据验证和净化，AFTER 用于审计跟踪，将修改记录到另外一张表中。\n\nINSERT 触发器包含一个名为 NEW 的虚拟表。\n\n```sql\nCREATE TRIGGER mytrigger AFTER INSERT ON mytableFOR EACH ROW SELECT NEW.col into @result;SELECT @result; -- 获取结果\n```\n\nDELETE 触发器包含一个名为 OLD 的虚拟表，并且是只读的。\n\nUPDATE 触发器包含一个名为 NEW 和一个名为 OLD 的虚拟表，其中 NEW 是可以被修改的，而 OLD 是只读的。\n\nMySQL 不允许在触发器中使用 CALL 语句，也就是不能调用存储过程。\n\n##二十一、事务管理\n\n基本术语：\n\n- 事务（transaction）指一组 SQL 语句；\n- 回退（rollback）指撤销指定 SQL 语句的过程；\n- 提交（commit）指将未存储的 SQL 语句结果写入数据库表；\n- 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）。\n\n不能回退 SELECT 语句，回退 SELECT 语句也没意义；也不能回退 CREATE 和 DROP 语句。\n\nMySQL 的事务提交默认是隐式提交，每执行一条语句就把这条语句当成一个事务然后进行提交。当出现 START TRANSACTION 语句时，会关闭隐式提交；当 COMMIT 或 ROLLBACK 语句执行后，事务会自动关闭，重新恢复隐式提交。\n\n设置 autocommit 为 0 可以取消自动提交；autocommit 标记是针对每个连接而不是针对服务器的。\n\n如果没有设置保留点，ROLLBACK 会回退到 START TRANSACTION 语句处；如果设置了保留点，并且在 ROLLBACK 中指定该保留点，则会回退到该保留点。\n\n```sql\nSTART TRANSACTION// ...SAVEPOINT delete1// ...ROLLBACK TO delete1// ...COMMIT\n```\n\n##二十二、字符集\n\n基本术语：\n\n- 字符集为字母和符号的集合；\n- 编码为某个字符集成员的内部表示；\n- 校对字符指定如何比较，主要用于排序和分组。\n\n除了给表指定字符集和校对外，也可以给列指定：\n\n```sql\nCREATE TABLE mytable(col VARCHAR(10) CHARACTER SET latin COLLATE latin1_general_ci )DEFAULT CHARACTER SET hebrew COLLATE hebrew_general_ci;\n```\n\n可以在排序、分组时指定校对：\n\n```sql\nSELECT *FROM mytableORDER BY col COLLATE latin1_general_ci;\n```\n\n##二十三、权限管理\n\nMySQL 的账户信息保存在 mysql 这个数据库中。\n\n```sql\nUSE mysql;SELECT user FROM user;\n```\n\n**创建账户**\n\n新创建的账户没有任何权限。\n\n```sql\nCREATE USER myuser IDENTIFIED BY 'mypassword';\n```\n\n**修改账户名**\n\n```sql\nRENAME USER myuser TO newuser;\n```\n\n**删除账户**\n\n```sql\nDROP USER myuser;\n```\n\n**查看权限**\n\n```sql\nSHOW GRANTS FOR myuser;\n```\n\n**授予权限**\n\n账户用 username@host 的形式定义，username@% 使用的是默认主机名。\n\n```sql\nGRANT SELECT, INSERT ON mydatabase.* TO myuser;\n```\n\n**删除权限**\n\nGRANT 和 REVOKE 可在几个层次上控制访问权限：\n\n- 整个服务器，使用 GRANT ALL 和 REVOKE ALL；\n- 整个数据库，使用 ON database.*；\n- 特定的表，使用 ON database.table；\n- 特定的列；\n- 特定的存储过程。\n\n```sql\nREVOKE SELECT, INSERT ON mydatabase.* FROM myuser;\n```\n\n**更改密码**\n\n必须使用 Password() 函数进行加密。\n\n```sql\nSET PASSWROD FOR myuser = Password('new_password');\n```\n\n","tags":["learn","Mysql"],"categories":["学习"]},{"title":"Linux","url":"/2020/01/25/Linux/","content":"\n\n\n# Linux的概述\n\nUnix是一个强大的多用户、多任务操作系统。于1969年在AT&T的贝尔实验室开发。UNIX的商标权由国际开放标准组织（The Open Group）所拥有。UNIX操作系统是商业版，需要收费，价格比Microsoft Windows正版要贵一些。\n\nLinux是基于Unix的，Linux是一种自由和开放源码的操作系统，存在着许多不同的Linux版本，但它们都使用了Linux内核。Linux可安装在各种计算机硬件设备中，比如手机、平板电脑、路由器、台式计算机 诞生于1991 年10 月5 日。是由芬兰赫尔辛基大学学生Linus Torvalds和后来加入的众多爱好者共同开发完成。\n\n# Linux系统的应用\n\n服务器系统\n\n​            Web应用服务器、数据库服务器、接口服务器、DNS、FTP等等； \n\n嵌入式系统\n\n​       路由器、防火墙、手机、PDA、IP 分享器、交换器、家电用品的微电脑控制器等等，\n\n高性能运算、计算密集型应用\n\n​        Linux有强大的运算能力。\n\n桌面应用系统\n\n移动手持系统\n\n# Linux的目录结构 centos7\n\n├── bin -> usr/bin ............................ #：存放着一百多个Linux下常用的命令、工具\n├── boot .......................................... #： Linux就是从这里启动的\n├── dev ............................................ #：存放着Linux下所有的设备文件!\n├── etc ............................................. #：这里存放在Linux大部分的配置文件\n├── home ......................................... #：普通用户的家目录\n├── lib -> usr/lib ............................... #：静态链接库\n├── lib64 -> usr/lib64 ...................... #：库文件\n├── media ..........................................#：媒体\n├── mnt .............................................. #：用于存放挂在储存设备的挂载目录\n├── opt .............................................. #：空目录\n├── proc ............................................ #：存放进程文件\n├── root .............................................. #:超级用户root的家目录\n├── run ............................................... #：一些进程产生的临时文件，重启会消失\n├── sbin -> usr/sbin .............................#：超级用户命令所在地\n├── srv .................................................#：空目录 存放一些服务产生的文件\n├── sys ................................................#：存放一些内核文件\n├── tmp ............................................. #：临时目录\n├── usr ............................................ #： 应用程序存放目录\n└── var ........................................... #：通常用来存放一些变化中的东西!\n\n# Linux常用命令\n\n## 切换目录 cd\n\n## 列出文件列表 ls ll \n\n## 创建和移除目录 mkdir rmdir\n\n## 浏览文件 cat more less tail\n\n## 文件操作\n\n### 删除文件rm\n\n### 复制文件cp\n\n### 移动文件mv\n\n### 创建文件touch\n\n### 打包文件tar \n\n常用参数：\n\n-c：创建一个新tar文件\n\n-v：显示运行过程的信息\n\n-f：指定文件名\n\n-z：调用gzip压缩命令进行压缩\n\n-t：查看压缩文件的内容\n\n-x：解开tar文件\n\n打包：\n\ntar –cvf xxx.tar ./*\n\n打包并且压缩：\n\ntar –zcvf xxx.tar.gz ./* \n\n 解压 \n\ntar –xvf xxx.tar\n\ntar -xvf xxx.tar.gz -C /usr/aaa\n\n## 查找 grep\n\n### 显示当前目录 pwd\n\n# vi和vim编辑器\n\n## vim编辑器\n\n在Linux下一般使用vi编辑器来编辑文件。vi既可以查看文件也可以编辑文件。\n\n三种模式：命令行、插入、底行模式。\n\n切换到命令行模式：按Esc键；\n\n切换到插入模式：按 i 、o、a键；\n\n  i 在当前位置生前插入\n\n  I 在当前行首插入\n\n  a 在当前位置后插入\n\n  A 在当前行尾插入\n\n  o 在当前行之后插入一行\n\n  O 在当前行之前插入一行\n\n切换到底行模式：按 :（冒号）；更多详细用法，查询文档《Vim命令合集.docx》和《vi使用方法详细介绍.docx》\n\n打开文件：vim file\n\n退出：esc  : q\n\n修改文件：输入i进入插入模式\n\n保存并退出：es :wq\n\n不保存退出：es :q!\n\n3中进入插入模式：\n\ni:在当前的光标所在处插入\n\no:在当前光标所在的行的下一行插入\n\na:在光标所在的下一个字符插入\n\n快捷键：\n\ndd – 快速删除一行\n\nR – 替换\n\n## 重定向输出>和>>\n\n\\> 重定向输出，覆盖原有内容；>> 重定向输出，又追加功能；示例：\n\ncat /etc/passwd > a.txt  将输出定向到a.txt中\n\ncat /etc/passwd >> a.txt  输出并且追加\n\nifconfig > ifconfig.txt\n\n## 管道 |\n\n管道是Linux命令中重要的一个概念，其作用是将一个命令的输出用作另一个命令的输入。示例\n\nls --help | more  分页查询帮助信息\n\nps –ef | grep java  查询名称中包含java的进程\n\nifconfig | more\n\ncat index.html | more\n\nps –ef | grep aio\n\n## &&命令执行控制：\n\n命令之间使用 && 连接，实现逻辑与的功能。  \n\n只有在 && 左边的命令返回真（命令返回值 $? == 0），&& 右边的命令才会被执行。 \n\n只要有一个命令返回假（命令返回值 $? == 1），后面的命令就不会被执行。\n\nmkdir test && cd test\n\n## 网络通讯命令\n\nifconfig  显示或设置网络设备。\n\nifconfig  显示网络设备\n\nifconfig eth0 up 启用eth0网卡\n\nifconfig eth0 down  停用eth0网卡\n\nping  探测网络是否通畅。\n\n​        ping 192.168.0.1\n\nnetstat 查看网络端口。\n\n​       netstat -an | grep 3306 查询3306端口占用情况\n\n## 系统管理命令\n\ndate 显示或设置系统时间\n\ndate  显示当前系统时间\n\ndate -s “2014-01-01 10:10:10“  设置系统时间df 显示磁盘信息\n\ndf –h  友好显示大小free 显示内存状态\n\nfree –m 以mb单位显示内存组昂头top 显示，管理执行中的程序\n\nclear 清屏幕 \n\nps 正在运行的某个进程的状态\n\nps –ef  查看所有进程\n\nps –ef | grep ssh 查找某一进程kill 杀掉某一进程\n\nkill 2868  杀掉2868编号的进程\n\nkill -9 2868  强制杀死进程\n\ndu 显示目录或文件的大小。\n\ndu –h 显示当前目录的大小\n\nwho 显示目前登入系统的用户信息。 \n\nhostname 查看当前主机名\n\n修改：vi /etc/sysconfig/network \n\nuname 显示系统信息。\n\nuname -a 显示本机详细信息。依次为：内核名称(类别)，主机名，内核版本号，内核版本，内核编译日期，硬件名，处理器类型，硬件平台类型，操作系统名称\n\n# Linux的用户和组\n\n## 用户的管理\n\nuseradd 添加一个用户\n\nuseradd test 添加test用户\n\nuseradd test -d /home/t1  指定用户home目录 \n\npasswd  设置、修改密码\n\npasswd test  为test用户设置密码\n\n切换登录：\n\nssh -l test -p 22 192.168.19.128\n\nsu – 用户名\n\n userdel 删除一个用户\n\nuserdel test 删除test用户(不会删除home目录)\n\nuserdel –r test  删除用户以及home目录\n\n## 组管理：\n\n当在创建一个新用户user时，若没有指定他所属于的组，就建立一个和该用户同名的私有组 \n\n创建用户时也可以指定所在组 \n\ngroupadd  创建组\n\ngroupadd public  创建一个名为public的组\n\nuseradd u1 –g public  创建用户指定组groupdel 删除组，如果该组有用户成员，必须先删除用户才能删除组。\n\ngroupdel public\n\n## id，su命令\n\n【id命令】\n\n功能：查看一个用户的UID和GID用法：id [选项]... [用户名]\n\n直接使用id\n\n直接使用id 用户名\n\n【su命令】\n\n功能：切换用户。用法：su [选项]... [-] [用户 [参数]... ]\n\n示例：\n\n​      su u1  切换到u1用户\n\n​      su - u1 切换到u1用户，并且将环境也切换到u1用户的环境（推荐使用）\n\n【账户文件】\n\n/etc/passwd  用户文件\n\n/etc/shadow  密码文件\n\n/etc/group  组信息文件\n\n【用户文件】\n\nroot:x:0:0:root:/root:/bin/bash\n\n账号名称：\t\t在系统中是唯一的\n\n用户密码：\t\t此字段存放加密口令\n\n用户标识码(User ID)：  系统内部用它来标示\n\n用户组标识码(Group ID)：  系统内部用它来标识用户属性\n\n用户相关信息：\t\t例如用户全名等\n\n用户目录：\t\t用户登录系统后所进入的目录\n\n用户环境:\t\t用户工作的环境\n\n【密码文件】\n\nshadow文件中每条记录用冒号间隔的9个字段组成.\n\n用户名：用户登录到系统时使用的名字，而且是惟一的\n\n口令：  存放加密的口令\n\n最后一次修改时间:  标识从某一时刻起到用户最后一次修改时间\n\n最大时间间隔:  口令保持有效的最大天数，即多少天后必须修改口令\n\n最小时间间隔：\t再次修改口令之间的最小天数\n\n警告时间：从系统开始警告到口令正式失效的天数不\n\n活动时间：\t口令过期少天后，该账号被禁用\n\n失效时间：指示口令失效的绝对天数(从1970年1月1日开始计算)\n\n标志：未使用 \n\n【组文件】\n\nroot:x:0:\n\n组名：用户所属组\n\n组口令：一般不用\n\nGID：组ID\n\n用户列表：属于该组的所有用户\n\n# Linux的权限命令\n\n### 文件权限\n\n\n\n| ***\\*属主（user）\\**** | ***\\*属组（group）\\**** | ***\\*其他用户\\**** |      |      |      |      |      |      |\n| ---------------------- | ----------------------- | ------------------ | ---- | ---- | ---- | ---- | ---- | ---- |\n| r                      | w                       | x                  | r    | w    | x    | r    | w    | x    |\n| 4                      | 2                       | 1                  | 4    | 2    | 1    | 4    | 2    | 1    |\n\n \n\n### Linux三种文件类型：\n\n普通文件： 包括文本文件、数据文件、可执行的二进制程序文件等。 \n\n 目录文件： Linux系统把目录看成是一种特殊的文件，利用它构成文件系统的树型结构。  \n\n设备文件： Linux系统把每一个设备都看成是一个文件\n\n### 文件类型标识\n\n普通文件（-）\n\n目录（d）\n\n符号链接（l）\n\n\\* 进入etc可以查看，相当于快捷方式\n\n字符设备文件（c）\n\n块设备文件（s）\n\n套接字（s）\n\n命名管道（p）\n\n### 文件权限管理：\n\nchmod 变更文件或目录的权限。\n\nchmod 755 a.txt \n\nchmod u=rwx,g=rx,o=rx a.txt\n\nchmod 000 a.txt  / chmod 777 a.txtchown 变更文件或目录改文件所属用户和组\n\nchown u1:public a.txt\t：变更当前的目录或文件的所属用户和组\n\nchown -R u1:public dir\t：变更目录中的所有的子目录及文件的所属用户和组\n","tags":["linux","learn"],"categories":["学习"]},{"title":"Git","url":"/2019/09/11/Git/","content":"\n# Git简介\n\n\n\n## 集中式vs分布式\n\nLinus一直痛恨的CVS及SVN都是集中式的版本控制系统，而Git是分布式版本控制系统.Git有一个存储在服务器上的远程存储库和一个存储在每个开发人员的计算机中的本地存储库。这意味着代码不仅存储在中央服务器上，而且代码的完整副本也存在于所有开发人员的计算机中。因为每个节点都有一个本地副本，所以几乎所有对Git的操作都是本地的（Pull和Push命令除外）。这意味着您不必一直连接到远程存储库即可进行工作。\n\n## 安装Git\n\n最早Git是在Linux上开发的，很长一段时间内，Git也只能在Linux和Unix系统上跑。不过，慢慢地有人把它移植到了Windows上。现在，Git可以在Linux、Unix、Mac和Windows这几大平台上正常运行了。\n\n要使用Git，第一步当然是安装Git了。根据你当前使用的平台来阅读下面的文字：\n\n### 在Linux上安装Git\n\n首先，你可以试着输入`git`，看看系统有没有安装Git：\n\n```\n$ git\nThe program 'git' is currently not installed. You can install it by typing:\nsudo apt-get install git\n```\n\n像上面的命令，有很多Linux会友好地告诉你Git没有安装，还会告诉你如何安装Git。\n\n如果你碰巧用Debian或Ubuntu Linux，通过一条`sudo apt-get install git`就可以直接完成Git的安装，非常简单。\n\n老一点的Debian或Ubuntu Linux，要把命令改为`sudo apt-get install git-core`，因为以前有个软件也叫GIT（GNU Interactive Tools），结果Git就只能叫`git-core`了。由于Git名气实在太大，后来就把GNU Interactive Tools改成`gnuit`，`git-core`正式改为`git`。\n\n如果是其他Linux版本，可以直接通过源码安装。先从Git官网下载源码，然后解压，依次输入：`./config`，`make`，`sudo make install`这几个命令安装就好了。\n\n`centos ： yum install git`\n\n### 在Windows上安装Git\n\n在Windows上使用Git，可以从Git官网直接[下载安装程序](https://git-scm.com/downloads)，然后按默认选项安装即可。\n\n安装完成后，在开始菜单里找到“Git”->“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！\n\n![install-git-on-windows](https://www.liaoxuefeng.com/files/attachments/919018718363424/0)\n\n安装完成后，还需要最后一步设置，在命令行输入：\n\n```\n$ git config --global user.name \"Your Name\"\n$ git config --global user.email \"email@example.com\"\n```\n\n因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。你也许会担心，如果有人故意冒充别人怎么办？这个不必担心，首先我们相信大家都是善良无知的群众，其次，真的有冒充的也是有办法可查的。\n\n注意`git config`命令的`--global`参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。\n\n## 创建版本库\n\n什么是版本库呢？版本库又名仓库，英文名**repository**，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。\n\n所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录：\n\n```\n$ mkdir learngit\n$ cd learngit\n$ pwd\n/Users/michael/learngit\n```\n\n`pwd`命令用于显示当前目录。在我的Mac上，这个仓库位于`/Users/michael/learngit`。\n\n 如果你使用Windows系统，为了避免遇到各种莫名其妙的问题，请确保目录名（包括父目录）不包含中文。\n\n第二步，通过`git init`命令把这个目录变成Git可以管理的仓库：\n\n```\n$ git init\nInitialized empty Git repository in /Users/michael/learngit/.git/\n```\n\n瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的读者可以发现当前目录下多了一个`.git`的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。\n\n如果你没有看到`.git`目录，那是因为这个目录默认是隐藏的，用`ls -ah`命令就可以看见。\n\n### 把文件添加到版本库\n\n首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。\n\n不幸的是，Microsoft的Word格式是二进制格式，因此，版本控制系统是没法跟踪Word文件的改动的，前面我们举的例子只是为了演示，如果要真正使用版本控制系统，就要以纯文本方式编写文件。\n\n因为文本是有编码的，比如中文有常用的GBK编码，日文有Shift_JIS编码，如果没有历史遗留问题，强烈建议使用标准的UTF-8编码，所有语言使用同一种编码，既没有冲突，又被所有平台所支持。\n\n现在我们编写一个`readme.txt`文件，内容如下：\n\n```\nGit is a version control system.\nGit is free software.\n```\n\n一定要放到`learngit`目录下（子目录也行），因为这是一个Git仓库，放到其他地方Git再厉害也找不到这个文件。\n\n和把大象放到冰箱需要3步相比，把一个文件放到Git仓库只需要两步。\n\n第一步，用命令`git add`告诉Git，把文件添加到仓库：\n\n```\n$ git add readme.txt\n```\n\n执行上面的命令，没有任何显示，这就对了，Unix的哲学是“没有消息就是好消息”，说明添加成功。\n\n第二步，用命令`git commit`告诉Git，把文件提交到仓库：\n\n```\n$ git commit -m \"wrote a readme file\"\n[master (root-commit) eaadf4e] wrote a readme file\n 1 file changed, 2 insertions(+)\n create mode 100644 readme.txt\n```\n\n简单解释一下`git commit`命令，`-m`后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。\n\n嫌麻烦不想输入`-m \"xxx\"`行不行？确实有办法可以这么干，但是强烈不建议你这么干，因为输入说明对自己对别人阅读都很重要。实在不想输入说明的童鞋请自行Google，我不告诉你这个参数。\n\n`git commit`命令执行成功后会告诉你，`1 file changed`：1个文件被改动（我们新添加的readme.txt文件）；`2 insertions`：插入了两行内容（readme.txt有两行内容）。\n\n为什么Git添加文件需要`add`，`commit`一共两步呢？因为`commit`可以一次提交很多文件，所以你可以多次`add`不同的文件，比如：\n\n```\n$ git add file1.txt\n$ git add file2.txt file3.txt\n$ git commit -m \"add 3 files.\"\n```\n\n### 疑难解答\n\nQ：输入`git add readme.txt`，得到错误：`fatal: not a git repository (or any of the parent directories)`。\n\nA：Git命令必须在Git仓库目录内执行（`git init`除外），在仓库目录外执行是没有意义的。\n\nQ：输入`git add readme.txt`，得到错误`fatal: pathspec 'readme.txt' did not match any files`。\n\nA：添加某个文件时，该文件必须在当前目录下存在，用`ls`或者`dir`命令查看当前目录的文件，看看文件是否存在，或者是否写错了文件名。\n\n# 时光机穿梭\n\n我们已经成功地添加并提交了一个readme.txt文件，现在，是时候继续工作了，于是，我们继续修改readme.txt文件，改成如下内容：\n\n```\nGit is a distributed version control system.Git is free software.\n```\n\n现在，运行`git status`命令看看结果：\n\n```\n$ git statusOn branch masterChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txtno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n`git status`命令可以让我们时刻掌握仓库当前的状态，上面的命令输出告诉我们，`readme.txt`被修改过了，但还没有准备提交的修改。\n\n虽然Git告诉我们`readme.txt`被修改了，但如果能看看具体修改了什么内容，自然是很好的。比如你休假两周从国外回来，第一天上班时，已经记不清上次怎么修改的`readme.txt`，所以，需要用`git diff`这个命令看看：\n\n```\n$ git diff readme.txt diff --git a/readme.txt b/readme.txtindex 46d49bf..9247db6 100644--- a/readme.txt+++ b/readme.txt@@ -1,2 +1,2 @@-Git is a version control system.+Git is a distributed version control system. Git is free software.\n```\n\n`git diff`顾名思义就是查看difference，显示的格式正是Unix通用的diff格式，可以从上面的命令输出看到，我们在第一行添加了一个`distributed`单词。\n\n知道了对`readme.txt`作了什么修改后，再把它提交到仓库就放心多了，提交修改和提交新文件是一样的两步，第一步是`git add`：\n\n```\n$ git add readme.txt\n```\n\n同样没有任何输出。在执行第二步`git commit`之前，我们再运行`git status`看看当前仓库的状态：\n\n```\n$ git statusOn branch masterChanges to be committed:  (use \"git reset HEAD <file>...\" to unstage)\tmodified:   readme.txt\n```\n\n`git status`告诉我们，将要被提交的修改包括`readme.txt`，下一步，就可以放心地提交了：\n\n```\n$ git commit -m \"add distributed\"[master e475afc] add distributed 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\n提交后，我们再用`git status`命令看看仓库的当前状态：\n\n```\n$ git statusOn branch masternothing to commit, working tree clean\n```\n\nGit告诉我们当前没有需要提交的修改，而且，工作目录是干净（working tree clean）的。\n\n### 小结\n\n- 要随时掌握工作区的状态，使用`git status`命令。\n- 如果`git status`告诉你有文件被修改过，用`git diff`可以查看修改内容。\n\n## 版本回退\n\n现在，你已经学会了修改文件，然后把修改提交到Git版本库，现在，再练习一次，修改readme.txt文件如下：\n\n```\nGit is a distributed version control system.Git is free software distributed under the GPL.\n```\n\n然后尝试提交：\n\n```\n$ git add readme.txt$ git commit -m \"append GPL\"[master 1094adb] append GPL 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\n像这样，你不断对文件进行修改，然后不断提交修改到版本库里，就好比玩RPG游戏时，每通过一关就会自动把游戏状态存盘，如果某一关没过去，你还可以选择读取前一关的状态。有些时候，在打Boss之前，你会手动存盘，以便万一打Boss失败了，可以从最近的地方重新开始。Git也是一样，每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为`commit`。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个`commit`恢复，然后继续工作，而不是把几个月的工作成果全部丢失。\n\n现在，我们回顾一下`readme.txt`文件一共有几个版本被提交到Git仓库里了：\n\n版本1：wrote a readme file\n\n```\nGit is a version control system.Git is free software.\n```\n\n版本2：add distributed\n\n```\nGit is a distributed version control system.Git is free software.\n```\n\n版本3：append GPL\n\n```\nGit is a distributed version control system.Git is free software distributed under the GPL.\n```\n\n当然了，在实际工作中，我们脑子里怎么可能记得一个几千行的文件每次都改了什么内容，不然要版本控制系统干什么。版本控制系统肯定有某个命令可以告诉我们历史记录，在Git中，我们用`git log`命令查看：\n\n```\n$ git logcommit 1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -> master)Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 21:06:15 2018 +0800    append GPLcommit e475afc93c209a690c39c13a46716e8fa000c366Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 21:03:36 2018 +0800    add distributedcommit eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 20:59:18 2018 +0800    wrote a readme file\n```\n\n`git log`命令显示从最近到最远的提交日志，我们可以看到3次提交，最近的一次是`append GPL`，上一次是`add distributed`，最早的一次是`wrote a readme file`。\n\n如果嫌输出信息太多，看得眼花缭乱的，可以试试加上`--pretty=oneline`参数：\n\n```\n$ git log --pretty=oneline1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -> master) append GPLe475afc93c209a690c39c13a46716e8fa000c366 add distributedeaadf4e385e865d25c48e7ca9c8395c3f7dfaef0 wrote a readme file\n```\n\n需要友情提示的是，你看到的一大串类似`1094adb...`的是`commit id`（版本号），和SVN不一样，Git的`commit id`不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示，而且你看到的`commit id`和我的肯定不一样，以你自己的为准。为什么`commit id`需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。\n\n每提交一个新版本，实际上Git就会把它们自动串成一条时间线。如果使用可视化工具查看Git历史，就可以更清楚地看到提交历史的时间线：\n\n![git-log-timeline](https://www.liaoxuefeng.com/files/attachments/919019707114272/0)\n\n好了，现在我们启动时光穿梭机，准备把`readme.txt`回退到上一个版本，也就是`add distributed`的那个版本，怎么做呢？\n\n首先，Git必须知道当前版本是哪个版本，在Git中，用`HEAD`表示当前版本，也就是最新的提交`1094adb...`（注意我的提交ID和你的肯定不一样），上一个版本就是`HEAD^`，上上一个版本就是`HEAD^^`，当然往上100个版本写100个`^`比较容易数不过来，所以写成`HEAD~100`。\n\n现在，我们要把当前版本`append GPL`回退到上一个版本`add distributed`，就可以使用`git reset`命令：\n\n```\n$ git reset --hard HEAD^HEAD is now at e475afc add distributed\n```\n\n`--hard`参数有啥意义？这个后面再讲，现在你先放心使用。\n\n看看`readme.txt`的内容是不是版本`add distributed`：\n\n```\n$ cat readme.txtGit is a distributed version control system.Git is free software.\n```\n\n果然被还原了。\n\n还可以继续回退到上一个版本`wrote a readme file`，不过且慢，让我们用`git log`再看看现在版本库的状态：\n\n```\n$ git logcommit e475afc93c209a690c39c13a46716e8fa000c366 (HEAD -> master)Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 21:03:36 2018 +0800    add distributedcommit eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 20:59:18 2018 +0800    wrote a readme file\n```\n\n最新的那个版本`append GPL`已经看不到了！好比你从21世纪坐时光穿梭机来到了19世纪，想再回去已经回不去了，肿么办？\n\n办法其实还是有的，只要上面的命令行窗口还没有被关掉，你就可以顺着往上找啊找啊，找到那个`append GPL`的`commit id`是`1094adb...`，于是就可以指定回到未来的某个版本：\n\n```\n$ git reset --hard 1094aHEAD is now at 83b0afe append GPL\n```\n\n版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。\n\n再小心翼翼地看看`readme.txt`的内容：\n\n```\n$ cat readme.txtGit is a distributed version control system.Git is free software distributed under the GPL.\n```\n\n果然，我胡汉三又回来了。\n\nGit的版本回退速度非常快，因为Git在内部有个指向当前版本的`HEAD`指针，当你回退版本的时候，Git仅仅是把HEAD从指向`append GPL`：\n\n```ascii\n┌────┐│HEAD│└────┘   │   └──> ○ append GPL        │        ○ add distributed        │        ○ wrote a readme file\n```\n\n改为指向`add distributed`：\n\n```ascii\n┌────┐│HEAD│└────┘   │   │    ○ append GPL   │    │   └──> ○ add distributed        │        ○ wrote a readme file\n```\n\n然后顺便把工作区的文件更新了。所以你让`HEAD`指向哪个版本号，你就把当前版本定位在哪。\n\n现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的`commit id`怎么办？\n\n在Git中，总是有后悔药可以吃的。当你用`$ git reset --hard HEAD^`回退到`add distributed`版本时，再想恢复到`append GPL`，就必须找到`append GPL`的commit id。Git提供了一个命令`git reflog`用来记录你的每一次命令：\n\n```\n$ git refloge475afc HEAD@{1}: reset: moving to HEAD^1094adb (HEAD -> master) HEAD@{2}: commit: append GPLe475afc HEAD@{3}: commit: add distributedeaadf4e HEAD@{4}: commit (initial): wrote a readme file\n```\n\n终于舒了口气，从输出可知，`append GPL`的commit id是`1094adb`，现在，你又可以乘坐时光机回到未来了。\n\n### 小结\n\n现在总结一下：\n\n- `HEAD`指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令`git reset --hard commit_id`。\n- 穿梭前，用`git log`可以查看提交历史，以便确定要回退到哪个版本。\n- 要重返未来，用`git reflog`查看命令历史，以便确定要回到未来的哪个版本。\n\n## 工作区和暂存区\n\nGit和其他版本控制系统如SVN的一个不同之处就是有暂存区的概念。\n\n先来看名词解释。\n\n### 工作区（Working Directory）\n\n就是你在电脑里能看到的目录，比如我的`learngit`文件夹就是一个工作区：\n\n![working-dir](https://www.liaoxuefeng.com/files/attachments/919021113952544/0)\n\n### 版本库（Repository）\n\n工作区有一个隐藏目录`.git`，这个不算工作区，而是Git的版本库。\n\nGit的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支`master`，以及指向`master`的一个指针叫`HEAD`。\n\n![git-repo](https://www.liaoxuefeng.com/files/attachments/919020037470528/0)\n\n分支和`HEAD`的概念我们以后再讲。\n\n前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的：\n\n第一步是用`git add`把文件添加进去，实际上就是把文件修改添加到暂存区；\n\n第二步是用`git commit`提交更改，实际上就是把暂存区的所有内容提交到当前分支。\n\n因为我们创建Git版本库时，Git自动为我们创建了唯一一个`master`分支，所以，现在，`git commit`就是往`master`分支上提交更改。\n\n你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。\n\n俗话说，实践出真知。现在，我们再练习一遍，先对`readme.txt`做个修改，比如加上一行内容：\n\n```\nGit is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.\n```\n\n然后，在工作区新增一个`LICENSE`文本文件（内容随便写）。\n\n先用`git status`查看一下状态：\n\n```\n$ git statusOn branch masterChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txtUntracked files:  (use \"git add <file>...\" to include in what will be committed)\tLICENSEno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\nGit非常清楚地告诉我们，`readme.txt`被修改了，而`LICENSE`还从来没有被添加过，所以它的状态是`Untracked`。\n\n现在，使用两次命令`git add`，把`readme.txt`和`LICENSE`都添加后，用`git status`再查看一下：\n\n```\n$ git statusOn branch masterChanges to be committed:  (use \"git reset HEAD <file>...\" to unstage)\tnew file:   LICENSE\tmodified:   readme.txt\n```\n\n现在，暂存区的状态就变成这样了：\n\n![git-stage](https://www.liaoxuefeng.com/files/attachments/919020074026336/0)\n\n所以，`git add`命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行`git commit`就可以一次性把暂存区的所有修改提交到分支。\n\n```\n$ git commit -m \"understand how stage works\"[master e43a48b] understand how stage works 2 files changed, 2 insertions(+) create mode 100644 LICENSE\n```\n\n一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的：\n\n```\n$ git statusOn branch masternothing to commit, working tree clean\n```\n\n现在版本库变成了这样，暂存区就没有任何内容了：\n\n![git-stage-after-commit](https://www.liaoxuefeng.com/files/attachments/919020100829536/0)\n\n## 管理修改\n\n现在，假定你已经完全掌握了暂存区的概念。下面，我们要讨论的就是，为什么Git比其他版本控制系统设计得优秀，因为Git跟踪并管理的是修改，而非文件。\n\n你会问，什么是修改？比如你新增了一行，这就是一个修改，删除了一行，也是一个修改，更改了某些字符，也是一个修改，删了一些又加了一些，也是一个修改，甚至创建一个新文件，也算一个修改。\n\n为什么说Git管理的是修改，而不是文件呢？我们还是做实验。第一步，对readme.txt做一个修改，比如加一行内容：\n\n```\n$ cat readme.txtGit is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes.\n```\n\n然后，添加：\n\n```\n$ git add readme.txt$ git status# On branch master# Changes to be committed:#   (use \"git reset HEAD <file>...\" to unstage)##       modified:   readme.txt#\n```\n\n然后，再修改readme.txt：\n\n```\n$ cat readme.txt Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.\n```\n\n提交：\n\n```\n$ git commit -m \"git tracks changes\"[master 519219b] git tracks changes 1 file changed, 1 insertion(+)\n```\n\n提交后，再看看状态：\n\n```\n$ git statusOn branch masterChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txtno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n咦，怎么第二次的修改没有被提交？\n\n别激动，我们回顾一下操作过程：\n\n第一次修改 -> `git add` -> 第二次修改 -> `git commit`\n\n你看，我们前面讲了，Git管理的是修改，当你用`git add`命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，`git commit`只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。\n\n提交后，用`git diff HEAD -- readme.txt`命令可以查看工作区和版本库里面最新版本的区别：\n\n```\n$ git diff HEAD -- readme.txt diff --git a/readme.txt b/readme.txtindex 76d770f..a9c5755 100644--- a/readme.txt+++ b/readme.txt@@ -1,4 +1,4 @@ Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage.-Git tracks changes.+Git tracks changes of files.\n```\n\n可见，第二次修改确实没有被提交。\n\n那怎么提交第二次修改呢？你可以继续`git add`再`git commit`，也可以别着急提交第一次修改，先`git add`第二次修改，再`git commit`，就相当于把两次修改合并后一块提交了：\n\n第一次修改 -> `git add` -> 第二次修改 -> `git add` -> `git commit`\n\n好，现在，把第二次修改提交了，然后开始小结。\n\n## 撤销修改\n\n你可以删掉最后一行，手动把文件恢复到上一个版本的状态。如果用`git status`查看一下：\n\n```\n$ git statusOn branch masterChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txtno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n你可以发现，Git会告诉你，`git checkout -- file`可以丢弃工作区的修改：\n\n```\n$ git checkout -- readme.txt\n```\n\n命令`git checkout -- readme.txt`意思就是，把`readme.txt`文件在工作区的修改全部撤销，这里有两种情况：\n\n一种是`readme.txt`自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；\n\n一种是`readme.txt`已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。\n\n总之，就是让这个文件回到最近一次`git commit`或`git add`时的状态。\n\n现在，看看`readme.txt`的文件内容：\n\n```\n$ cat readme.txtGit is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.\n```\n\n文件内容果然复原了。\n\n`git checkout -- file`命令中的`--`很重要，没有`--`，就变成了“切换到另一个分支”的命令，我们在后面的分支管理中会再次遇到`git checkout`命令。\n\n现在假定是凌晨3点，你不但写了一些胡话，还`git add`到暂存区了：\n\n```\n$ cat readme.txtGit is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.My stupid boss still prefers SVN.$ git add readme.txt\n```\n\n庆幸的是，在`commit`之前，你发现了这个问题。用`git status`查看一下，修改只是添加到了暂存区，还没有提交：\n\n```\n$ git statusOn branch masterChanges to be committed:  (use \"git reset HEAD <file>...\" to unstage)\tmodified:   readme.txt\n```\n\nGit同样告诉我们，用命令`git reset HEAD <file>`可以把暂存区的修改撤销掉（unstage），重新放回工作区：\n\n```\n$ git reset HEAD readme.txtUnstaged changes after reset:M\treadme.txt\n```\n\n`git reset`命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用`HEAD`时，表示最新的版本。\n\n再用`git status`查看一下，现在暂存区是干净的，工作区有修改：\n\n```\n$ git statusOn branch masterChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txt\n```\n\n还记得如何丢弃工作区的修改吗？\n\n```\n$ git checkout -- readme.txt$ git statusOn branch masternothing to commit, working tree clean\n```\n\n整个世界终于清静了！\n\n现在，假设你不但改错了东西，还从暂存区提交到了版本库，怎么办呢？还记得[版本回退](https://www.liaoxuefeng.com/wiki/896043488029600/897013573512192)一节吗？可以回退到上一个版本。不过，这是有条件的，就是你还没有把自己的本地版本库推送到远程。还记得Git是分布式版本控制系统吗？我们后面会讲到远程版本库，一旦你把`stupid boss`提交推送到远程版本库，你就真的惨了……\n\n### 小结\n\n又到了小结时间。\n\n场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令`git checkout -- file`。\n\n场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令`git reset HEAD <file>`，就回到了场景1，第二步按场景1操作。\n\n场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考[版本回退](https://www.liaoxuefeng.com/wiki/896043488029600/897013573512192)一节，不过前提是没有推送到远程库。\n\n## 删除文件\n\n在Git中，删除也是一个修改操作，我们实战一下，先添加一个新文件`test.txt`到Git并且提交：\n\n```\n$ git add test.txt$ git commit -m \"add test.txt\"[master b84166e] add test.txt 1 file changed, 1 insertion(+) create mode 100644 test.txt\n```\n\n一般情况下，你通常直接在文件管理器中把没用的文件删了，或者用`rm`命令删了：\n\n```\n$ rm test.txt\n```\n\n这个时候，Git知道你删除了文件，因此，工作区和版本库就不一致了，`git status`命令会立刻告诉你哪些文件被删除了：\n\n```\n$ git statusOn branch masterChanges not staged for commit:  (use \"git add/rm <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tdeleted:    test.txtno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令`git rm`删掉，并且`git commit`：\n\n```\n$ git rm test.txtrm 'test.txt'$ git commit -m \"remove test.txt\"[master d46f35e] remove test.txt 1 file changed, 1 deletion(-) delete mode 100644 test.txt\n```\n\n现在，文件就从版本库中被删除了。\n\n# 远程仓库\n\nGit是分布式版本控制系统，同一个Git仓库，可以分布到不同的机器上。怎么分布呢？最早，肯定只有一台机器有一个原始版本库，此后，别的机器可以“克隆”这个原始版本库，而且每台机器的版本库其实都是一样的，并没有主次之分。\n\n你肯定会想，至少需要两台机器才能玩远程库不是？但是我只有一台电脑，怎么玩？\n\n其实一台电脑上也是可以克隆多个版本库的，只要不在同一个目录下。不过，现实生活中是不会有人这么傻的在一台电脑上搞几个远程库玩，因为一台电脑上搞几个远程库完全没有意义，而且硬盘挂了会导致所有库都挂掉，所以我也不告诉你在一台电脑上怎么克隆多个仓库。\n\n实际情况往往是这样，找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交。\n\n完全可以自己搭建一台运行Git的服务器，不过现阶段，为了学Git先搭个服务器绝对是小题大作。好在这个世界上有个叫[GitHub](https://github.com/)的神奇的网站，从名字就可以看出，这个网站就是提供Git仓库托管服务的，所以，只要注册一个GitHub账号，就可以免费获得Git远程仓库。\n\n在继续阅读后续内容前，请自行注册GitHub账号。由于你的本地Git仓库和GitHub仓库之间的传输是通过SSH加密的，所以，需要一点设置：\n\n第1步：创建SSH Key。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有`id_rsa`和`id_rsa.pub`这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key：\n\n```\n$ ssh-keygen -t rsa -C \"youremail@example.com\"\n```\n\n你需要把邮件地址换成你自己的邮件地址，然后一路回车，使用默认值即可，由于这个Key也不是用于军事目的，所以也无需设置密码。\n\n如果一切顺利的话，可以在用户主目录里找到`.ssh`目录，里面有`id_rsa`和`id_rsa.pub`两个文件，这两个就是SSH Key的秘钥对，`id_rsa`是私钥，不能泄露出去，`id_rsa.pub`是公钥，可以放心地告诉任何人。\n\n第2步：登陆GitHub，打开“Account settings”，“SSH Keys”页面：\n\n然后，点“Add SSH Key”，填上任意Title，在Key文本框里粘贴`id_rsa.pub`文件的内容：\n\n![github-addkey-1](https://www.liaoxuefeng.com/files/attachments/919021379029408/0)\n\n点“Add Key”，你就应该看到已经添加的Key：\n\n![github-addkey-2](https://www.liaoxuefeng.com/files/attachments/919021395420160/0)\n\n为什么GitHub需要SSH Key呢？因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送。\n\n当然，GitHub允许你添加多个Key。假定你有若干电脑，你一会儿在公司提交，一会儿在家里提交，只要把每台电脑的Key都添加到GitHub，就可以在每台电脑上往GitHub推送了。\n\n最后友情提示，在GitHub上免费托管的Git仓库，任何人都可以看到喔（但只有你自己才能改）。所以，不要把敏感信息放进去。\n\n如果你不想让别人看到Git库，有两个办法，一个是交点保护费，让GitHub把公开的仓库变成私有的，这样别人就看不见了（不可读更不可写）。另一个办法是自己动手，搭一个Git服务器，因为是你自己的Git服务器，所以别人也是看不见的。这个方法我们后面会讲到的，相当简单，公司内部开发必备。\n\n## 添加远程库\n\n现在的情景是，你已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作，真是一举多得。\n\n首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库：\n\n![github-create-repo-1](https://www.liaoxuefeng.com/files/attachments/919021631860000/0)\n\n在Repository name填入`learngit`，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库：\n\n![github-create-repo-2](https://www.liaoxuefeng.com/files/attachments/919021652277920/0)\n\n目前，在GitHub上的这个`learngit`仓库还是空的，GitHub告诉我们，可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联，然后，把本地仓库的内容推送到GitHub仓库。\n\n现在，我们根据GitHub的提示，在本地的`learngit`仓库下运行命令：\n\n```\n$ git remote add origin git@github.com:michaelliao/learngit.git\n```\n\n请千万注意，把上面的`michaelliao`替换成你自己的GitHub账户名，否则，你在本地关联的就是我的远程库，关联没有问题，但是你以后推送是推不上去的，因为你的SSH Key公钥不在我的账户列表中。\n\n添加后，远程库的名字就是`origin`，这是Git默认的叫法，也可以改成别的，但是`origin`这个名字一看就知道是远程库。\n\n下一步，就可以把本地库的所有内容推送到远程库上：\n\n```\n$ git push -u origin masterCounting objects: 20, done.Delta compression using up to 4 threads.Compressing objects: 100% (15/15), done.Writing objects: 100% (20/20), 1.64 KiB | 560.00 KiB/s, done.Total 20 (delta 5), reused 0 (delta 0)remote: Resolving deltas: 100% (5/5), done.To github.com:michaelliao/learngit.git * [new branch]      master -> masterBranch 'master' set up to track remote branch 'master' from 'origin'.\n```\n\n把本地库的内容推送到远程，用`git push`命令，实际上是把当前分支`master`推送到远程。\n\n由于远程库是空的，我们第一次推送`master`分支时，加上了`-u`参数，Git不但会把本地的`master`分支内容推送的远程新的`master`分支，还会把本地的`master`分支和远程的`master`分支关联起来，在以后的推送或者拉取时就可以简化命令。\n\n推送成功后，可以立刻在GitHub页面中看到远程库的内容已经和本地一模一样：\n\n![github-repo](https://www.liaoxuefeng.com/files/attachments/919021675995552/0)\n\n从现在起，只要本地作了提交，就可以通过命令：\n\n```\n$ git push origin master\n```\n\n把本地`master`分支的最新修改推送至GitHub，现在，你就拥有了真正的分布式版本库！\n\n### SSH警告\n\n当你第一次使用Git的`clone`或者`push`命令连接GitHub时，会得到一个警告：\n\n```\nThe authenticity of host 'github.com (xx.xx.xx.xx)' can't be established.RSA key fingerprint is xx.xx.xx.xx.xx.Are you sure you want to continue connecting (yes/no)?\n```\n\n这是因为Git使用SSH连接，而SSH连接在第一次验证GitHub服务器的Key时，需要你确认GitHub的Key的指纹信息是否真的来自GitHub的服务器，输入`yes`回车即可。\n\nGit会输出一个警告，告诉你已经把GitHub的Key添加到本机的一个信任列表里了：\n\n```\nWarning: Permanently added 'github.com' (RSA) to the list of known hosts.\n```\n\n这个警告只会出现一次，后面的操作就不会有任何警告了。\n\n如果你实在担心有人冒充GitHub服务器，输入`yes`前可以对照[GitHub的RSA Key的指纹信息](https://help.github.com/articles/what-are-github-s-ssh-key-fingerprints/)是否与SSH连接给出的一致。\n\n### 删除远程库\n\n如果添加的时候地址写错了，或者就是想删除远程库，可以用`git remote rm <name>`命令。使用前，建议先用`git remote -v`查看远程库信息：\n\n```\n$ git remote -vorigin  git@github.com:michaelliao/learn-git.git (fetch)origin  git@github.com:michaelliao/learn-git.git (push)\n```\n\n然后，根据名字删除，比如删除`origin`：\n\n```\n$ git remote rm origin\n```\n\n此处的“删除”其实是解除了本地和远程的绑定关系，并不是物理上删除了远程库。远程库本身并没有任何改动。要真正删除远程库，需要登录到GitHub，在后台页面找到删除按钮再删除。\n\n### 小结\n\n要关联一个远程库，使用命令`git remote add origin git@server-name:path/repo-name.git`；\n\n关联一个远程库时必须给远程库指定一个名字，`origin`是默认习惯命名；\n\n关联后，使用命令`git push -u origin master`第一次推送master分支的所有内容；\n\n此后，每次本地提交后，只要有必要，就可以使用命令`git push origin master`推送最新修改；\n\n分布式版本系统的最大好处之一是在本地工作完全不需要考虑远程库的存在，也就是有没有联网都可以正常工作，而SVN在没有联网的时候是拒绝干活的！当有网络的时候，再把本地提交推送一下就完成了同步，真是太方便了！\n\n## 从远程库克隆\n\n上次我们讲了先有本地库，后有远程库的时候，如何关联远程库。\n\n现在，假设我们从零开发，那么最好的方式是先创建远程库，然后，从远程库克隆。\n\n首先，登陆GitHub，创建一个新的仓库，名字叫`gitskills`：\n\n![github-init-repo](https://www.liaoxuefeng.com/files/attachments/919021808263616/0)\n\n我们勾选`Initialize this repository with a README`，这样GitHub会自动为我们创建一个`README.md`文件。创建完毕后，可以看到`README.md`文件：\n\n![github-init-repo-2](https://www.liaoxuefeng.com/files/attachments/919021836828288/0)\n\n现在，远程库已经准备好了，下一步是用命令`git clone`克隆一个本地库：\n\n```\n$ git clone git@github.com:michaelliao/gitskills.gitCloning into 'gitskills'...remote: Counting objects: 3, done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 3Receiving objects: 100% (3/3), done.\n```\n\n注意把Git库的地址换成你自己的，然后进入`gitskills`目录看看，已经有`README.md`文件了：\n\n```\n$ cd gitskills$ lsREADME.md\n```\n\n如果有多个人协作开发，那么每个人各自从远程克隆一份就可以了。\n\n你也许还注意到，GitHub给出的地址不止一个，还可以用`https://github.com/michaelliao/gitskills.git`这样的地址。实际上，Git支持多种协议，默认的`git://`使用ssh，但也可以使用`https`等其他协议。\n\n使用`https`除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用`ssh`协议而只能用`https`。\n\n### 小结\n\n要克隆一个仓库，首先必须知道仓库的地址，然后使用`git clone`命令克隆。\n\nGit支持多种协议，包括`https`，但`ssh`协议速度最快。\n\n# 分支管理\n\n## 创建与合并分支\n\n在[版本回退](https://www.liaoxuefeng.com/wiki/896043488029600/897013573512192)里，你已经知道，每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即`master`分支。`HEAD`严格来说不是指向提交，而是指向`master`，`master`才是指向提交的，所以，`HEAD`指向的就是当前分支。\n\n一开始的时候，`master`分支是一条线，Git用`master`指向最新的提交，再用`HEAD`指向`master`，就能确定当前分支，以及当前分支的提交点：\n\n![git-br-initial](https://www.liaoxuefeng.com/files/attachments/919022325462368/0)\n\n每次提交，`master`分支都会向前移动一步，这样，随着你不断提交，`master`分支的线也越来越长。\n\n当我们创建新的分支，例如`dev`时，Git新建了一个指针叫`dev`，指向`master`相同的提交，再把`HEAD`指向`dev`，就表示当前分支在`dev`上：\n\n![git-br-create](https://www.liaoxuefeng.com/files/attachments/919022363210080/l)\n\n你看，Git创建一个分支很快，因为除了增加一个`dev`指针，改改`HEAD`的指向，工作区的文件都没有任何变化！\n\n不过，从现在开始，对工作区的修改和提交就是针对`dev`分支了，比如新提交一次后，`dev`指针往前移动一步，而`master`指针不变：\n\n![git-br-dev-fd](https://www.liaoxuefeng.com/files/attachments/919022387118368/l)\n\n假如我们在`dev`上的工作完成了，就可以把`dev`合并到`master`上。Git怎么合并呢？最简单的方法，就是直接把`master`指向`dev`的当前提交，就完成了合并：\n\n![git-br-ff-merge](https://www.liaoxuefeng.com/files/attachments/919022412005504/0)\n\n所以Git合并分支也很快！就改改指针，工作区内容也不变！\n\n合并完分支后，甚至可以删除`dev`分支。删除`dev`分支就是把`dev`指针给删掉，删掉后，我们就剩下了一条`master`分支：\n\n![git-br-rm](https://www.liaoxuefeng.com/files/attachments/919022479428512/0)\n\n真是太神奇了，你看得出来有些提交是通过分支完成的吗？\n\n下面开始实战。\n\n首先，我们创建`dev`分支，然后切换到`dev`分支：\n\n```\n$ git checkout -b devSwitched to a new branch 'dev'\n```\n\n`git checkout`命令加上`-b`参数表示创建并切换，相当于以下两条命令：\n\n```\n$ git branch dev$ git checkout devSwitched to branch 'dev'\n```\n\n然后，用`git branch`命令查看当前分支：\n\n```\n$ git branch* dev  master\n```\n\n`git branch`命令会列出所有分支，当前分支前面会标一个`*`号。\n\n然后，我们就可以在`dev`分支上正常提交，比如对`readme.txt`做个修改，加上一行：\n\n```\nCreating a new branch is quick.\n```\n\n然后提交：\n\n```\n$ git add readme.txt $ git commit -m \"branch test\"[dev b17d20e] branch test 1 file changed, 1 insertion(+)\n```\n\n现在，`dev`分支的工作完成，我们就可以切换回`master`分支：\n\n```\n$ git checkout masterSwitched to branch 'master'\n```\n\n切换回`master`分支后，再查看一个`readme.txt`文件，刚才添加的内容不见了！因为那个提交是在`dev`分支上，而`master`分支此刻的提交点并没有变：\n\n![git-br-on-master](https://www.liaoxuefeng.com/files/attachments/919022533080576/0)\n\n现在，我们把`dev`分支的工作成果合并到`master`分支上：\n\n```\n$ git merge devUpdating d46f35e..b17d20eFast-forward readme.txt | 1 + 1 file changed, 1 insertion(+)\n```\n\n`git merge`命令用于合并指定分支到当前分支。合并后，再查看`readme.txt`的内容，就可以看到，和`dev`分支的最新提交是完全一样的。\n\n注意到上面的`Fast-forward`信息，Git告诉我们，这次合并是“快进模式”，也就是直接把`master`指向`dev`的当前提交，所以合并速度非常快。\n\n当然，也不是每次合并都能`Fast-forward`，我们后面会讲其他方式的合并。\n\n合并完成后，就可以放心地删除`dev`分支了：\n\n```\n$ git branch -d devDeleted branch dev (was b17d20e).\n```\n\n删除后，查看`branch`，就只剩下`master`分支了：\n\n```\n$ git branch* master\n```\n\n因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在`master`分支上工作效果是一样的，但过程更安全。\n\n### switch\n\n我们注意到切换分支使用`git checkout <branch>`，而前面讲过的撤销修改则是`git checkout -- <file>`，同一个命令，有两种作用，确实有点令人迷惑。\n\n实际上，切换分支这个动作，用`switch`更科学。因此，最新版本的Git提供了新的`git switch`命令来切换分支：\n\n创建并切换到新的`dev`分支，可以使用：\n\n```\n$ git switch -c dev\n```\n\n直接切换到已有的`master`分支，可以使用：\n\n```\n$ git switch master\n```\n\n使用新的`git switch`命令，比`git checkout`要更容易理解。\n\n### 小结\n\nGit鼓励大量使用分支：\n\n查看分支：`git branch`\n\n创建分支：`git branch <name>`\n\n切换分支：`git checkout <name>`或者`git switch <name>`\n\n创建+切换分支：`git checkout -b <name>`或者`git switch -c <name>`\n\n合并某分支到当前分支：`git merge <name>`\n\n删除分支：`git branch -d <name>`\n\n## 解决冲突\n\n人生不如意之事十之八九，合并分支往往也不是一帆风顺的。\n\n准备新的`feature1`分支，继续我们的新分支开发：\n\n```\n$ git switch -c feature1Switched to a new branch 'feature1'\n```\n\n修改`readme.txt`最后一行，改为：\n\n```\nCreating a new branch is quick AND simple.\n```\n\n在`feature1`分支上提交：\n\n```\n$ git add readme.txt$ git commit -m \"AND simple\"[feature1 14096d0] AND simple 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\n切换到`master`分支：\n\n```\n$ git switch masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 1 commit.  (use \"git push\" to publish your local commits)\n```\n\nGit还会自动提示我们当前`master`分支比远程的`master`分支要超前1个提交。\n\n在`master`分支上把`readme.txt`文件的最后一行改为：\n\n```\nCreating a new branch is quick & simple.\n```\n\n提交：\n\n```\n$ git add readme.txt $ git commit -m \"& simple\"[master 5dc6824] & simple 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\n现在，`master`分支和`feature1`分支各自都分别有新的提交，变成了这样：\n\n![git-br-feature1](https://www.liaoxuefeng.com/files/attachments/919023000423040/0)\n\n这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突，我们试试看：\n\n```\n$ git merge feature1Auto-merging readme.txtCONFLICT (content): Merge conflict in readme.txtAutomatic merge failed; fix conflicts and then commit the result.\n```\n\n果然冲突了！Git告诉我们，`readme.txt`文件存在冲突，必须手动解决冲突后再提交。`git status`也可以告诉我们冲突的文件：\n\n```\n$ git statusOn branch masterYour branch is ahead of 'origin/master' by 2 commits.  (use \"git push\" to publish your local commits)You have unmerged paths.  (fix conflicts and run \"git commit\")  (use \"git merge --abort\" to abort the merge)Unmerged paths:  (use \"git add <file>...\" to mark resolution)\tboth modified:   readme.txtno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n我们可以直接查看readme.txt的内容：\n\n```\nGit is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.<<<<<<< HEADCreating a new branch is quick & simple.=======Creating a new branch is quick AND simple.>>>>>>> feature1\n```\n\nGit用`<<<<<<<`，`=======`，`>>>>>>>`标记出不同分支的内容，我们修改如下后保存：\n\n```\nCreating a new branch is quick and simple.\n```\n\n再提交：\n\n```\n$ git add readme.txt $ git commit -m \"conflict fixed\"[master cf810e4] conflict fixed\n```\n\n现在，`master`分支和`feature1`分支变成了下图所示：\n\n![git-br-conflict-merged](https://www.liaoxuefeng.com/files/attachments/919023031831104/0)\n\n用带参数的`git log`也可以看到分支的合并情况：\n\n```\n$ git log --graph --pretty=oneline --abbrev-commit*   cf810e4 (HEAD -> master) conflict fixed|\\  | * 14096d0 (feature1) AND simple* | 5dc6824 & simple|/  * b17d20e branch test* d46f35e (origin/master) remove test.txt* b84166e add test.txt* 519219b git tracks changes* e43a48b understand how stage works* 1094adb append GPL* e475afc add distributed* eaadf4e wrote a readme file\n```\n\n最后，删除`feature1`分支：\n\n```\n$ git branch -d feature1Deleted branch feature1 (was 14096d0).\n```\n\n工作完成。\n\n### 小结\n\n当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。\n\n解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。\n\n用`git log --graph`命令可以看到分支合并图。\n\n## 分支管理策略\n\n通常，合并分支时，如果可能，Git会用`Fast forward`模式，但这种模式下，删除分支后，会丢掉分支信息。\n\n如果要强制禁用`Fast forward`模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。\n\n下面我们实战一下`--no-ff`方式的`git merge`：\n\n首先，仍然创建并切换`dev`分支：\n\n```\n$ git switch -c devSwitched to a new branch 'dev'\n```\n\n修改readme.txt文件，并提交一个新的commit：\n\n```\n$ git add readme.txt $ git commit -m \"add merge\"[dev f52c633] add merge 1 file changed, 1 insertion(+)\n```\n\n现在，我们切换回`master`：\n\n```\n$ git switch masterSwitched to branch 'master'\n```\n\n准备合并`dev`分支，请注意`--no-ff`参数，表示禁用`Fast forward`：\n\n```\n$ git merge --no-ff -m \"merge with no-ff\" devMerge made by the 'recursive' strategy. readme.txt | 1 + 1 file changed, 1 insertion(+)\n```\n\n因为本次合并要创建一个新的commit，所以加上`-m`参数，把commit描述写进去。\n\n合并后，我们用`git log`看看分支历史：\n\n```\n$ git log --graph --pretty=oneline --abbrev-commit*   e1e9c68 (HEAD -> master) merge with no-ff|\\  | * f52c633 (dev) add merge|/  *   cf810e4 conflict fixed...\n```\n\n可以看到，不使用`Fast forward`模式，merge后就像这样：\n\n![git-no-ff-mode](https://www.liaoxuefeng.com/files/attachments/919023225142304/0)\n\n\n\n### 分支策略\n\n在实际开发中，我们应该按照几个基本原则进行分支管理：\n\n首先，`master`分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活；\n\n那在哪干活呢？干活都在`dev`分支上，也就是说，`dev`分支是不稳定的，到某个时候，比如1.0版本发布时，再把`dev`分支合并到`master`上，在`master`分支发布1.0版本；\n\n你和你的小伙伴们每个人都在`dev`分支上干活，每个人都有自己的分支，时不时地往`dev`分支上合并就可以了。\n\n所以，团队合作的分支看起来就像这样：\n\n![git-br-policy](https://www.liaoxuefeng.com/files/attachments/919023260793600/0)\n\n### 小结\n\nGit分支十分强大，在团队开发中应该充分应用。\n\n合并分支时，加上`--no-ff`参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而`fast forward`合并就看不出来曾经做过合并。\n\n## Bug分支\n\n软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。\n\n当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支`issue-101`来修复它，但是，等等，当前正在`dev`上进行的工作还没有提交：\n\n```\n$ git statusOn branch devChanges to be committed:  (use \"git reset HEAD <file>...\" to unstage)\tnew file:   hello.pyChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txt\n```\n\n并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？\n\n幸好，Git还提供了一个`stash`功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：\n\n```\n$ git stashSaved working directory and index state WIP on dev: f52c633 add merge\n```\n\n现在，用`git status`查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。\n\n首先确定要在哪个分支上修复bug，假定需要在`master`分支上修复，就从`master`创建临时分支：\n\n```\n$ git checkout masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 6 commits.  (use \"git push\" to publish your local commits)$ git checkout -b issue-101Switched to a new branch 'issue-101'\n```\n\n现在修复bug，需要把“Git is free software ...”改为“Git is a free software ...”，然后提交：\n\n```\n$ git add readme.txt $ git commit -m \"fix bug 101\"[issue-101 4c805e2] fix bug 101 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\n修复完成后，切换到`master`分支，并完成合并，最后删除`issue-101`分支：\n\n```\n$ git switch masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 6 commits.  (use \"git push\" to publish your local commits)$ git merge --no-ff -m \"merged bug fix 101\" issue-101Merge made by the 'recursive' strategy. readme.txt | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\n太棒了，原计划两个小时的bug修复只花了5分钟！现在，是时候接着回到`dev`分支干活了！\n\n```\n$ git switch devSwitched to branch 'dev'$ git statusOn branch devnothing to commit, working tree clean\n```\n\n工作区是干净的，刚才的工作现场存到哪去了？用`git stash list`命令看看：\n\n```\n$ git stash liststash@{0}: WIP on dev: f52c633 add merge\n```\n\n工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，有两个办法：\n\n一是用`git stash apply`恢复，但是恢复后，stash内容并不删除，你需要用`git stash drop`来删除；\n\n另一种方式是用`git stash pop`，恢复的同时把stash内容也删了：\n\n```\n$ git stash popOn branch devChanges to be committed:  (use \"git reset HEAD <file>...\" to unstage)\tnew file:   hello.pyChanges not staged for commit:  (use \"git add <file>...\" to update what will be committed)  (use \"git checkout -- <file>...\" to discard changes in working directory)\tmodified:   readme.txtDropped refs/stash@{0} (5d677e2ee266f39ea296182fb2354265b91b3b2a)\n```\n\n再用`git stash list`查看，就看不到任何stash内容了：\n\n```\n$ git stash list\n```\n\n你可以多次stash，恢复的时候，先用`git stash list`查看，然后恢复指定的stash，用命令：\n\n```\n$ git stash apply stash@{0}\n```\n\n\n\n在master分支上修复了bug后，我们要想一想，dev分支是早期从master分支分出来的，所以，这个bug其实在当前dev分支上也存在。\n\n那怎么在dev分支上修复同样的bug？重复操作一次，提交不就行了？\n\n有木有更简单的方法？\n\n有！\n\n同样的bug，要在dev上修复，我们只需要把`4c805e2 fix bug 101`这个提交所做的修改“复制”到dev分支。注意：我们只想复制`4c805e2 fix bug 101`这个提交所做的修改，并不是把整个master分支merge过来。\n\n为了方便操作，Git专门提供了一个`cherry-pick`命令，让我们能复制一个特定的提交到当前分支：\n\n```\n$ git branch* dev  master$ git cherry-pick 4c805e2[master 1d4b803] fix bug 101 1 file changed, 1 insertion(+), 1 deletion(-)\n```\n\nGit自动给dev分支做了一次提交，注意这次提交的commit是`1d4b803`，它并不同于master的`4c805e2`，因为这两个commit只是改动相同，但确实是两个不同的commit。用`git cherry-pick`，我们就不需要在dev分支上手动再把修bug的过程重复一遍。\n\n有些聪明的童鞋会想了，既然可以在master分支上修复bug后，在dev分支上可以“重放”这个修复过程，那么直接在dev分支上修复bug，然后在master分支上“重放”行不行？当然可以，不过你仍然需要`git stash`命令保存现场，才能从dev分支切换到master分支。\n\n### 小结\n\n修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；\n\n当手头工作没有完成时，先把工作现场`git stash`一下，然后去修复bug，修复后，再`git stash pop`，回到工作现场；\n\n在master分支上修复的bug，想要合并到当前dev分支，可以用`git cherry-pick <commit>`命令，把bug提交的修改“复制”到当前分支，避免重复劳动。\n\n## Feature分支\n\n软件开发中，总有无穷无尽的新的功能要不断添加进来。\n\n添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。\n\n现在，你终于接到了一个新任务：开发代号为Vulcan的新功能，该功能计划用于下一代星际飞船。\n\n于是准备开发：\n\n```\n$ git switch -c feature-vulcanSwitched to a new branch 'feature-vulcan'\n```\n\n5分钟后，开发完毕：\n\n```\n$ git add vulcan.py$ git statusOn branch feature-vulcanChanges to be committed:  (use \"git reset HEAD <file>...\" to unstage)\tnew file:   vulcan.py$ git commit -m \"add feature vulcan\"[feature-vulcan 287773e] add feature vulcan 1 file changed, 2 insertions(+) create mode 100644 vulcan.py\n```\n\n切回`dev`，准备合并：\n\n```\n$ git switch dev\n```\n\n一切顺利的话，feature分支和bug分支是类似的，合并，然后删除。\n\n但是！\n\n就在此时，接到上级命令，因经费不足，新功能必须取消！\n\n虽然白干了，但是这个包含机密资料的分支还是必须就地销毁：\n\n```\n$ git branch -d feature-vulcanerror: The branch 'feature-vulcan' is not fully merged.If you are sure you want to delete it, run 'git branch -D feature-vulcan'.\n```\n\n销毁失败。Git友情提醒，`feature-vulcan`分支还没有被合并，如果删除，将丢失掉修改，如果要强行删除，需要使用大写的`-D`参数。。\n\n现在我们强行删除：\n\n```\n$ git branch -D feature-vulcanDeleted branch feature-vulcan (was 287773e).\n```\n\n终于删除成功！\n\n### 小结\n\n开发一个新feature，最好新建一个分支；\n\n如果要丢弃一个没有被合并过的分支，可以通过`git branch -D <name>`强行删除。\n\n## 多人协作\n\n当你从远程仓库克隆时，实际上Git自动把本地的`master`分支和远程的`master`分支对应起来了，并且，远程仓库的默认名称是`origin`。\n\n要查看远程库的信息，用`git remote`：\n\n```\n$ git remoteorigin\n```\n\n或者，用`git remote -v`显示更详细的信息：\n\n```\n$ git remote -vorigin  git@github.com:michaelliao/learngit.git (fetch)origin  git@github.com:michaelliao/learngit.git (push)\n```\n\n上面显示了可以抓取和推送的`origin`的地址。如果没有推送权限，就看不到push的地址。\n\n### 推送分支\n\n推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上：\n\n```\n$ git push origin master\n```\n\n如果要推送其他分支，比如`dev`，就改成：\n\n```\n$ git push origin dev\n```\n\n但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？\n\n- `master`分支是主分支，因此要时刻与远程同步；\n- `dev`分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步；\n- bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug；\n- feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。\n\n总之，就是在Git中，分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！\n\n### 抓取分支\n\n多人协作时，大家都会往`master`和`dev`分支上推送各自的修改。\n\n现在，模拟一个你的小伙伴，可以在另一台电脑（注意要把SSH Key添加到GitHub）或者同一台电脑的另一个目录下克隆：\n\n```\n$ git clone git@github.com:michaelliao/learngit.gitCloning into 'learngit'...remote: Counting objects: 40, done.remote: Compressing objects: 100% (21/21), done.remote: Total 40 (delta 14), reused 40 (delta 14), pack-reused 0Receiving objects: 100% (40/40), done.Resolving deltas: 100% (14/14), done.\n```\n\n当你的小伙伴从远程库clone时，默认情况下，你的小伙伴只能看到本地的`master`分支。不信可以用`git branch`命令看看：\n\n```\n$ git branch* master\n```\n\n现在，你的小伙伴要在`dev`分支上开发，就必须创建远程`origin`的`dev`分支到本地，于是他用这个命令创建本地`dev`分支：\n\n```\n$ git checkout -b dev origin/dev\n```\n\n现在，他就可以在`dev`上继续修改，然后，时不时地把`dev`分支`push`到远程：\n\n```\n$ git add env.txt$ git commit -m \"add env\"[dev 7a5e5dd] add env 1 file changed, 1 insertion(+) create mode 100644 env.txt$ git push origin devCounting objects: 3, done.Delta compression using up to 4 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 308 bytes | 308.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git   f52c633..7a5e5dd  dev -> dev\n```\n\n\n\n你的小伙伴已经向`origin/dev`分支推送了他的提交，而碰巧你也对同样的文件作了修改，并试图推送：\n\n```\n$ cat env.txtenv$ git add env.txt$ git commit -m \"add new env\"[dev 7bd91f1] add new env 1 file changed, 1 insertion(+) create mode 100644 env.txt$ git push origin devTo github.com:michaelliao/learngit.git ! [rejected]        dev -> dev (non-fast-forward)error: failed to push some refs to 'git@github.com:michaelliao/learngit.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n```\n\n推送失败，因为你的小伙伴的最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用`git pull`把最新的提交从`origin/dev`抓下来，然后，在本地合并，解决冲突，再推送：\n\n```\n$ git pullThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details.    git pull <remote> <branch>If you wish to set tracking information for this branch you can do so with:    git branch --set-upstream-to=origin/<branch> dev\n```\n\n`git pull`也失败了，原因是没有指定本地`dev`分支与远程`origin/dev`分支的链接，根据提示，设置`dev`和`origin/dev`的链接：\n\n```\n$ git branch --set-upstream-to=origin/dev devBranch 'dev' set up to track remote branch 'dev' from 'origin'.\n```\n\n再pull：\n\n```\n$ git pullAuto-merging env.txtCONFLICT (add/add): Merge conflict in env.txtAutomatic merge failed; fix conflicts and then commit the result.\n```\n\n这回`git pull`成功，但是合并有冲突，需要手动解决，解决的方法和分支管理中的[解决冲突](http://www.liaoxuefeng.com/wiki/896043488029600/900004111093344)完全一样。解决后，提交，再push：\n\n```\n$ git commit -m \"fix env conflict\"[dev 57c53ab] fix env conflict$ git push origin devCounting objects: 6, done.Delta compression using up to 4 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (6/6), 621 bytes | 621.00 KiB/s, done.Total 6 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git   7a5e5dd..57c53ab  dev -> dev\n```\n\n\n\n因此，多人协作的工作模式通常是这样：\n\n1. 首先，可以试图用`git push origin <branch-name>`推送自己的修改；\n2. 如果推送失败，则因为远程分支比你的本地更新，需要先用`git pull`试图合并；\n3. 如果合并有冲突，则解决冲突，并在本地提交；\n4. 没有冲突或者解决掉冲突后，再用`git push origin <branch-name>`推送就能成功！\n\n如果`git pull`提示`no tracking information`，则说明本地分支和远程分支的链接关系没有创建，用命令`git branch --set-upstream-to <branch-name> origin/<branch-name>`。\n\n这就是多人协作的工作模式，一旦熟悉了，就非常简单。\n\n### 小结\n\n- 查看远程库信息，使用`git remote -v`；\n- 本地新建的分支如果不推送到远程，对其他人就是不可见的；\n- 从本地推送分支，使用`git push origin branch-name`，如果推送失败，先用`git pull`抓取远程的新提交；\n- 在本地创建和远程分支对应的分支，使用`git checkout -b branch-name origin/branch-name`，本地和远程分支的名称最好一致；\n- 建立本地分支和远程分支的关联，使用`git branch --set-upstream branch-name origin/branch-name`；\n- 从远程抓取分支，使用`git pull`，如果有冲突，要先处理冲突。\n\n# 标签管理\n\n## 创建标签\n\n在Git中打标签非常简单，首先，切换到需要打标签的分支上：\n\n```\n$ git branch* dev  master$ git checkout masterSwitched to branch 'master'\n```\n\n然后，敲命令`git tag <name>`就可以打一个新标签：\n\n```\n$ git tag v1.0\n```\n\n可以用命令`git tag`查看所有标签：\n\n```\n$ git tagv1.0\n```\n\n默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？\n\n方法是找到历史提交的commit id，然后打上就可以了：\n\n```\n$ git log --pretty=oneline --abbrev-commit12a631b (HEAD -> master, tag: v1.0, origin/master) merged bug fix 1014c805e2 fix bug 101e1e9c68 merge with no-fff52c633 add mergecf810e4 conflict fixed5dc6824 & simple14096d0 AND simpleb17d20e branch testd46f35e remove test.txtb84166e add test.txt519219b git tracks changese43a48b understand how stage works1094adb append GPLe475afc add distributedeaadf4e wrote a readme file\n```\n\n比方说要对`add merge`这次提交打标签，它对应的commit id是`f52c633`，敲入命令：\n\n```\n$ git tag v0.9 f52c633\n```\n\n再用命令`git tag`查看标签：\n\n```\n$ git tagv0.9v1.0\n```\n\n注意，标签不是按时间顺序列出，而是按字母排序的。可以用`git show <tagname>`查看标签信息：\n\n```\n$ git show v0.9commit f52c63349bc3c1593499807e5c8e972b82c8f286 (tag: v0.9)Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 21:56:54 2018 +0800    add mergediff --git a/readme.txt b/readme.txt...\n```\n\n可以看到，`v0.9`确实打在`add merge`这次提交上。\n\n还可以创建带有说明的标签，用`-a`指定标签名，`-m`指定说明文字：\n\n```\n$ git tag -a v0.1 -m \"version 0.1 released\" 1094adb\n```\n\n用命令`git show <tagname>`可以看到说明文字：\n\n```\n$ git show v0.1tag v0.1Tagger: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 22:48:43 2018 +0800version 0.1 releasedcommit 1094adb7b9b3807259d8cb349e7df1d4d6477073 (tag: v0.1)Author: Michael Liao <askxuefeng@gmail.com>Date:   Fri May 18 21:06:15 2018 +0800    append GPLdiff --git a/readme.txt b/readme.txt...\n```\n\n 注意：标签总是和某个commit挂钩。如果这个commit既出现在master分支，又出现在dev分支，那么在这两个分支上都可以看到这个标签。\n\n\n\n### 小结\n\n- 命令`git tag <tagname>`用于新建一个标签，默认为`HEAD`，也可以指定一个commit id；\n- 命令`git tag -a <tagname> -m \"blablabla...\"`可以指定标签信息；\n- 命令`git tag`可以查看所有标签。\n\n## 操作标签\n\n如果标签打错了，也可以删除：\n\n```\n$ git tag -d v0.1Deleted tag 'v0.1' (was f15b0dd)\n```\n\n因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。\n\n如果要推送某个标签到远程，使用命令`git push origin <tagname>`：\n\n```\n$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag]         v1.0 -> v1.0\n```\n\n或者，一次性推送全部尚未推送到远程的本地标签：\n\n```\n$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag]         v0.9 -> v0.9\n```\n\n如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除：\n\n```\n$ git tag -d v0.9Deleted tag 'v0.9' (was f52c633)\n```\n\n然后，从远程删除。删除命令也是push，但是格式如下：\n\n```\n$ git push origin :refs/tags/v0.9To github.com:michaelliao/learngit.git - [deleted]         v0.9\n```\n\n要看看是否真的从远程库删除了标签，可以登陆GitHub查看。\n\n\n\n### 小结\n\n- 命令`git push origin <tagname>`可以推送一个本地标签；\n- 命令`git push origin --tags`可以推送全部未推送过的本地标签；\n- 命令`git tag -d <tagname>`可以删除一个本地标签；\n- 命令`git push origin :refs/tags/<tagname>`可以删除一个远程标签。\n\n# 使用GitHub\n\n我们一直用GitHub作为免费的远程仓库，如果是个人的开源项目，放到GitHub上是完全没有问题的。其实GitHub还是一个开源协作社区，通过GitHub，既可以让别人参与你的开源项目，也可以参与别人的开源项目。\n\n在GitHub出现以前，开源项目开源容易，但让广大人民群众参与进来比较困难，因为要参与，就要提交代码，而给每个想提交代码的群众都开一个账号那是不现实的，因此，群众也仅限于报个bug，即使能改掉bug，也只能把diff文件用邮件发过去，很不方便。\n\n但是在GitHub上，利用Git极其强大的克隆和分支功能，广大人民群众真正可以第一次自由参与各种开源项目了。\n\n如何参与一个开源项目呢？比如人气极高的bootstrap项目，这是一个非常强大的CSS框架，你可以访问它的项目主页https://github.com/twbs/bootstrap，点“Fork”就在自己的账号下克隆了一个bootstrap仓库，然后，从自己的账号下clone：\n\n```\ngit clone git@github.com:michaelliao/bootstrap.git\n```\n\n一定要从自己的账号下clone仓库，这样你才能推送修改。如果从bootstrap的作者的仓库地址`git@github.com:twbs/bootstrap.git`克隆，因为没有权限，你将不能推送修改。\n\nBootstrap的官方仓库`twbs/bootstrap`、你在GitHub上克隆的仓库`my/bootstrap`，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样：\n\n```ascii\n┌─ GitHub ────────────────────────────────────┐│                                             ││ ┌─────────────────┐     ┌─────────────────┐ ││ │ twbs/bootstrap  │────>│  my/bootstrap   │ ││ └─────────────────┘     └─────────────────┘ ││                                  ▲          │└──────────────────────────────────┼──────────┘                                   ▼                          ┌─────────────────┐                          │ local/bootstrap │                          └─────────────────┘\n```\n\n如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送。\n\n如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了。\n\n如果你没能力修改bootstrap，但又想要试一把pull request，那就Fork一下我的仓库：https://github.com/michaelliao/learngit，创建一个`your-github-id.txt`的文本文件，写点自己学习Git的心得，然后推送一个pull request给我，我会视心情而定是否接受。\n\n### 小结\n\n- 在GitHub上，可以任意Fork开源仓库；\n- 自己拥有Fork后的仓库的读写权限；\n- 可以推送pull request给官方仓库来贡献代码。\n\n# 使用Gitee\n\n如果我们希望体验Git飞一般的速度，可以使用国内的Git托管服务——[Gitee](https://gitee.com/?utm_source=blog_lxf)（[gitee.com](https://gitee.com/?utm_source=blog_lxf)）。\n\n和GitHub相比，Gitee也提供免费的Git仓库。此外，还集成了代码质量检测、项目演示等功能。对于团队协作开发，Gitee还提供了项目管理、代码托管、文档管理的服务，5人以下小团队免费。\n\n Gitee的免费版本也提供私有库功能，只是有5人的成员上限。\n\n使用Gitee和使用GitHub类似，我们在Gitee上注册账号并登录后，需要先上传自己的SSH公钥。选择右上角用户头像 -> 菜单“修改资料”，然后选择“SSH公钥”，填写一个便于识别的标题，然后把用户主目录下的`.ssh/id_rsa.pub`文件的内容粘贴进去：\n\n![gitee-add-ssh-key](https://www.liaoxuefeng.com/files/attachments/1163452910422880/l)\n\n点击“确定”即可完成并看到刚才添加的Key：\n\n![gitee-key](https://www.liaoxuefeng.com/files/attachments/1163453163108928/l)\n\n如果我们已经有了一个本地的git仓库（例如，一个名为learngit的本地库），如何把它关联到Gitee的远程库上呢？\n\n首先，我们在Gitee上创建一个新的项目，选择右上角用户头像 -> 菜单“控制面板”，然后点击“创建项目”：\n\n![gitee-new-repo](https://www.liaoxuefeng.com/files/attachments/1163453517527296/l)\n\n项目名称最好与本地库保持一致：\n\n然后，我们在本地库上使用命令`git remote add`把它和Gitee的远程库关联：\n\n```\ngit remote add origin git@gitee.com:liaoxuefeng/learngit.git\n```\n\n之后，就可以正常地用`git push`和`git pull`推送了！\n\n如果在使用命令`git remote add`时报错：\n\n```\ngit remote add origin git@gitee.com:liaoxuefeng/learngit.gitfatal: remote origin already exists.\n```\n\n这说明本地库已经关联了一个名叫`origin`的远程库，此时，可以先用`git remote -v`查看远程库信息：\n\n```\ngit remote -vorigin\tgit@github.com:michaelliao/learngit.git (fetch)origin\tgit@github.com:michaelliao/learngit.git (push)\n```\n\n可以看到，本地库已经关联了`origin`的远程库，并且，该远程库指向GitHub。\n\n我们可以删除已有的GitHub远程库：\n\n```\ngit remote rm origin\n```\n\n再关联Gitee的远程库（注意路径中需要填写正确的用户名）：\n\n```\ngit remote add origin git@gitee.com:liaoxuefeng/learngit.git\n```\n\n此时，我们再查看远程库信息：\n\n```\ngit remote -vorigin\tgit@gitee.com:liaoxuefeng/learngit.git (fetch)origin\tgit@gitee.com:liaoxuefeng/learngit.git (push)\n```\n\n现在可以看到，origin已经被关联到Gitee的远程库了。通过`git push`命令就可以把本地库推送到Gitee上。\n\n有的小伙伴又要问了，一个本地库能不能既关联GitHub，又关联Gitee呢？\n\n答案是肯定的，因为git本身是分布式版本控制系统，可以同步到另外一个远程库，当然也可以同步到另外两个远程库。\n\n使用多个远程库时，我们要注意，git给远程库起的默认名称是`origin`，如果有多个远程库，我们需要用不同的名称来标识不同的远程库。\n\n仍然以`learngit`本地库为例，我们先删除已关联的名为`origin`的远程库：\n\n```\ngit remote rm origin\n```\n\n然后，先关联GitHub的远程库：\n\n```\ngit remote add github git@github.com:michaelliao/learngit.git\n```\n\n注意，远程库的名称叫`github`，不叫`origin`了。\n\n接着，再关联Gitee的远程库：\n\n```\ngit remote add gitee git@gitee.com:liaoxuefeng/learngit.git\n```\n\n同样注意，远程库的名称叫`gitee`，不叫`origin`。\n\n现在，我们用`git remote -v`查看远程库信息，可以看到两个远程库：\n\n```\ngit remote -vgitee\tgit@gitee.com:liaoxuefeng/learngit.git (fetch)gitee\tgit@gitee.com:liaoxuefeng/learngit.git (push)github\tgit@github.com:michaelliao/learngit.git (fetch)github\tgit@github.com:michaelliao/learngit.git (push)\n```\n\n如果要推送到GitHub，使用命令：\n\n```\ngit push github master\n```\n\n如果要推送到Gitee，使用命令：\n\n```\ngit push gitee master\n```\n\n这样一来，我们的本地库就可以同时与多个远程库互相同步：\n\n```ascii\n┌─────────┐ ┌─────────┐│ GitHub  │ │  Gitee  │└─────────┘ └─────────┘     ▲           ▲     └─────┬─────┘           │    ┌─────────────┐    │ Local Repo  │    └─────────────┘\n```\n\nGitee也同样提供了Pull request功能，可以让其他小伙伴参与到开源项目中来。你可以通过Fork我的仓库：[https://gitee.com/liaoxuefeng/learngit](https://gitee.com/liaoxuefeng/learngit?utm_source=blog_lxf)，创建一个`your-gitee-id.txt`的文本文件， 写点自己学习Git的心得，然后推送一个pull request给我，这个仓库会在Gitee和GitHub做双向同步。\n\n# 配置别名\n\n有没有经常敲错命令？比如`git status`？`status`这个单词真心不好记。\n\n如果敲`git st`就表示`git status`那就简单多了，当然这种偷懒的办法我们是极力赞成的。\n\n我们只需要敲一行命令，告诉Git，以后`st`就表示`status`：\n\n```\n$ git config --global alias.st status\n```\n\n好了，现在敲`git st`看看效果。\n\n当然还有别的命令可以简写，很多人都用`co`表示`checkout`，`ci`表示`commit`，`br`表示`branch`：\n\n```\n$ git config --global alias.co checkout$ git config --global alias.ci commit$ git config --global alias.br branch\n```\n\n以后提交就可以简写成：\n\n```\n$ git ci -m \"bala bala bala...\"\n```\n\n`--global`参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。\n\n在[撤销修改](https://www.liaoxuefeng.com/wiki/896043488029600/897889638509536)一节中，我们知道，命令`git reset HEAD file`可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个`unstage`别名：\n\n```\n$ git config --global alias.unstage 'reset HEAD'\n```\n\n当你敲入命令：\n\n```\n$ git unstage test.py\n```\n\n实际上Git执行的是：\n\n```\n$ git reset HEAD test.py\n```\n\n配置一个`git last`，让其显示最后一次提交信息：\n\n```\n$ git config --global alias.last 'log -1'\n```\n\n这样，用`git last`就能显示最近一次的提交：\n\n```\n$ git lastcommit adca45d317e6d8a4b23f9811c3d7b7f0f180bfe2Merge: bd6ae48 291bea8Author: Michael Liao <askxuefeng@gmail.com>Date:   Thu Aug 22 22:49:22 2013 +0800    merge & fix hello.py\n```\n\n甚至还有人丧心病狂地把`lg`配置成了：\n\n```\ngit config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit\"\n```\n\n来看看`git lg`的效果：\n\n![git-lg](https://www.liaoxuefeng.com/files/attachments/919059728302912/0)\n\n为什么不早点告诉我？别激动，咱不是为了多记几个英文单词嘛！\n\n## 配置文件\n\n配置Git的时候，加上`--global`是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。\n\n配置文件放哪了？每个仓库的Git配置文件都放在`.git/config`文件中：\n\n```\n$ cat .git/config [core]    repositoryformatversion = 0    filemode = true    bare = false    logallrefupdates = true    ignorecase = true    precomposeunicode = true[remote \"origin\"]    url = git@github.com:michaelliao/learngit.git    fetch = +refs/heads/*:refs/remotes/origin/*[branch \"master\"]    remote = origin    merge = refs/heads/master[alias]    last = log -1\n```\n\n别名就在`[alias]`后面，要删除别名，直接把对应的行删掉即可。\n\n而当前用户的Git配置文件放在用户主目录下的一个隐藏文件`.gitconfig`中：\n\n```\n$ cat .gitconfig[alias]    co = checkout    ci = commit    br = branch    st = status[user]    name = Your Name    email = your@email.com\n```\n\n配置别名也可以直接修改这个文件，如果改错了，可以删掉文件重新通过命令配置。\n\n## 小结\n\n给Git配置好别名，就可以输入命令时偷个懒。我们鼓励偷懒。\n\n# 搭建Git服务器\n\n在[远程仓库](https://www.liaoxuefeng.com/wiki/896043488029600/896954117292416)一节中，我们讲了远程仓库实际上和本地仓库没啥不同，纯粹为了7x24小时开机并交换大家的修改。\n\nGitHub就是一个免费托管开源代码的远程仓库。但是对于某些视源代码如生命的商业公司来说，既不想公开源代码，又舍不得给GitHub交保护费，那就只能自己搭建一台Git服务器作为私有仓库使用。\n\n搭建Git服务器需要准备一台运行Linux的机器，强烈推荐用Ubuntu或Debian，这样，通过几条简单的`apt`命令就可以完成安装。\n\n假设你已经有`sudo`权限的用户账号，下面，正式开始安装。\n\n第一步，安装`git`：\n\n```\n$ sudo apt-get install git\n```\n\n第二步，创建一个`git`用户，用来运行`git`服务：\n\n```\n$ sudo adduser git\n```\n\n第三步，创建证书登录：\n\n收集所有需要登录的用户的公钥，就是他们自己的`id_rsa.pub`文件，把所有公钥导入到`/home/git/.ssh/authorized_keys`文件里，一行一个。\n\n第四步，初始化Git仓库：\n\n先选定一个目录作为Git仓库，假定是`/srv/sample.git`，在`/srv`目录下输入命令：\n\n```\n$ sudo git init --bare sample.git\n```\n\nGit就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以`.git`结尾。然后，把owner改为`git`：\n\n```\n$ sudo chown -R git:git sample.git\n```\n\n第五步，禁用shell登录：\n\n出于安全考虑，第二步创建的git用户不允许登录shell，这可以通过编辑`/etc/passwd`文件完成。找到类似下面的一行：\n\n```\ngit:x:1001:1001:,,,:/home/git:/bin/bash\n```\n\n改为：\n\n```\ngit:x:1001:1001:,,,:/home/git:/usr/bin/git-shell\n```\n\n这样，`git`用户可以正常通过ssh使用git，但无法登录shell，因为我们为`git`用户指定的`git-shell`每次一登录就自动退出。\n\n第六步，克隆远程仓库：\n\n现在，可以通过`git clone`命令克隆远程仓库了，在各自的电脑上运行：\n\n```\n$ git clone git@server:/srv/sample.gitCloning into 'sample'...warning: You appear to have cloned an empty repository.\n```\n\n剩下的推送就简单了。\n\n## 管理公钥\n\n如果团队很小，把每个人的公钥收集起来放到服务器的`/home/git/.ssh/authorized_keys`文件里就是可行的。如果团队有几百号人，就没法这么玩了，这时，可以用[Gitosis](https://github.com/res0nat0r/gitosis)来管理公钥。\n\n这里我们不介绍怎么玩[Gitosis](https://github.com/res0nat0r/gitosis)了，几百号人的团队基本都在500强了，相信找个高水平的Linux管理员问题不大。\n\n## 管理权限\n\n有很多不但视源代码如生命，而且视员工为窃贼的公司，会在版本控制系统里设置一套完善的权限控制，每个人是否有读写权限会精确到每个分支甚至每个目录下。因为Git是为Linux源代码托管而开发的，所以Git也继承了开源社区的精神，不支持权限控制。不过，因为Git支持钩子（hook），所以，可以在服务器端编写一系列脚本来控制提交等操作，达到权限控制的目的。[Gitolite](https://github.com/sitaramc/gitolite)就是这个工具。\n\n这里我们也不介绍[Gitolite](https://github.com/sitaramc/gitolite)了，不要把有限的生命浪费到权限斗争中。\n\n## 小结\n\n- 搭建Git服务器非常简单，通常10分钟即可完成；\n- 要方便管理公钥，用[Gitosis](https://github.com/res0nat0r/gitosis)；\n- 要像SVN那样变态地控制权限，用[Gitolite](https://github.com/sitaramc/gitolite)。\n\n> 转载https://www.liaoxuefeng.com\n>\n","tags":["git"],"categories":["工具"]},{"title":"IDEA快捷键","url":"/2019/08/11/IDEA快捷键/","content":"\nAlt+Enter \n\n导入包，自动修正代码 \n\nCtrl+Y \n\n删除光标所在行 \n\nCtrl+D \n\n复制光标所在行的内容，插入光标位置下面 \n\nCtrl+Alt+L \n\n格式化代码 \n\nCtrl+/ \n\n单行注释 \n\nCtrl+Shift+/ \n\n选中代码注释，多行注释，再按取消注释 \n\nAlt+Ins \n\n自动生成代码，toString，get，set等方法 \n\nAlt+Shift+上下箭头 \n\n移动当前代码行 \n","tags":["IDEA","tool"],"categories":["工具"]}]